{
  "articles": [
    {
      "path": "0-Por_que_R.html",
      "title": "Por que R?",
      "description": "Vantagens e Desvantagens de R e porque usá-lo.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nR vs Python\nR vs Julia\nVantagens de R\nProdutivo (Análises/hora)\nEficaz (Conseguir usar a ferramenta correta dentre um rol de inúmeras)\nComunicativo (Maioria das ciências aplicadas usam R)\nReplicável e Transparente\n\n\n\nHá tantas linguagens de programação por aí: “Por que devo escolher R?” “E Python?” “Ouvi falar que Python é melhor que R.” “Julia é melhor que Python e R,”… Estas são as diversas perguntas e dúvidas que nos são endereçadas quando começamos a abordar R com alunos e pesquisadores. Se você quer a resposta curta (TL;DR1 como é chamado ultimamente) é esta:\n\nVocê consegue praticar Estatística com qualquer linguagem obscura que dê um suporte mínimo a operações matriciais.\n\n\nAqui usamos Estatística quando nos referimos a disciplina e estatística quando nos referimos a uma métrica dos dados\nEntão, se você quiser “fazer Estatística” com COBOL, LISP ou qualquer outra coisa fique a vontade… Não vamos te impedir. Agora se você quer “fazer Estatística” sendo:\nProdutivo (Análises/hora)\nEficaz (Conseguir usar a ferramenta correta dentre um rol de inúmeras)\nComunicativo (Maioria das ciências aplicadas usam R)\nReplicável (Com as configurações corretas, sua análise sempre será a mesma)\nTransparente (Não tem como se esconder atrás de opensource)\nEntão, acreditamos que o R é a escolha certa\nPrimeiramente, abordaremos o R versus outras duas linguagens muito usadas para dados: Python e Julia. E na sequência, explanaremos essas cinco características de R.\nR vs Python\nEssa é uma briga boa. Acreditamos que não há um vencedor. Ambas são muito boas para certos fins. Primeiramente as semelhanças:\nAmbas são linguagens lentas e tudo que é rapido é rodado em C/C++ ou Fortran2 com wrappers convenientes.\nAmbas são amplamente usadas para análise de dados e possuem bibliotecas especializadas para certas operações.\nAmbas possuem uma comunidade ativa de usuários e contribuidores.\nAmbas são opensource e gratuitas3.\nAgora as diferenças. Essa é a parte mais interessante e sem dúvida desencadeia muito hate mail4:\nR é mais voltada para o paradigma de programação funcional, enquanto Python é mais voltado para o paradigma de programação orientada a objetos\nR é feito por estatísticos para estatísticos (ou para quem queira primeiramente fazer análises estatísticas). Dados tabulares e funções estatísticas são “cidadãos de primeira-classe.” Python teve que sofrer (e ainda sofre) muitas gambiarras customizações para conseguirem trabalhar com dados tabulares e funções estatísticas.\nR é mais interoperacional que Python. Com o R conseguimos exportar a aproveitar resultados de uma biblioteca em outra por meio de objetos data.frame. Com o Python, isto é mais complicado e interoperabilidade envolve martelar transformar objetos oriundos de uma biblioteca em classes comuns de Python ou em tipos de arquivos comuns (JSON, CSV etc.)\nR é mais usado pelos cientistas e estatísticos5.\nR possui mais bibliotecas e maneiras de se analisar estatisticamente dados que Python. Maioria das novas inovações em métodos estatísticos oriundos de teses e artigos são também escritos em bibliotecas de R e publicados.\nR não é muito bom para Deep Learning (Aprendizagem Profunda). A maioria dessas bibliotecas são focadas em Python. Mas quando falamos de Machine Learning, tanto R quando Python possuem o mesmo potencial.\nR não tem list comprehension (compreensão de listas), enquanto Python tem.\n\nQuando falamos Deep Learning estamos no referindo à Redes Neurais com diversas camadas. E Machine Learning à modelos estatísticos que o intuito é poder preditivo.\nR vs Julia\nCom as grandes diferenças entre Python e R apresentadas, precisamos falar de Julia. Julia é uma linguagem nova oriunda do MIT que está sendo muito usada para computação científica. O quê muda com Julia?\nJulia é rápida. E quando eu digo rápida, eu quero dizer bem rápida. Julia trabalha em cima do LLVM(Low Level Virtual Machine) que é um compilador universal e usa uma abordagem JIT (Just-in-Time) de compilação de código que faz com que seja às vezes 100x mais rápida que R ou Python para algumas operações6.\nJulia permite usarmos caracteres unicode como variáveis no código. Isso quer dizer que eu consigo escrever em Julia algo como µ = 0 e em Python/R seria escrito mu = 0. Para matemáticos e cientistas isso permite com o que o código fique mais inteligível.\nJulia ainda é muito nova e não há bibliotecas para todas as coisas que conseguimos fazer com Python e R.\nJulia, assim como Python, possui list comprehension (compreensão de listas).\nJulia é uma linguagem que estamos olhando de maneira promissora. Ela é rápida, já é adotada pela comunidade científica, possui um paradigma funcional e permite uma melhor inteligibilidade do código ao permitir o uso de caracteres unicode e símbolos matemáticos7.\nA principal lacuna que a linguagem Julia tenta solucionar é o paradigma das duas linguagens. Esse paradigma é como os desenvolvedores de algoritmos e softwares de análise desenvolvem suas funcionalidades. Primeiro o código é escrito em uma linguagem de fácil entendeimento e rápida prototipagem como R ou Python. Então, o código do protótipo é testado com um problema pequeno ou com uma fração dos dados que serão utilizados pela solução final. Somente após averiguar que o protótipo funciona da maneira correta, é que os desenvolvedores partem para uma linguagem mais robusta e rápida, mas de implementação demorada como C++ ou Fortran. Julia serve para eliminar esse paradigma e ser a linguagem usada tanto para prototipagem quando para implementação.\nAcreditamos que ainda é necessário no mínimo 5 anos para sabermos qual será o real potencial da linguagem Julia. O nosso conselho é usar R para suas análises estatísticas e considerar Julia se precisar de algo mais incomum que necessite de computação intensa que não tenha ainda uma implementação rápida em R ou Python (usando C/C++ ou Fortran).\nVantagens de R\nCom essas diferenças e semelhanças com Python e Julia, é hora de retornarmos aquelas cinco características que mostramos.\nProdutivo (Análises/hora)\nCom R, conseguimos nos aproveitar do paradigma de programação funcional e sermos mais produtivos (além que o código fica muito mais inteligível). Veja um exemplo abaixo com R e Python. Estamos pegando um dataset chamado mtcars que possui informações sobre alguns carros. Aqui serão feitas algumas operações sequenciais:\nTransformar variáveis que contém texto em variáveis categóricas8\nFiltrar somente as observações que tenham hp maior que 100\nCalcular a média somente para as variáveis númericas\nPrimeiro o R, veja como o código é muito mais sucinto e simples de ler. O pipe %>% significa “pegue o resultado dessa operação e jogue como input da próxima.” Aqui estamos usando o pacote {dplyr} do {tidyverse}.\n\n\nmtcars %>% \n  mutate_if(is.character, as.factor) %>% \n  filter(hp > 100) %>% \n  summarise_if(is.numeric, mean)\n\n\n\nAgora com Python usando a biblioteca {pandas}. Como a lógica de Python é orientada a objetos eu tenho que acessar as funções e atributos de um objeto usando um ponto . após o objeto. Exemplos: objeto.atributo ou objeto.funcao(). Aqui estou fazendo diversas operações em um objeto chamado mtcars que é o nosso dataset. Quase todas operações do {pandas} em um dataset resultam em um novo dataset transformado. Aqui é muito mais complicado porque eu preciso encadear diversas operações usando funções de um objeto. Sem o paradigma funcional (e em especial o pipe %>%) o código fica muito mais verboso e não tão inteligível.\n\nmtcars.select_dtypes(\n  ['object']).apply(\n    lambda x: x.astype('category')).query(\n      'hp > 100').select_dtypes(\n        ['number']).mean()\n\nNós preferimos usar o R para manipular e transformar dados, não só porque a síntaxe é melhor, mas também porque há muito mais funções e operações criadas para diversos tipos de manipulações. No universo das bibliotecas do {tidyverse} temos os chamados core packages:\n{readr} – Leitura de dados de diversos tipos de arquivos\n{tidyr} – Coerção de dados em formatos diversos para um formato tabular\n{dplyr} – Manipulação e transformação de dados tabulares\n{ggplot2} – Gráficos\n{stringr} – Manipulação de dados textuais\n{forcats} – Manipulação de dados qualitativos\n{purrr} – Programação funcional\nAlém disso, há as bibliotecas auxiliares\n{readxl} – Leitura de dados de tabelas Excel\n{haven} – Leitura de dados de tabelas SPSS e Stata\n{DBI} e {dbplyr} – Leitura de dados de Banco de Dados e tradução de operações usando linguagem R e verbos do {tidyverse}9 em operações usando linguagem SQL\n{rvest} e {httr} – Raspagem de dados da Web\nTodas esses bibliotecas rodam em C/C++ e por isso são bem rápidos e eficientes. Além disso, vale a pena mecionar todo o universo {tidymodels} que é um ecossistema para modelagem e machine learning com R.\nEficaz (Conseguir usar a ferramenta correta dentre um rol de inúmeras)\nAtualmente o CRAN10 possui um total de 16,837 bibliotecas11. Todas opensource e gratuitas. Quase toda grande inovação em Estatística em diversos campos são publicadas como bibliotecas de R. A incorporação de novas ferramentas ao rol do estatístico no ecossistema do R é muito mais simples e fácil por conta da interoperabilidade proporcionada pelo objeto universal básico de R que é o data.frame. Tal funcionalidade é incorporada na linguagem em si, qualquer versão de R (desde os primórdios da década de 90) já tinha esse objeto para representar dados tabulares.\nAlém de bibliotecas para análises de dados e Rstatística de maneira geral. Temos ecossistemas e bibliotecas para campos distintos como por exemplo12:\nEstatística Bayesiana\nEnsaios Clínicos\nFinanças\nEconomia\nDados Geospaciais\nAnálise de Sobreviência\nSéries Temporais\nGenoma e Genética\nConstrução e Validação de Escalas\nComunicativo (Maioria das ciências aplicadas usam R)\nDurante o processo de avaliação-por-pares que as publicações científicas passam para serem publicadas, muitos editores e revisores pedem aos autores que submetam ou mostrem o código usado para analisar os dados. Isto é feito para averiguar se a análise foi feita de maneira correta. E a maioria dessas análises no mundo das ciências aplicadas, em especial a área de ciências sociais aplicadas13, usam o R.\nAlém disso, com a biblioteca {rmarkdown} e seus diversos templates, é possível criar diversos tipos de documentos14:\nDocumentos:\nHTML com CSS usando Bootstrap\nPDF\nWord\nRTF\nODT\n\nApresentações (slides):\nioslides\nBeamer\nSlidy\nPowerPoint\n\nArtigos formatados para certos periódicos usando os templates da biblioteca {rticles}\nDashboards\nLivros\nWebsites\nBlogs\nCurriculum Vitae\nReplicável e Transparente15\nA ciência está passando por uma crise de credibilidade que no fundo é também uma crise de replicabilidade. Um livro muito que recomendamos para entender esta crise da ciência é o “Science Fictions: How Fraud, Bias, Negligence, and Hype Undermine the Search for Truth” de Stuart Ritchie (Ritchie, 2020)16. Uma das vantagens do R é que com o mesmo código e o mesmo conjunto de dados, dois usuários conseguem chegar na mesma análise e resultados. Claro que R não soluciona todo o problema de replicabilidade da ciência. Mas, código aberto, e se possível, dados abertos, já ajudam bastante…\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS Medicine, 2(8), e124.\n\n\nRitchie, S. (2020). Science fictions: Exposing fraud, bias, negligence and hype in science. Random House.\n\n\nToo Long, Didn’t Read, traduzindo Muito Grande, Não Li↩︎\nSciPy roda em C/C++ e Fortran, NumPy em C/C++, todo o tidyverse roda em C++, etc↩︎\nÓbvio, mas é bom enfatizar.↩︎\nNotem que estas são nossas opiniões. E como não casamos com opiniões, casamos com fatos (afinal somos estatísticos): uma vez que os fatos mudam, nossas opiniões mudarão de acordo.↩︎\nClaro que em alguns campos (ex: ciências da computação), Python é muito mais utilizado.↩︎\nQuando Python e R usam C/C++ ou Fortran essa vantagem cai bastante ou é inexistente.↩︎\nPara o leitor isso não pode fazer diferença. Mas quando você, por exemplo, quer pegar um algoritmo descrito matematicamente em um artigo e implementá-lo diretamente em código, esses caracteres matemáticos são muito bem-vindos. Palavras de quem já escreveu um algoritmo de Amostragem Monte Carlo usando correntes Markov na mão (não por falta de opção, mas por busca de sinestesia para melhor aprendizagem).↩︎\nVariáveis categóricas são conhecidas como factors no R e são maneiras eficientes de manipular e armazenar dados não-numéricos. Geralmente dados não-numéricos são dados textuais ou alguma chave de identificação unica (tipo um id).↩︎\nAqui você já viu alguns em ação: mutate(), filter() e summarise()↩︎\nCRAN – Comprehensive R Archive Network, repositório global de bibliotecas de R.↩︎\nDados de 27/12/20.↩︎\nPara ver uma lista curada pelo CRAN de bibliotecas por assunto vá em CRAN Task Views.↩︎\nDa qual, nós somos oriundos.↩︎\nEste documento é um exemplo. Usamos a biblioteca {distill} que é focada para escrita científica e técnica.↩︎\nNão é uma característica única do R, mas de qualquer linguagem que possua suporte básico a análise e manipulação de dados.↩︎\nHá um metacientista (cientista que estuda a ciência) chamado John Ioannidis que possui diversas publicações interessantes sobre a crise atual da ciência. Em especial, há um artigo de 2005 intitulado “Why Most Published Research Findings Are False” publicado na PLOS Medicine (Ioannidis, 2005) que merece atenção do leitor.\n\n↩︎\n",
      "last_modified": "2020-12-27T11:57:22-03:00"
    },
    {
      "path": "1-Comandos_Basicos.html",
      "title": "Comandos Básicos de R",
      "description": "Introdução ao R e aos comandos básicos do R.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nLendo Arquivos\nCSV\nExcel\n\nGráficos\nAmbiente\n\n\nEste arquivo é um documento R Markdown Quando você executa um código nesse documento os resultados aparecem abaixo do código.\nPara executar um código clique no botão Run (play em cor verde) ou coloque o seu cursos dentro do código e aperte Ctrl+Shift+Enter.\n\n\nprint(\"Você executou um código\")\n\n\n[1] \"Você executou um código\"\n\nVocê pode adicionar um novo código clicando no botão Insert Chunk na toolbar ou apertando Crtl+Alt+I.\nQuando você salva esse notebook, um arquivo HTML contendo o código e os resultados será salvo junto com ele (clique no botão Preview ou aperte Crtl+Shift+K para visualizar o arquivo HTML).\nEssa visualização mostra uma copia renderizada em HTML do editor do R. Ao contrário do botão Knit, Preview não executra nenhum código de R. Ele apenas exibe o output do código quando foi executado a última vez. Além disso, o botão Knit permite com que você renderize o documento como HTML, PDF ou Word.\nLendo Arquivos\nCSV\nPara ler um arquivo CSV (.csv) no R execute a função read.csv() para arquivos CSV formato americano (vírgula como separador e decimais como ponto) ou a função read.csv2() para arquivos CSV formato europeu/brasileiro (ponto-e-vírgula como separador e decimais como vírgula). Não esqueça de designar a leitura para uma variável com o designador <-.\n\n\ndf <- read.csv2(\"datasets/mtcars.csv\", row.names = 1)\nhead(df)\n\n\n                  mpg cyl disp  hp drat  wt qsec vs am gear carb\nMazda RX4          21   6  160 110  3.9 2.6   16  0  1    4    4\nMazda RX4 Wag      21   6  160 110  3.9 2.9   17  0  1    4    4\nDatsun 710         23   4  108  93  3.9 2.3   19  1  1    4    1\nHornet 4 Drive     21   6  258 110  3.1 3.2   19  1  0    3    1\nHornet Sportabout  19   8  360 175  3.1 3.4   17  0  0    3    2\nValiant            18   6  225 105  2.8 3.5   20  1  0    3    1\n\nExcel\nPara ler um arquivo Excel (.xls ou .xlsx) no R é necessário importar um pacote chamado readxl que contem a função read_excel. Para importar um pacote no R executamos o comando library() com um argumento único sendo o nome do pacote. Caso não tenha o pacote instalado, deve instalar ele com o comando install.packages(). Não esqueça de colocar o nome do pacote entre aspas \"nome_do_pacote\" dentro do parênteses da função.\n\n\n# install.packages(\"readxl\")\nlibrary(readxl)\ndf <- read_excel(\"datasets/mtcars.xlsx\")\nhead(df)\n\n\n# A tibble: 6 x 12\n  ...1       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n  <chr>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Mazda R…  21       6   160   110  3.9   2.62  16.5     0     1     4\n2 Mazda R…  21       6   160   110  3.9   2.88  17.0     0     1     4\n3 Datsun …  22.8     4   108    93  3.85  2.32  18.6     1     1     4\n4 Hornet …  21.4     6   258   110  3.08  3.22  19.4     1     0     3\n5 Hornet …  18.7     8   360   175  3.15  3.44  17.0     0     0     3\n6 Valiant   18.1     6   225   105  2.76  3.46  20.2     1     0     3\n# … with 1 more variable: carb <dbl>\n\nGráficos\nGeralmente no R você pode plotar diversos objetos (variáveis do ambiente) com o comando plot(). Quando você plota um dataset (conjunto de dados lido de um aquivo), o R retorna um gráfico chamado Pair Plot:\nNa diagonal: nome da variável (coluna do dataset)\nFora da diagonal: um gráfico de dispersão entre a variável no eixo horizontal e a variável no eixo vertical\nExemplo: Veja a relação entre disp (cilindrada) e hp (cavalos de potência). Ela é uma relação positiva. Quanto maior disp maior hp.\n\n\nplot(mtcars)\n\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] readxl_1.3.1\n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.5        compiler_4.0.3    cellranger_1.1.0 \n [4] pillar_1.4.7      tools_4.0.3       digest_0.6.27    \n [7] downlit_0.2.1     lubridate_1.7.9.2 jsonlite_1.7.2   \n[10] evaluate_0.14     tibble_3.0.4      lifecycle_0.2.0  \n[13] lattice_0.20-41   pkgconfig_2.0.3   rlang_0.4.9      \n[16] Matrix_1.3-0      cli_2.2.0         rstudioapi_0.13  \n[19] distill_1.1       yaml_2.2.1        parallel_4.0.3   \n[22] xfun_0.19         stringr_1.4.0     xml2_1.3.2       \n[25] knitr_1.30        generics_0.1.0    vctrs_0.3.6      \n[28] rprojroot_2.0.2   grid_4.0.3        reticulate_1.18  \n[31] glue_1.4.2        fansi_0.4.1       rmarkdown_2.6    \n[34] bookdown_0.21     magrittr_2.0.1    htmltools_0.5.0  \n[37] ellipsis_0.3.1    assertthat_0.2.1  utf8_1.1.4       \n[40] stringi_1.5.3     crayon_1.3.4     \n\n\n\n\n",
      "last_modified": "2020-12-27T11:57:24-03:00"
    },
    {
      "path": "2-Teste_t.html",
      "title": "Teste de Médias - Teste t de Student e Testes não-Paramétricos",
      "description": "Como comparar a diferença de uma variável entre dois grupos.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nPressupostos\nIndependência dos Dados\nNormalidade, Tamanho Amostral e Homogeneidade das Variâncias\n\n\\(p\\)-valor e Hipótese Nula \\(H_0\\)\nAlgumas questões históricas\nO que o \\(p\\)-valor não é\nIntervalos de Confiança\nSignificância Estatística vs Significância Prática\n\nTeste \\(t\\) de Student\nStudent vs Welch\nTeste \\(t\\) para Amostras Independentes\nTeste \\(t\\) para duas Amostras Pareadas\n\nTestes \\(t\\) Não-Paramétricos\nTeste de Mann–Whitney\nTeste de Wilcoxon\n\nComo visualizar testes de média entre grupos com R\nAmbiente\n\n\nPressupostos\nAntes de avançarmos, é necessário clarificar algo que muitos pesquisadores e cientistas não se atentam e acaba invalidando diversas análises1: pressupostos das técnicas estatísticas clássicas.\nIndependência dos Dados\nPrimeiramente, para quase toda a estatística inferencial2, temos o pressuposto de independência dos dados. Isso é valido para teste \\(t\\), ANOVA, regressões, entre outros… O pressuposto de independência dos dados quer dizer que o valor de uma observação não influencia ou afeta o valor de outras observações. Caso você encontre dados que violam esse pressuposto, é necessário incluir na sua análise. Fontes comuns de não-independência são3:\nDependência Temporal: O valor de uma observação é influenciado pela dimensão temporal. Muito comum em séries temporais, tais como dados financeiros e econômicos. Nesse caso, o ideal é tentar incluir a dimensão temporal na sua análise.\nDependência Espacial: O valor de uma observação é influenciado pela dimensão espacial. Muito comum em dados geoespaciais e georeferenciados. Aqui, o ideal é incorporar a dimensão espacial na sua análise.\n\nDependência temporal e espacial não são os únicos tipos de dependências que existem nos dados. Se as observações tiverem algum tipo de relação que faz com que uma influencie a outra, considere o pressuposto de independência dos dados violado.\nSe esse pressuposto for violado, as técnicas clássicas de Estatística inferencial não serão válidas na sua análise. Sugerimos que você tente remover a fonte de dependência dos dados, recoletar os dados de maneira que não sejam geradas fontes de dependência, ou empregar técnicas que consigam incorporar a fonte de dependência na análise.\nNormalidade, Tamanho Amostral e Homogeneidade das Variâncias\n\n\n\nAqui estão sempre as três pedras no sapato das técnicas clássicas de Estatística inferencial. E antes de apresentar elas, vale a pena um pequeno histórico dessas técnicas. Antes do advento de computadores, todos esses cálculos estatísticos e matemáticos eram feitos na mão. Então, como uma maneira de facilitar o cálculo, foram feitas diversas truques derivações matemáticas usando a teoria da probabilidade para computar facilmente um teste estatístico e gerar algo que vocês já devem ter ouvido falar: \\(p\\)-valor. Mais sobre \\(p\\)-valor adiante…\n\nQuem ficou curioso com a história da Estatística. Recomendo um livro de Stephen Stigler intitulado Statistics on the Table: The History of Statistical Concepts and Methods. O primeiro autor comprou uma cópia em um sebo online.\nComo decorrência dessas facilidades, os testes estatísticos possuem fortes pressupostos sobre os dados. E, se esses pressupostos forem violados, os resultados todos análise podem ser invalidados.\nVoltando às três pedras no sapato. Duas delas são realmente pressupostos: normalidade e homogeneidade de variâncias. A restante, tamanho amostral, abordamos em um conteúdo auxiliar.\nNormalidade\nDados normais são dados que seguem uma distribuição Normal, também conhecida por distribuição Gaussiana4. Uma variável distribuída como uma distribuição Normal segue aquela forma clássica de sino. Mais especificamente, esse pressuposto de normalidade geralmante se aplica somente à variável dependente. Abaixo um exemplo de variável Normal.\n\nVariável dependente é aquela que estamos interessados na nossa análise. É a variável que se altera conforme outras variáveis (chamadas de independentes) se alteram.\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\ntibble(x = c(-4, 4)) %>% \nggplot(aes(x)) + \n    stat_function(size = 3, col = \"red\", fun = dnorm) +\n  labs(\n    x = NULL,\n    y = NULL\n  )\n\n\n\n\nFigure 1: Distribuição Normal\n\n\n\nComo eu sei que minha variável dependente é Normal?\nMuitos gostam de plotar um gráfico para bisolhar estimar se uma varíavel segue uma distribuição Normal ou não. Somos adeptos de visualizações e usamos constantemente nas nossas análises. Mas, na Estatística, as visualizações são muito boas para mostrar alguma tendência, característica ou peculiaridade dos dados. Agora, para provar algo é necessário um teste estatístico.\nHá dois testes estatísticos para saber se uma variável é distribuída conforme uma distribuição Normal: Komolgorov-Smirnov e Shapiro-Wilk.\nKomolgorov-Smirnov vs Shapiro-Wilk\nAmbos os testes aceitam como input uma variável e dão como output um \\(p\\)-valor. Mas qual usar? Estudos comparativos (Saculinggan & Balase, 2013) de diferentes testes de normalidade demonstram que Shapiro-Wilk é o teste com maior poder estatístico5.\nAbaixo, no R, vamos simular 1.000 observações de uma variável distribuída conforme uma distribuição Normal com média 0 e desvio padrão 1. Além disso, vamos simular também 100 observações de uma variável bem longe de ser distribuída como uma distribuição Normal. Vamos usar uma variável distribuída conforme uma distribuição Log-Normal. Primeiramente, vamos mostrar graficamente as duas distribuições. Como vocês podem na figura 2, a distribuição Normal tem a forma característica de sino e a distribuição Log-Normal tem uma assimetria para a direita com uma cauda mais alongada.\n\n\ntibble(x = c(-8, 8)) %>% \nggplot(aes(x)) + \n  stat_function(size = 3, col = \"red\", fun = dnorm) +\n  stat_function(size = 3, col = \"blue\", fun = dlnorm) +\n  labs(\n    x = NULL,\n    y = NULL\n  )\n\n\n\n\nFigure 2: Distribuição Normal vs Distribuição Log-Normal\n\n\n\nAgora com as simulações! Na figura 3 é possível ver o histograma das distribuições simuladas. Em vermelho temos o histograma das 1.000 amostragens de uma distribuição Normal e, em azul da distribuição Log-Normal.\n\n\nset.seed(123)\nn_sim <- 1000\nsims <- tibble(\n  normal = rnorm(n_sim),\n  log_normal = rlnorm(n_sim)\n)\n\nggplot(sims) +\n  geom_density(aes(normal, fill = \"Normal\"), alpha = 0.5) +\n  geom_density(aes(log_normal, fill = \"Log-Normal\"), alpha = 0.5) +\n  labs(y = NULL, x = NULL) +\n  scale_fill_manual(name = \"Distribuição\", values = c(\"Normal\" = \"red\", \"Log-Normal\" = \"blue\")) +\n  theme(legend.position = \"bottom\")\n\n\n\n\nFigure 3: Histograma das Simulações de Normalidade\n\n\n\nAgora como fazer um teste de Shapiro-Wilk (shapiro.test) com R. Sobre o \\(p\\)-valor que aparece como resultado do teste, veja adiante. Para agora basta saber que \\(p < 0.05\\) (\\(p\\) menor que 0.05) significa fortes evidências de que a variável testada não segue uma distribuição Normal.\n\n\nshapiro.test(sims$normal)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  sims$normal\nW = 1, p-value = 0.5\n\nshapiro.test(sims$log_normal)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  sims$log_normal\nW = 0.6, p-value <0.0000000000000002\n\nVamos também aproveitar e mostrar como fazer um teste Komolgorov-Smirnof (ks.test). Aqui temos que ser um pouco mais específico pois o teste exige a especificação exata do que comparar. No caso, estamos informando que a distribuição a ser testada contra é uma Normal \"pnorm\" e usamos os valores de média mean() e desvio padrão sd() da distribuição que estamos testando. Lembrando que a definição do \\(p\\)-valor para este teste é a mesma do Shapiro-Wilk.\n\n\nks.test(sims$normal, \"pnorm\", mean(sims$normal), sd(sims$normal))\n\n\n\n    One-sample Kolmogorov-Smirnov test\n\ndata:  sims$normal\nD = 0.01, p-value = 1\nalternative hypothesis: two-sided\n\nks.test(sims$log_normal,  \"pnorm\", mean(sims$log_normal), sd(sims$log_normal))\n\n\n\n    One-sample Kolmogorov-Smirnov test\n\ndata:  sims$log_normal\nD = 0.2, p-value <0.0000000000000002\nalternative hypothesis: two-sided\n\nHomogeneidade das Variâncias\nTambém chamado de homocedasticidade, homogeneidade das variâncias, é um pressuposto que, para uma dada mensuração, a variação dessa mensuração dentro de estratos/grupos da sua amostra é similar. Em outras palavras, se você possui três grupos de indivíduos e está mensurando a altura, a variação da altura dentre os três grupos não pode ser muito diferentes entre os três grupos.\nUma boa maneira de visualizar isso é usarmos distribuições Normais com diferentes médias e desvio padrões. No caso de homogeneidade das variâncias, conseguimos visualizá-la com três distribuições Normais, sendo que todas possuem o mesmo desvio padrão, mas diferentes médias. Esse seria o gráfico da esquerda na figura 4. Já no caso de heterogeneidade, conseguimos demonstrar usando as mesmas três distribuições Normais mas agora introduzindo diferentes desvios padrões. Esta situação é o gráfico da direita na figura 4\n\n\nlibrary(patchwork)\np1 <- ggplot(data.frame(x = c(-4, 4)), aes(x)) + \n  mapply(function(mean, sd, col) {\n    stat_function(fun = dnorm, args = list(mean = mean, sd = sd), size = 3, col = col)\n  }, \n  # enter means, standard deviations and colors here\n  mean = c(0, 1, -1), \n  sd = c(1, 1, 1), \n  col = c('red', 'blue', 'green')\n)\n\np2 <- ggplot(data.frame(x = c(-4, 4)), aes(x)) + \n  mapply(function(mean, sd, col) {\n    stat_function(fun = dnorm, args = list(mean = mean, sd = sd), size = 3, col = col)\n  }, \n  # enter means, standard deviations and colors here\n  mean = c(0, 1, .5), \n  sd = c(1, .5, 2),  \n  col = c('red', 'blue', 'green')\n)\n\np1 | p2\n\n\n\n\nFigure 4: Homogeneidade e Heterogeneidade das Variâncias\n\n\n\nTeste de Levene\nVamos mais uma vez usar simulações. Aqui vamos gerar um dataset de 500 observações em dois grupos: A com 250 e B com 250 observações. E vamos considerar dois cenários: o primeiro onde temos médias diferentes entre os grupos mas homogeneidade de variâncias (possuem o mesmo desvio padrão) e o segundo onde temos médias diferentes entre os grupos e com heterogeneidade de variâncias (possuem desvio padrões diferentes). Ambos cenários podem ser visualizados na figura 5.\n\n\nsims2 <- tibble(\n  group = c(rep(\"A\", n_sim/4), rep(\"B\", n_sim/4)),\n  homog = c(rnorm(n_sim/4, 0, 1), rnorm(n_sim/4, 1, 1)),\n  heterog = c(rnorm(n_sim/4, 0, 0.1), rnorm(n_sim/4, 1, 2))\n)\n\np3 <- ggplot(sims2, aes(homog, fill = group)) + \n  geom_density(alpha = 0.5, show.legend = F)\n\np4 <- ggplot(sims2, aes(heterog, fill = group)) + \n  geom_density(alpha = 0.5, show.legend = F)\n\np3 | p4\n\n\n\n\nFigure 5: Histograma das Simulações de Homogeneidade das Variâncias\n\n\n\nUm teste muito utilizado para testar a igualdade de variâncias é o teste de Levene. O teste de Levene está disponível na biblioteca {car} (Fox & Weisberg, 2019) na função leveneTest() e você tem que passar dois argumentos:\nFórmula designando qual variável deve ser analisada a homogeneidade das variâncias em quais grupos. A fórmula é designada pela seguinte síntaxe: variavel ~ grupo.\nO dataset no qual deverá ser encontrados tanto a varíavel quanto os grupos.\n{car} não tem nada a ver com carros. Ele é um acrônimo para “Companion to Applied Regression” e é uma biblioteca com funções para acompanhar um livro intitulado “An R Companion to Applied Regression” de Fox & Weisberg. Ele tem diversas funções interessantes e testes estatísticos que não estão disponíveis como padrão no R.\n\n\nlibrary(car)\nleveneTest(homog ~ group, data = sims2)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(>F)\ngroup   1    1.74   0.19\n      498               \n\nleveneTest(heterog ~ group, data = sims2)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value              Pr(>F)    \ngroup   1     346 <0.0000000000000002 ***\n      498                                \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSobre o \\(p\\)-valor que aparece como resultado do teste, veja adiante. Para agora basta saber que \\(p < 0.05\\) (\\(p\\) menor que 0.05) significa fortes evidências de que a variável testada não possui homogeneidade de variâncias para os grupos especificados.\n\\(p\\)-valor e Hipótese Nula \\(H_0\\)\n\n\\(p\\)-valores são de difícil entendimento, \\(p < 0.05\\).\n\n\n\n\nEsta parte da Estatística inferencial é a mais complicada e menos intuitiva. Parafraseando Andrew Gelman, estatístico da Columbia University, “Para definir \\(p\\)-valores, escolha uma das duas características: intuitiva ou precisa. Ou sua definição é intuitiva mas imprecisa, ou sua definição é precisa mas não intuitiva.” A grande maioria dos pesquisadores6 possui uma definição incorreta do que é um \\(p\\)-valor (Cumming, 2009). E quando vemos evidências do campo da medicina, que talvez seja o campo com maior quantidade de recursos disponíveis para pesquisa e avanço do conhecimento, também encontramos muitos problemas no uso dos \\(p\\)-valores (Ioannidis, 2019). Antes de entrarmos nas definições de \\(p\\)-valores, vale a pena tranquilizá-los: \\(p\\)-valores são uma coisa complicada e se você não entender na primeira vez que ler as definições abaixo, não se preocupe, você não estará em má companhia; respire fundo e tente novamente.\n\nNem nós ficamos 100% confiantes quando falamos de \\(p\\)-valores…\nPrimeiramente a definição estatística:\n\n\\(p\\)-valor é a probabilidade de obter resultados no mínimo tão extremos quanto os que foram observados, dado que a hipótese nula é verdadeira.\n\nSe você escrever essa definição em qualquer prova, livro ou artigo científico, você estará 100% preciso e correto na definição do que é um \\(p\\)-valor. Agora, a compreensão dessa definição é algo complicado. Para isso, vamos quebrar essa definição em algumas partes para melhor compreensão:\n“probabilidade de obter resultados…”: vejam que \\(p\\)-valores são uma característica dos seus dados e não da sua teoria ou hipótese.\n“…no mínimo tão extremos quanto os que foram observados…”: “no minimo tão” implica em definir um limiar para a caracterização de algum achado relevante, que é comumente chamado de alpha, representado pela letra grega \\(\\alpha\\). Geralmente estipulamos alpha em 5% (\\(\\alpha = 0.05\\)) e qualquer coisa mais extrema que alpha (ou seja menor que 5%) caracterizamos como significante7.\n“..dado que a hipótese nula é verdadeira…”: lembra daquela história de “…derivações matemáticas usando a teoria da probabilidade para computar facilmente um teste estatístico…” que falamos acima? Todo teste estatístico que possui um \\(p\\)-valor possui uma Hipótese Nula (geralmente escrita como \\(H_0\\)). Hipótese nula, sempre tem a ver com algum efeito nulo. Por exemplo, a hipótese nula do teste Shapiro-Wilk e Komolgorov-Smirnov é “os dados são distribuídos conforme uma distribuição Normal” e a do teste de Levene é “as variâncias dos dados são iguais.” Sempre que ver um \\(p\\)-valor, se pergunte: “Qual a hipótese nula que este teste presupõe correta?8”\n\n\n\n\\(p\\)-valor é a probabilidade dos dados que você obteve dado que a hipótese nula é verdadeira. Para os que gostam do formalismo matemático: \\(p = P(D|H_0)\\). Em português, essa expressão significa “a probabilidade de \\(D\\) condicionado à \\(H_0\\).” Antes de avançarmos para alguns exemplos e tentativas de formalizar uma intuição sobre os \\(p\\)-valores, é importante ressaltar que \\(p\\)-valores dizem algo à respeito dos dados e não de hipóteses. Para o \\(p\\)-valor, a hipótese nula é verdadeira, e estamos apenas avaliando se os dados se conformam à essa hipótese nula ou não. Se vocês saírem desse tutorial munidos com essa intuição, o mundo será agraciado com pesquisadores mais preparados para qualificar e interpretar evidências (\\(p < 0.05\\)).\nExemplo intuitivo:\n\nImagine que você tem uma moeda que suspeita ser enviesada para uma probabilidade maior de dar cara. (Sua hipótese nula é então que a moeda é justa.) Você joga a moeda 100 vezes e obtém mais cara do que coroa. O \\(p\\)-valor não dirá se a moeda é justa, mas dirá a probabilidade de você obter pelo menos tantas caras quanto se a moeda fosse justa. É isso - nada mais9.\n\n\nApesar de termos falado anterior que definições intuitivas não são precisas, elas sem dúvida facilitam o entendimento do \\(p\\)-valor.\nAlgumas questões históricas\nNão tem como entendermos \\(p\\)-valores se não compreendermos as suas origens e trajetória histórica. A primeira menção do termo foi feita pelo estatístico Ronald Fisher10 em 1925 (Fisher, 1925) que define o \\(p\\)-valor como um “índice que mede a força da evidência contra a hipótese nula.” Para quantificar a força da evidência contra a hipótese nula, Fisher defendeu “\\(p<0.05\\) (5% de significância) como um nível padrão para concluir que há evidência contra a hipótese testada, embora não como uma regra absoluta.” Fisher não parou por aí mas classificou a força da evidência contra a hipótese nula. Ele propôs “se \\(p\\) está entre 0.1 e 0.9, certamente não há razão para suspeitar da hipótese testada. Se estiver abaixo de 0.02, é fortemente indicado que a hipótese falha em explicar o conjunto dos fatos. Não seremos frequentemente perdidos se traçarmos uma linha convencional de 0.05” Desde que Fisher fez esta declaração há quase 100 anos, o limiar de 0.05 foi usado por pesquisadores e cientistas em todo o mundo e tornou-se ritualístico usar 0.05 como limiar como se outros limiares não pudessem ser usados.\n\n\n\nApós isso, o limiar de 0.05 agora instaurado como inquestionável influenciou fortemente a estatística e a ciência. Mas não há nenhuma razão contra a adoção de outros limiares (\\(\\alpha\\)) como 0.1 ou 0.01. Se bem argumentados, a escolha de limiares diferentes de 0.05 pode ser bem-vista por editores, revisores e orientadores.\n\nApesar que, pela nossa experiência, isto geralmente não é verdade.\nO que o \\(p\\)-valor não é\nCom a definição e intuição do que é um \\(p\\)-valor bem ancoradas, podemos avançar para o que o \\(p\\)-valor não é!\n\n\n\n\\(p\\)-valor não é a probabilidade da Hipótese nula - Famosa confusão entre \\(P(D|H_0)\\) e \\(P(H_0|D)\\). \\(p\\)-valor não é a probabilidade da hipótese nula, mas sim a probabilidade dos dados que você obteve. Por exemplo: a probabilidade de você tossir dado que você está com COVID é diferente da probabilidade de você estar com COVID dado que você tossiu: \\(P(\\text{tosse} | \\text{COVID}) \\neq P(\\text{COVID} | \\text{tosse})\\). Acredito que a primeira, \\(P(\\text{tosse} | \\text{COVID})\\) é bem alta, enquanto a segunda, \\(P(\\text{COVID} | \\text{tosse})\\) deve ser bem baixa (afinal tossimos a todo momento).\n\nO primeiro autor tentou explicar essa diferença para uma senhora que o viu tossir na fila do mercado, mas os seus esforços foram em vão…\n\\(p\\)-valor não é a probabilidade dos dados serem produzidos pelo acaso - Não! Ninguém falou nada de acaso. Mais uma vez: \\(p\\)-valor é probabilidade de obter resultados no mínimo tão extremos quanto os que foram observados, dado que a hipótese nula é verdadeira.\n\\(p\\)-valor mensura o tamanho do efeito de um teste estatístico - Também não… \\(p\\)-valor não diz nada sobre o tamanho do efeito. Apenas sobre se o quanto os dados observados divergem do esperado sob a hipótese nula. É claro que efeitos grandes são mais prováveis de serem estatisticamente significantes que efeitos pequenos. Mas isto não é via de regra e nunca julguem um achado pelo seu \\(p\\)-valor, mas sim pelo seu tamanho de efeito. Além disso, \\(p\\)-valores podem ser hackeados  [ comment ]  de diversas maneiras (Head, Holman, Lanfear, Kahn, & Jennions, 2015) e muitas vezes seu valor é uma consequência direta do tamanho da amostra. Mais sobre isso no conteúdo auxiliar sobre tamanho de amostra.\nIntervalos de Confiança\nIntervalos de confiança foram criados como uma solução para os problemas de má-interpretação dos \\(p\\)-valores e sua aplicação se destina ao tamanho do efeito. Se você achou \\(p\\)-valor confuso, se prepare! Intervalos de confiança são ainda mais confusos…Vamos para a definição estatística:\n\nIntervalo de confiança é o intervalo de valores que incluem um valor de uma população com um certo nível de confiança.\n\nMais uma vez vamos quebrar essa definição em em algumas partes para melhor compreensão:\n“… intervalo de valores …”: intervalo de confiança sempre serão expressados como um intervalo \\(a\\) - \\(b\\), onde \\(a\\) é menor que \\(b\\) (\\(a < b\\)).\n“… incluem um valor de uma população…”: aqui estamos falando de população. E o que você geralmente tem nas suas mãos quando está fazendo uma análise estatística é uma amostra. Uma população é um conjunto de pessoas, itens ou eventos sobre os quais você quer fazer inferências. Uma amostra é um é um subconjunto de pessoas, itens ou eventos de uma população maior que você coleta e analisa para fazer inferências. Geralmente o tamanho da amostra é bem menor que o tamanho da população11. Então, intervalos de confiança expressam a frequência de longo-prazo que vocês esperaria obter de um tamanho de efeito caso replicasse o teste estatístico para diversas amostras da MESMA população.\n“.. com um certo nível de confiança”: sempre os intervalos de confiança serão expressados acompanhados de uma probabilidade (algo entre 0.001% e 99.999%) que quantifica a certeza de encontrar o intervalo em uma replicações do teste estatístico para diversas amostras da MESMA população.\nPor exemplo: digamos que você executou uma análise estatística para comparar eficácia de uma política pública em dois grupos e você obteve a diferença entre a média desses grupos. Você pode expressar essa diferença como um intervalo de confiança. Geralmente escolhemos a confiança de 95% (sim, está relacionado com o 0.05 do \\(p\\)-valor). Você então escreve no seu artigo que a “diferença entre grupos observada é de 10.5 - 23.5 (95% IC).” Isso quer dizer que 95 estudos de 100, que usem o mesmo tamanho de amostra e população-alvo, aplicando o mesmo teste estatístico, esperarão encontrar um resultado de diferenças de média entre grupos entre 10.5 e 23.5. Aqui as unidades são arbitrárias, mas para continuar o exemplo vamos supor que sejam espectativa de vida.\nIntervalos de confiança estão profundamente relacionados com \\(p\\)-valores. Primeiro, para que uma estimativa tenha um \\(p\\)-valor menor que 0.05, seu intervalo de confiança 95% não pode capturar o zero. Ou seja, o intervalo não pode compreender o efeito nulo (Hipótese Nula - \\(H_0\\)). Isso segue para outros valores de \\(p\\) correspondentes com outros níveis de confiança dos intervalos. Por exemplo, para uma estimativa com \\(p\\)-valor menor que 0.01, seu intervalo de confiança 99% não pode capturar o 0. Além disso, intervalos de confiança (assim como \\(p\\)-valores) estão intrinsicamente conectados com o tamanho da amostra. Quanto maior o tamanho de amostra, mais estreito será o intervalo de confiança. A intuição por trás disso é que conforme a sua amostra aumenta, também aumentarão a sua confiança e precisão em inferências sobre a população-alvo. Por fim, intervalos de confiança (assim como \\(p\\)-valores) não falam nada sobre a sua teoria ou hipótese, mas sobre a relação dos seus dados (amostra) com a população-alvo. Eles não são a probabilidade do parâmetro estimado (\\(P(\\text{parâmetro} | D)\\), no nosso exemplo diferença entre médias de grupos), mas sim a probabilidade de amostras com o mesmo parâmetro estimado (\\(P(D | \\text{parâmetro})\\)).\nUma boa maneira de resumir \\(p\\)-valores e intervalos de confiança é a seguinte:\n\nConsidere \\(p\\)-valores algo que mensura a possibilidade de existir um efeito ou não e intervalos de confiança quantificam o tamanho desse efeito.\n\n\nMas sempre se atente nas definições. Lembre-se que se tentarmos ser intuitivos com \\(p\\)-valores e intervalos de confiança não seremos precisos nas definições.\nSignificância Estatística vs Significância Prática\n\nConsidere isso uma introdução rápida à \\(p\\)-hacking.\nPara encerrar esse tour de \\(p\\)-valores e intervalos de confiança, temos que nos atentar que significância estatística não é a mesma coisa que significância prática. Significância estatística é se algum achado de um teste/modelo estatístico diverge o suficiente da hipótese nula e, sendo que hipótese nula sempre são sobre efeitos ou diferenças nulas, podemos afirmar que significância estatística quer dizer um achado é diferente de um efeito nulo. Diversos testes da Estatística inferencial clássica quando submetidos à amostras grandes12 vão detectar uma diferença significante, mesmo que praticamente insignificante. Com uma amostra suficientemente grande nós conseguimos gerar \\(p\\)-valores significantes para diferenças minúsculas, como por exemplo uma diferença de 0.01cm altura entre dois grupos de uma amostra.\nPor isso que defendemos que nunca se interprete análises estatísticas somente com \\(p\\)-valores, mas sempre em conjunto com os intervalos de confiança que quantificam o tamanho do efeito. Nunca gere argumentos sobre evidências somente a partir de significância estatística, sempre inclua tamanho do efeito.\n\nHá uma abordagem de Estatística inferencial que não se baseia em hipóteses nulas e \\(p\\)-valores: a Estatística Bayesiana. Caso fiquem curiosos o primeiro autor possui uma disciplina opensource de Estatística Bayesiana com R.\nTeste \\(t\\) de Student\nAgora estamos prontos para apresentar o teste \\(t\\) de Student.\nWilliam Sealy Gosset (químico, 1876-1937) publicou o teste \\(t\\) sob o pseudônimo de “Student,” razão pela qual o teste às vezes é chamado de “teste \\(t\\) de Student” (Student, 1908). Há controvérsia sobre a origem e o significado de \\(t\\). Uma hipótese é que \\(s\\) era comumente usado na época para se referir a estatísticas de amostra, então Gosset escolheu \\(t\\) como a próxima letra, talvez indicando um “avanço” no pensamento sobre estatísticas de amostra? Gosset publicou sob um pseudônimo porque ele era um funcionário da Cervejaria Guinness na época, e ele foi contratado para examinar questões ao fazer inferências sobre pequenas amostras na fabricação de cerveja. O teste que ele desenvolveu poderia ser propriedade intelectual do Guinness, mas Gosset achou que o teste poderia ser amplamente usado, então ele o publicou sob um pseudônimo para proteger seu trabalho.\nO teste \\(t\\) de Student detecta a diferença entre médias de alguma mensuração de dois grupos. Sua hipótese nula é de que a diferença entre os grupos é zero, então \\(p\\)-valores oriundos do teste \\(t\\) de Student quantificam a probabilidade de você obter resultados tão extremos caso não haja diferença entre os grupos. O teste \\(t\\) de Student assume os seguintes pressupostos com relação aos dados:\nA variável dependente (aquela que estamos usando para calcular a média dos grupos) é distribuída conforme uma distribuição Normal.\nA variável dependente possui homogeneidade de variância dentre os grupos13.\n\nLembre-se que uma vez violados esses pressupostos, os resultados do teste \\(t\\) são inválidos.\nStudent vs Welch\nEm 1947, Bernard Lewis Welch, estatístico britânico adaptou o teste \\(t\\) de Student para ser robusto perante heterogeneidade das variâncias (Welch, 1947). O teste \\(t\\) de Welch é muita vezes confudido e reportado erroneamente como teste \\(t\\) de Student, uma vez que pela sua robustez é o teste \\(t\\) padrão de diversos softwares estatísticos (Delacre, Lakens, & Leys, 2017). No R a função t.test() possui como padrão o teste \\(t\\) de Welch e caso você queira explicitamente usar o teste \\(t\\) de Student você deve incluir o argumento var.equal = TRUE na função.\nTeste \\(t\\) para Amostras Independentes\nQuando temos dois grupos na mesma amostra, usamos o teste \\(t\\) para amostras independentes. A função t.test() é incluída como padrão no R. Aqui vamos simular dois grupos A e B cada um com 20 observações e vamos amostrar de uma distribuição Normal para cada um dos grupos com médias diferentes.\nA fórmula que deve ser passada na função t.test() é similar com a fórmula do car::leveneTest(), sendo que é necessário tem que passar dois argumentos:\nFórmula designando qual variável deve ser analisada a diferença de média em quais grupos. A fórmula é designada pela seguinte síntaxe: variavel ~ grupo.\nO dataset no qual deverá ser encontrados tanto a varíavel quanto os grupos.\nO resultado para a simulação é um \\(p\\)-valor menor que 0.05, ou seja um resultado significante apontando que podemos rejeitar a hipótese nula (fortes evidências contrárias que as médias dos grupos são iguais).\n\n\nn_sim_t <- 20\nsim3 <- tibble(\n  group = c(rep(\"A\", n_sim_t), rep(\"B\", n_sim_t)),\n  measure = c(rnorm(n_sim_t, mean = 0), rnorm(n_sim_t, mean = 5))\n)\n\nt.test(measure ~ group, data = sim3)\n\n\n\n    Welch Two Sample t-test\n\ndata:  measure by group\nt = -13, df = 38, p-value = 0.000000000000001\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -5.1 -3.7\nsample estimates:\nmean in group A mean in group B \n            0.2             4.6 \n\nTeste \\(t\\) para duas Amostras Pareadas\nEm agumas situações temos amostras pareadas, como por exemplo quando fazemos uma mensuração antes e depois de algum acontecimento ou intervenção. Para isso a função t.test() tem o argumento paired que quando definido como TRUE faz com que o teste \\(t\\) seja pareado.\nA mesma simulação do teste \\(t\\) para amostras pareadas, mas agora não usamos a fórmula e passamos como argumento as mensurações das duas amostras pareadas:\n\n\namostra_1 <- tibble(measure = rnorm(n_sim_t, mean = 0))\namostra_2 <- tibble(measure = rnorm(n_sim_t, mean = 5))\n\nt.test(amostra_1$measure, amostra_2$measure, paired = TRUE)\n\n\n\n    Paired t-test\n\ndata:  amostra_1$measure and amostra_2$measure\nt = -15, df = 19, p-value = 0.000000000007\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -5.8 -4.4\nsample estimates:\nmean of the differences \n                   -5.1 \n\nTestes \\(t\\) Não-Paramétricos\nO que fazer se meus dados violam o princípio da normalidade? Nesse caso devemos usar uma abordagem não-paramétrica. O teste \\(t\\) de Student (e também de Welch) é uma abordagem paramétrica: dependem fortemente da suposição que os dados estejam distribuídos de acordo com uma distribuição específica. Testes não-paramétricos não fazem suposições sobre a distribuição dos dados e portanto podem ser usados quando os pressupostos dos testes paramétricos são violados.\nAtenção: testes não-paramétricos são menos sensíveis em rejeitar a hipótese nula quando ela é falsa (erro tipo I) do que testes paramétricos quando o pressuposto de normalidade não é violado (Zimmerman, 1998). Então não pense que deve sempre aplicar um teste não-paramétrico em todas as ocasiões.\nTeste de Mann–Whitney\nO teste de Mann-Whitney foi desenvolvido em 1947 para ser uma alternativa não-paramétrica ao teste \\(t\\) para amostras independentes (Mann & Whitney, 1947). Para aplicar o teste Mann-Whitney use a função wilcox.test()14 é incluída como padrão no R. Aqui vamos simular novemente dois grupos A e B cada um com 20 observações e vamos amostrar de uma distribuição Log-Normal para cada um dos grupos com médias diferentes. A síntaxe é a mesma que a função t.test().\n\n\nsim4 <- tibble(\n  group = c(rep(\"A\", n_sim_t), rep(\"B\", n_sim_t)),\n  measure = c(rlnorm(n_sim_t, mean = 0), rlnorm(n_sim_t, mean = 5))\n)\n\nwilcox.test(measure ~ group, data = sim4)\n\n\n\n    Wilcoxon rank sum exact test\n\ndata:  measure by group\nW = 0, p-value = 0.00000000001\nalternative hypothesis: true location shift is not equal to 0\n\nTeste de Wilcoxon\nO teste de Wilcoxon foi desenvolvido em 1945 para ser uma alternativa não-paramétrica ao teste \\(t\\) para amostras pareadas (Wilcoxon, 1945). A função wilcox.test()15 tem o argumento paired que quando definido como TRUE faz com que o teste não-paramétrico seja pareado (muito similar a função t.test() para amostras pareadas).\nA mesma simulação do teste de Mann-Whitney para amostras pareadas, mas agora não usamos a fórmula e passamos como argumento as mensurações das duas amostras pareadas:\n\n\namostra_3 <- tibble(measure = rlnorm(n_sim_t, mean = 0))\namostra_4 <- tibble(measure = rlnorm(n_sim_t, mean = 5))\n\nwilcox.test(amostra_3$measure, amostra_4$measure, paired = TRUE)\n\n\n\n    Wilcoxon signed rank exact test\n\ndata:  amostra_3$measure and amostra_4$measure\nV = 0, p-value = 0.000002\nalternative hypothesis: true location shift is not equal to 0\n\nComo visualizar testes de média entre grupos com R\nUma das bibliotecas que usamos bastante para visualização de testes estatísticos é a {ggpubr} (Kassambara, 2020). Veja um exemplo abaixo com um dos datasets que simulamos nesse tutorial.\nPrimeiramente criamos um diagrama de caixa (boxplot) com a função ggboxplot() na qual especificamos o eixo X, eixo Y, cor, paleta de cores etc. Na sequencia adicionamos a camada das estatísticas de comparação dos grupos com o stat_compare_means() especificando que tipo de método será utilizado na análise:\n\"wilcox.test\" – Teste não-paramétrico de Wilcoxon (padrão da função).\n\"t.test\" – Teste \\(t\\) paramétrico de Welch.\n\n\nlibrary(ggpubr)\nggboxplot(sim3, x = \"group\", y = \"measure\", color = \"group\", palette = \"lancet\", add = \"jitter\") +\n  stat_compare_means(method = \"t.test\")\n\n\n\n\nFigure 6: Diagrama de Caixa usando o {ggpubr} – Amostras Independentes\n\n\n\nPara testes usando amostras pareadas é necessário usar a função ggpaired() e adicionar o argumento paired = TRUE dentro da função stat_compare_means()\n\n\nggpaired(sim3, x = \"group\", y = \"measure\", color = \"group\", palette = \"lancet\", line.color = \"gray\", line.size = 0.4) +\n  stat_compare_means(method = \"t.test\", paired = TRUE)\n\n\n\n\nFigure 7: Diagrama de Caixa usando o {ggpubr} – Amostras Pareadas\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] ggpubr_0.4.0    car_3.0-10      carData_3.0-4   patchwork_1.1.1\n[5] dplyr_1.0.2     ggplot2_3.3.2   readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.5        lubridate_1.7.9.2 lattice_0.20-41  \n [4] tidyr_1.1.2       assertthat_0.2.1  rprojroot_2.0.2  \n [7] digest_0.6.27     utf8_1.1.4        R6_2.5.0         \n[10] cellranger_1.1.0  backports_1.2.1   evaluate_0.14    \n[13] icon_0.1.0.9000   highr_0.8         pillar_1.4.7     \n[16] rlang_0.4.9       curl_4.3          rstudioapi_0.13  \n[19] data.table_1.13.4 Matrix_1.3-0      reticulate_1.18  \n[22] rmarkdown_2.6     labeling_0.4.2    stringr_1.4.0    \n[25] foreign_0.8-81    munsell_0.5.0     broom_0.7.3      \n[28] compiler_4.0.3    xfun_0.19         pkgconfig_2.0.3  \n[31] htmltools_0.5.0   downlit_0.2.1     tidyselect_1.1.0 \n[34] tibble_3.0.4      bookdown_0.21     rio_0.5.16       \n[37] fansi_0.4.1       crayon_1.3.4      withr_2.3.0      \n[40] rappdirs_0.3.1    grid_4.0.3        jsonlite_1.7.2   \n[43] gtable_0.3.0      lifecycle_0.2.0   magrittr_2.0.1   \n[46] scales_1.1.1      zip_2.1.1         cli_2.2.0        \n[49] stringi_1.5.3     ggsignif_0.6.0    farver_2.0.3     \n[52] xml2_1.3.2        ellipsis_0.3.1    generics_0.1.0   \n[55] vctrs_0.3.6       openxlsx_4.2.3    distill_1.1      \n[58] ggsci_2.9         tools_4.0.3       forcats_0.5.0    \n[61] glue_1.4.2        purrr_0.3.4       hms_0.5.3        \n[64] abind_1.4-5       parallel_4.0.3    yaml_2.2.1       \n[67] colorspace_2.0-0  rstatix_0.6.0     knitr_1.30       \n[70] haven_2.3.1      \n\n\n\n\nBaird, D. (1983). The fisher/pearson chi-squared controversy: A turning point for inductive inference. The British Journal for the Philosophy of Science, 34(2), 105–118. Retrieved from http://www.jstor.org/stable/687444\n\n\nCumming, G. (2009). Inference by eye: Reading the overlap of independent confidence intervals. Statistics in Medicine, 28(2), 205–220.\n\n\nDelacre, M., Lakens, D., & Leys, C. (2017). Why psychologists should by default use welch’s t-test instead of student’s t-test. International Review of Social Psychology, 30(1).\n\n\nFisher, R. A. (1925). Statistical methods for research workers. Oliver; Boyd.\n\n\nFox, J., & Weisberg, S. (2019). An R companion to applied regression (Third). Retrieved from https://socialsciences.mcmaster.ca/jfox/Books/Companion/\n\n\nHead, M. L., Holman, L., Lanfear, R., Kahn, A. T., & Jennions, M. D. (2015). The extent and consequences of p-hacking in science. PLoS Biol, 13(3), e1002106.\n\n\nIoannidis, J. P. A. (2019). What Have We (Not) Learnt from Millions of Scientific Papers with <i>P<\/i> Values? The American Statistician, 73(sup1), 20–25. https://doi.org/10.1080/00031305.2018.1447512\n\n\nKassambara, A. (2020). Ggpubr: ’ggplot2’ based publication ready plots. Retrieved from https://CRAN.R-project.org/package=ggpubr\n\n\nMann, H. B., & Whitney, D. R. (1947). On a test of whether one of two random variables is stochastically larger than the other. Ann. Math. Statist., 18(1), 50–60. https://doi.org/10.1214/aoms/1177730491\n\n\nSaculinggan, M., & Balase, E. A. (2013). Empirical power comparison of goodness of fit tests for normality in the presence of outliers. Journal of physics: Conference series, 435, 012041. IOP Publishing.\n\n\nStigler, S. M., & others. (2007). The epic story of maximum likelihood. Statistical Science, 22(4), 598–620.\n\n\nStudent. (1908). The probable error of a mean. Biometrika, 1–25.\n\n\nTaleb, N. N. (2020). The statistical consequences of fat tails. STEM Academic Press.\n\n\nWelch, B. L. (1947). The generalization of student’s’ problem when several different population variances are involved. Biometrika, 34(1/2), 28–35.\n\n\nWilcoxon, F. (1945). Individual comparisons by ranking methods. Biometrics Bulletin, 1(6), 80–83. Retrieved from http://www.jstor.org/stable/3001968\n\n\nZimmerman, D. W. (1998). Invalidation of parametric and nonparametric statistical tests by concurrent violation of two assumptions. The Journal of Experimental Education, 67(1), 55–68. https://doi.org/10.1080/00220979809598344\n\n\nNão estamos exagerando, quando você aprender o que são os pressupostos de cada técnica estatística vai começar a identificar que muitos artigos por aí não estão nem aí para pressupostos.↩︎\nA Estatística pode ser dividida em dois ramos: a descritiva e a inferencial. A Estatistica inferencial é aquela que gera infêrencias a partir dos dados observados sobre o real fenômeno do processo de geração de dados. É a Estatística que vai dos dados observados para as associações prováveis por de trás daquelas observações.↩︎\nAnálises de séries temporais e análises de dados geoespaciais fazem parte de um projeto futuro nosso.↩︎\nHomenagem a Carl Friedrich Gauss, matemático Alemão que viveu entre 1777 e 1855.↩︎\nPoder estatístico é, para uma certa probabilidade de erro tipo I (\\(\\alpha\\)), 1 menos a probabilidade de erro tipo II (\\(1 - \\beta\\)). Veja mais no conteúdo auxiliar de Tamanho da Amostra.↩︎\nInclusive muitos renomados e citados em abundância em suas áreas.↩︎\nCuidado com essa palavra. Ela é precisa e somente deve ser usada em contextos estatísticos. Significância estatística quer dizer que os dados observados são mais extremos que um alpha prédefinido de que a hipótese nula é verdadeira.↩︎\nEsse conselho é extremamente útil. Por diversas vezes temos alunos que nos procuram com uma pergunta mais ou menos assim: “Professor, o que é o teste de Sobrenome que nunca ouvi falar na minha vida hífen outro sobrenome ainda mais estranho?” Graças a Wikipedia e Google, nós simplesmente vamos atrás da \\(H_0\\) desse teste (busca Google: “sobrenome1-sobrenome2 null hypothesis”) e com isso conseguimos responder ao aluno.↩︎\nProvavelmente receberemos muito hate mail por conta dessa simplificação e falta de formalismo, por favor, caso consigam aprimorar o conteúdo, criem um nova issue no repositório GitHub do conteúdo.↩︎\nA controvérsia da personalidade e vida de Ronald Fisher merece uma nota de rodapé. Suas contribuições, sem dúvida, foram cruciais para o avanço da ciência e da estatística. Seu intelecto era brilhante e seu talento já floresceu jovem: antes de completar 33 anos de idade ele tinha proposto o método de estimação por máxima verossimilhança (maximum likelihood estimation) (Stigler & others, 2007) e também criou o conceito de graus de liberdade (degrees of freedom) ao propor uma correção no teste de chi-quadrado de Pearson (Baird, 1983). Também inventou a Análise de Variância (ANOVA) e foi o primeiro a propor randomização como uma maneira de realizar experimentos, sendo considerado o “pai” dos ensaios clínicos randomizados. Nem tudo é florido na vida de Fisher, ele foi um eugenista e possuía uma visão muito forte sobre etnia e raça preconizando a superioridade de certas etnias. Além disso, era extremamente invariante, perseguindo, prejudicando e debochando qualquer crítico à suas teorias e publicações. O que vemos hoje no monopólio do paradigma Neyman-Pearson com \\(p\\)-valores e hipóteses nulas é resultado desse esforço Fisheriano em calar os críticos e deixar apenas sua voz ecoar.↩︎\nBoa parte dos teoremas matemáticos por trás da Estatística inferencial se baseiam em “convergências em distribuição” que é uma maneira de expressarmos que a media que o tamanho da população tende ao infinito, \\(n \\to \\infty\\), certas variáveis aleatórias convergem para uma certa distribuição. Um belo exemplo é o teorema do limite central. Um bom trabalho que crítica o alicerce da Estatística inferencial ser baseado em convergências quando a população tende ao infinito e propõem adotar alicerces baseados em desigualdades probabilísticas é Taleb (2020).↩︎\nO que é muito comum em 2020s com o advento de Big Data e facilidade de obtenção de dados.↩︎\nUma versão do teste \\(t\\) de Welch é robusta a heterogeneidade de variâncias e permite com que esse pressuposto seja violado.↩︎\nO teste Mann-Whitney também e chamado de teste de Mann–Whitney–Wilcoxon (MWW), teste da soma dos postos de Wilcoxon e teste de Wilcoxon–Mann–Whitney. Por isso o nome da função R para teste de Mann-Whitney é wilcox.test().↩︎\nTeste de Wilcoxon também e conhecido como testes dos postos sinalizados de Wilcoxon.↩︎\n",
      "last_modified": "2020-12-27T11:57:38-03:00"
    },
    {
      "path": "3-ANOVA.html",
      "title": "Untitled",
      "description": "A new article created using the Distill format.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\n\n\n\n",
      "last_modified": "2020-12-27T11:57:38-03:00"
    },
    {
      "path": "4-Correlacoes.html",
      "title": "Untitled",
      "description": "A new article created using the Distill format.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
      "last_modified": "2020-12-27T11:57:38-03:00"
    },
    {
      "path": "5-Regressao_Linear.html",
      "title": "Untitled",
      "description": "A new article created using the Distill format.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
      "last_modified": "2020-12-27T11:57:39-03:00"
    },
    {
      "path": "6-Regressao_Logistica.html",
      "title": "Untitled",
      "description": "A new article created using the Distill format.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
      "last_modified": "2020-12-27T11:57:39-03:00"
    },
    {
      "path": "aux-Dados_Faltantes.html",
      "title": "Untitled",
      "description": "A new article created using the Distill format.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
      "last_modified": "2020-12-27T11:57:40-03:00"
    },
    {
      "path": "aux-Tabelas_para_Publicacao.html",
      "title": "Untitled",
      "description": "A new article created using the Distill format.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
      "last_modified": "2020-12-27T11:57:40-03:00"
    },
    {
      "path": "aux-Tabelas.html",
      "title": "Untitled",
      "description": "A new article created using the Distill format.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
      "last_modified": "2020-12-27T11:57:41-03:00"
    },
    {
      "path": "aux-Tamanho_Amostra.html",
      "title": "Untitled",
      "description": "A new article created using the Distill format.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
      "last_modified": "2020-12-27T11:57:41-03:00"
    },
    {
      "path": "index.html",
      "title": "Estatística com R",
      "description": "Tutoriais de R para a disciplina de Estatística para alunos de Mestrado e Doutorado da UNINOVE\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nPor que R?\nAulas\nConteúdos Principais\nConteúdos Auxiliares\n\nO que esta disciplina não é\nRStudio na Núvem Gratuito\nProfessores\nComo usar esse conteúdo?\nSlides de Apresentação da Disciplina\n\n\nPor que R?\nR é uma linguagem criada por estatísticos para estatísticos. Possui um vasto ecossistema de bibliotecas e é amplamente usado na ciência e em especial nas ciências aplicadas. Fizemos toda uma argumentação de porque você deve usar R aqui ou clicando no banner superior em “Por que R?”.\nAulas\nConteúdos Principais\n\nPara quem gosta de nomenclaturas chiques: Conteúdos curriculares obrigatórios na formação do futuro pesquisador. Aqui estão coisas importantes que você usará nas suas pesquisas.\nComandos Básicos de R\nTeste de Hipóteses e Teste \\(t\\)\nAnálise de Variância (ANOVA)\nCorrelações\nRegressão Linear\nRegressão Logística\nConteúdos Auxiliares\n\nMais nomenclaturas chiques: Conteúdos extracurriculares facultativos na formação do futuro pesquisador. Aqui estão coisas não-essenciais mas que farão sua vida de pesquisador muito mais fácil.\nDados Faltantes\nTamanho de Amostra e Tamanho de Efeito\nComo ler Tabelas Em Estudos Científicos\nTabelas para Publicação\nO que esta disciplina não é\nNão será coberto conteúdos sobre leitura, manipulação e exportação de dados com R. Para isso recomendo fortemente o livro R para Data Science que pode ser encontrado gratuitamente aqui e possui uma versão impressa em português1.\n\n\n\nFigure 1: R for Data Science\n\n\n\nRStudio na Núvem Gratuito\nClique no ícone abaixo para abrir uma sessão do RStudio no Projeto Binder.\n\nProfessores\nProf. Dr. José Eduardo Storopoli - Currículo Lattes - ORCID - josees@uni9.pro.br\nProf. Dr. Leonardo Vils - Currículo Lattes - ORCID - leonardo.vils@uni9.pro.br\nComo usar esse conteúdo?\nEste conteúdo possui licença livre para uso. Caso queira utilizar o conteúdo para um curso ou estudos, por favor colabore nesse repositório quaisquer aprimorações que foram realizadas.\nPara configurar um ambiente local:\nClone o repositório do GitHub: git clone https://github.com/storopoli/Estatistica.git\nAcesse o diretório: cd Estatistica\nInstale os pacotes necessários: Rscript install.R\nSlides de Apresentação da Disciplina2\n\n\n\nfitvids('.shareagain', {players: 'iframe'});\n\nNão temos nada a ver com a Amazon. Caso queira comprar em qualquer outra loja fique à vontade, ou algum sebo… Jeff Bezos nem sabe que nós existimos…↩︎\nGeralmente nossos Slides são extremamente enxutos e o real conteúdo fica na nossa fala e na interatividade da apresentação. Provavelmente você não entenderá nada desses slides, mas a sua experiência conosco apresentando-os deverá ser excepcional.\n\n↩︎\n",
      "last_modified": "2020-12-27T11:57:42-03:00"
    },
    {
      "path": "README.html",
      "author": [],
      "contents": "\n\nContents\nEstatística com R\n\nEstatística com R\n\n\n",
      "last_modified": "2020-12-27T11:57:42-03:00"
    }
  ],
  "collections": []
}
