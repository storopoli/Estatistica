{
  "articles": [
    {
      "path": "0-Por_que_R.html",
      "title": "Por que R?",
      "description": "Vantagens e Desvantagens de R e porque usá-lo.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nR vs Python\nR vs Julia\nVantagens de R\nProdutivo (Análises/hora)\nEficaz (Conseguir usar a ferramenta correta dentre um rol de inúmeras)\nComunicativo (Maioria das ciências aplicadas usam R)\nReplicável e Transparente\n\n\n\nHá tantas linguagens de programação por aí: “Por que devo escolher R?” “E Python?” “Ouvi falar que Python é melhor que R.” “Julia é melhor que Python e R,”… Estas são as diversas perguntas e dúvidas que nos são endereçadas quando começamos a abordar R com alunos e pesquisadores. Se você quer a resposta curta (TL;DR1 como é chamado ultimamente) é esta:\n\nVocê consegue praticar Estatística com qualquer linguagem obscura que dê um suporte mínimo a operações matriciais.\n\n\nAqui usamos Estatística quando nos referimos a disciplina e estatística quando nos referimos a uma métrica dos dados\nEntão, se você quiser “fazer Estatística” com COBOL, LISP ou qualquer outra coisa fique a vontade… Não vamos te impedir. Agora se você quer “fazer Estatística” sendo:\nProdutivo (Análises/hora)\nEficaz (Conseguir usar a ferramenta correta dentre um rol de inúmeras)\nComunicativo (Maioria das ciências aplicadas usam R)\nReplicável (Com as configurações corretas, sua análise sempre será a mesma)\nTransparente (Não tem como se esconder atrás de opensource)\nEntão, acreditamos que o R é a escolha certa.\nPrimeiramente, abordaremos o R versus outras duas linguagens muito usadas para estatística e análise de dados: Python e Julia. E na sequência, explanaremos essas cinco características de R.\nR vs Python\nEssa é uma briga boa. Acreditamos que não há um vencedor. Ambas são muito boas para certos fins. Primeiramente as semelhanças:\nAmbas são linguagens lentas e tudo que é rapido é rodado em C/C++ ou Fortran2 com wrappers convenientes.\nAmbas são amplamente usadas para análise de dados e possuem bibliotecas especializadas para certas operações.\nAmbas possuem uma comunidade ativa de usuários e contribuidores.\nAmbas são opensource e gratuitas3.\nAgora as diferenças. Essa é a parte mais interessante e sem dúvida desencadeia muito hate mail4:\nAmbas são linguagens multi-paradigmas entretanto R oferece mais recurso para a programação funcional, enquanto Python oferece mais recurso para programação orientado a objetos.\nR é feito por estatísticos para estatísticos (ou para quem queira primeiramente fazer análises estatísticas). Dados tabulares e funções estatísticas são “cidadãos de primeira-classe.” Python teve que sofrer (e ainda sofre) muitas gambiarras customizações para conseguirem trabalhar com dados tabulares e funções estatísticas.\nR é mais interoperacional que Python. Com o R conseguimos exportar a aproveitar resultados de uma biblioteca em outra por meio de objetos data.frame. Com o Python, isto é mais complicado e interoperabilidade envolve martelar transformar objetos oriundos de uma biblioteca em classes comuns de Python ou em tipos de arquivos comuns (JSON, CSV etc.)\nR é mais usado pelos cientistas e estatísticos5.\nR possui mais bibliotecas e maneiras de se analisar estatisticamente dados que Python. Maioria das novas inovações em métodos estatísticos oriundos de teses e artigos são também escritos em bibliotecas de R e publicados.\nR não é muito bom para Deep Learning (Aprendizagem Profunda). A maioria dessas bibliotecas são focadas em Python. Mas quando falamos de Machine Learning, tanto R quando Python possuem o mesmo potencial.\nR não tem list comprehension (compreensão de listas), enquanto Python tem.\n\nQuando falamos Deep Learning estamos no referindo à Redes Neurais com diversas camadas. E Machine Learning à modelos estatísticos que o intuito é poder preditivo.\nR vs Julia\nCom as grandes diferenças entre Python e R apresentadas, precisamos falar de Julia. Julia é uma linguagem nova oriunda do MIT que está sendo muito usada para computação científica. O quê muda com Julia?\nJulia é rápida. E quando eu digo rápida, eu quero dizer bem rápida. Julia trabalha em cima do LLVM(Low Level Virtual Machine) que é um compilador universal e usa uma abordagem JIT (Just-in-Time) de compilação de código que faz com que seja às vezes 100x mais rápida que R ou Python para algumas operações6.\nJulia permite usarmos caracteres unicode como variáveis no código. Isso quer dizer que eu consigo escrever em Julia algo como µ = 0 e em Python/R seria escrito mu = 0. Para matemáticos e cientistas isso permite com o que o código fique mais inteligível.\nJulia ainda é muito nova e não há bibliotecas para todas as coisas que conseguimos fazer com Python e R.\nJulia, assim como Python, possui list comprehension (compreensão de listas).\nJulia é uma linguagem que estamos olhando de maneira promissora. Ela é rápida, já é adotada pela comunidade científica, possui um paradigma funcional e permite uma melhor inteligibilidade do código ao permitir o uso de caracteres unicode e símbolos matemáticos7.\nA principal lacuna que a linguagem Julia tenta solucionar é o paradigma das duas linguagens. Esse paradigma é como os desenvolvedores de algoritmos e softwares de análise desenvolvem suas funcionalidades. Primeiro o código é escrito em uma linguagem de fácil entendeimento e rápida prototipagem como R ou Python. Então, o código do protótipo é testado com um problema pequeno ou com uma fração dos dados que serão utilizados pela solução final. Somente após averiguar que o protótipo funciona da maneira correta, é que os desenvolvedores partem para uma linguagem mais robusta e rápida, mas de implementação demorada como C++ ou Fortran. Julia serve para eliminar esse paradigma e ser a linguagem usada tanto para prototipagem quando para implementação.\nAcreditamos que ainda é necessário no mínimo 5 anos para sabermos qual será o real potencial da linguagem Julia. O nosso conselho é usar R para suas análises estatísticas e considerar Julia se precisar de algo mais incomum que necessite de computação intensa que não tenha ainda uma implementação rápida em R ou Python (usando C/C++ ou Fortran).\nVantagens de R\nCom essas diferenças e semelhanças com Python e Julia, é hora de retornarmos aquelas cinco características que mostramos.\nProdutivo (Análises/hora)\nCom R, conseguimos nos aproveitar do paradigma de programação funcional e sermos mais produtivos (além que o código fica muito mais inteligível). Veja um exemplo abaixo com R e Python. Estamos pegando um dataset chamado mtcars que possui informações sobre alguns carros. Aqui serão feitas algumas operações sequenciais:\nTransformar variáveis que contém texto em variáveis categóricas8\nFiltrar somente as observações que tenham hp maior que 100\nCalcular a média somente para as variáveis númericas\nPrimeiro o R, veja como o código é muito mais sucinto e simples de ler. O pipe %>% significa “pegue o resultado dessa operação e jogue como input da próxima.” Aqui estamos usando o pacote {dplyr} do {tidyverse}.\n\n\nmtcars %>%\n  mutate_if(is.character, as.factor) %>%\n  filter(hp > 100) %>%\n  summarise_if(is.numeric, mean)\n\n\n\nAgora com Python usando a biblioteca {pandas}. Como a lógica de Python é orientada a objetos eu tenho que acessar as funções e atributos de um objeto usando um ponto . após o objeto. Exemplos: objeto.atributo ou objeto.funcao(). Aqui estou fazendo diversas operações em um objeto chamado mtcars que é o nosso dataset. Quase todas operações do {pandas} em um dataset resultam em um novo dataset transformado. Aqui é muito mais complicado porque eu preciso encadear diversas operações usando funções de um objeto. Sem o paradigma funcional (e em especial o pipe %>%) o código fica muito mais verboso e não tão inteligível.\n\nmtcars.select_dtypes(\n  ['object']).apply(\n    lambda x: x.astype('category')).query(\n      'hp > 100').select_dtypes(\n        ['number']).mean()\n\nNós preferimos usar o R para manipular e transformar dados, não só porque a síntaxe é melhor, mas também porque há muito mais funções e operações criadas para diversos tipos de manipulações. No universo das bibliotecas do {tidyverse} temos os chamados core packages:\n{readr} – Leitura de dados de diversos tipos de arquivos\n{tidyr} – Coerção de dados em formatos diversos para um formato tabular\n{dplyr} – Manipulação e transformação de dados tabulares\n{ggplot2} – Gráficos\n{stringr} – Manipulação de dados textuais\n{forcats} – Manipulação de dados qualitativos\n{purrr} – Programação funcional\nAlém disso, há as bibliotecas auxiliares\n{readxl} – Leitura de dados de tabelas Excel\n{haven} – Leitura de dados de tabelas SPSS e Stata\n{DBI} e {dbplyr} – Leitura de dados de Banco de Dados e tradução de operações usando linguagem R e verbos do {tidyverse}9 em operações usando linguagem SQL\n{rvest} e {httr} – Raspagem de dados da Web\nTodas esses bibliotecas rodam em C/C++ e por isso são bem rápidos e eficientes. Além disso, vale a pena mecionar todo o universo {tidymodels} que é um ecossistema para modelagem e machine learning com R.\nEficaz (Conseguir usar a ferramenta correta dentre um rol de inúmeras)\nAtualmente o CRAN10 possui um total de 17,084 bibliotecas11. Todas opensource e gratuitas. Quase toda grande inovação em Estatística em diversos campos são publicadas como bibliotecas de R. A incorporação de novas ferramentas ao rol do estatístico no ecossistema do R é muito mais simples e fácil por conta da interoperabilidade proporcionada pelo objeto universal básico de R que é o data.frame. Tal funcionalidade é incorporada na linguagem em si, qualquer versão de R (desde os primórdios da década de 90) já tinha esse objeto para representar dados tabulares.\nAlém de bibliotecas para análises de dados e Estatística de maneira geral. Temos ecossistemas e bibliotecas para campos distintos como por exemplo12:\nEstatística Bayesiana\nEnsaios Clínicos\nFinanças\nEconomia\nDados Geospaciais\nAnálise de Sobrevivência\nSéries Temporais\nGenoma e Genética\nConstrução e Validação de Escalas\nComunicativo (Maioria das ciências aplicadas usam R)\nDurante o processo de avaliação-por-pares que as publicações científicas passam para serem publicadas, muitos editores e revisores pedem aos autores que submetam ou mostrem o código usado para analisar os dados. Isto é feito para averiguar se a análise foi feita de maneira correta. E a maioria dessas análises no mundo das ciências aplicadas, em especial a área de ciências sociais aplicadas13, usam o R.\nAlém disso, com a biblioteca {rmarkdown} e seus diversos templates, é possível criar diversos tipos de documentos14:\nDocumentos:\nHTML com CSS usando Bootstrap\nPDF\nWord\nRTF\nODT\n\nApresentações (slides):\nioslides\nBeamer\nSlidy\nPowerPoint\n\nArtigos formatados para certos periódicos usando os templates da biblioteca {rticles}\nDashboards\nLivros\nWebsites\nBlogs\nCurriculum Vitae\nReplicável e Transparente15\nA ciência está passando por uma crise de credibilidade que no fundo é também uma crise de replicabilidade. Um livro muito que recomendamos para entender esta crise da ciência é o “Science Fictions: How Fraud, Bias, Negligence, and Hype Undermine the Search for Truth” de Stuart Ritchie (Ritchie, 2020)16. Uma das vantagens do R é que com o mesmo código e o mesmo conjunto de dados, dois usuários conseguem chegar na mesma análise e resultados. Claro que R não soluciona todo o problema de replicabilidade da ciência. Mas, código aberto, e se possível, dados abertos, já ajudam bastante…\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS Medicine, 2(8), e124.\n\n\nRitchie, S. (2020). Science fictions: Exposing fraud, bias, negligence and hype in science. Random House.\n\n\nToo Long, Didn’t Read, traduzindo Muito Grande, Não Li↩︎\nSciPy roda em C/C++ e Fortran, NumPy em C/C++, todo o tidyverse roda em C++, etc↩︎\nÓbvio, mas é bom enfatizar.↩︎\nNotem que estas são nossas opiniões. E como não casamos com opiniões, casamos com fatos (afinal somos estatísticos): uma vez que os fatos mudam, nossas opiniões mudarão de acordo.↩︎\nClaro que em alguns campos (ex: ciências da computação), Python é muito mais utilizado.↩︎\nQuando Python e R usam C/C++ ou Fortran essa vantagem cai bastante ou é inexistente.↩︎\nPara o leitor isso não pode fazer diferença. Mas quando você, por exemplo, quer pegar um algoritmo descrito matematicamente em um artigo e implementá-lo diretamente em código, esses caracteres matemáticos são muito bem-vindos. Palavras de quem já escreveu um algoritmo de Amostragem Monte Carlo usando correntes Markov na mão (não por falta de opção, mas por busca de sinestesia para melhor aprendizagem).↩︎\nVariáveis categóricas são conhecidas como factors no R e são maneiras eficientes de manipular e armazenar dados não-numéricos. Geralmente dados não-numéricos são dados textuais ou alguma chave de identificação única (tipo um id).↩︎\nAqui você já viu alguns em ação: mutate(), filter() e summarise()↩︎\nCRAN – Comprehensive R Archive Network, repositório global de bibliotecas de R.↩︎\nDados de 11/02/21.↩︎\nPara ver uma lista curada pelo CRAN de bibliotecas por assunto vá em CRAN Task Views.↩︎\nDa qual, nós somos oriundos.↩︎\nEste documento é um exemplo. Usamos a biblioteca {distill} que é focada para escrita científica e técnica.↩︎\nNão é uma característica única do R, mas de qualquer linguagem que possua suporte básico a análise e manipulação de dados.↩︎\nHá um metacientista (cientista que estuda a ciência) chamado John Ioannidis que possui diversas publicações interessantes sobre a crise atual da ciência. Em especial, há um artigo de 2005 intitulado “Why Most Published Research Findings Are False” publicado na PLOS Medicine (Ioannidis, 2005) que merece atenção do leitor.\n\n↩︎\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "1-Comandos_Basicos.html",
      "title": "Comandos Básicos de R",
      "description": "Introdução ao R e aos comandos básicos do R.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nLendo Arquivos de Dados\nCSV\nExcel\n\nGráficos\nAmbiente\n\n\nEste arquivo é um documento R Markdown. Ele é uma proposta de prosa com código em R, além de ser o formato preferido nosso de comunicar nossas análises. Quando renderizamos o documento no formato desejado. Todo código que é inserido nele é executado e as saídas são incorporadas no documento final. Isto vale para tabelas e gráficos. Por exemplo, podemos pedir para o R imprimir algo com a função print() e o resultado será o código que foi executado e o seu resultado.\n\n\nprint(\"Você executou um código\")\n\n\n[1] \"Você executou um código\"\n\nO formato R Markdown é muito flexível. Podemos fazer relatórios (em PDF, Word e HTML), apresentações (em PDF, PowerPoint e HTML), artigos acadêmicos, livros, websites1, blogs, CVs, etc.\n\nO site do primeiro autor foi feito usando a biblioteca {postcars} de R. O CV também foi feito em R usando a biblioteca {vitae}.\nLendo Arquivos de Dados\nCom o R conseguimos ler diversos tipo de arquivos de dados: CSV, texto, HTML, Excel, Stata, SPSS, Planilhas Google, Banco de Dados Relacionais, entre outros… Vamos demonstrar como ler arquivos de dados dos dois formatos mais comuns: CSV e Excel.\nCSV\nPara ler um arquivo CSV (.csv) no R execute a função read.csv() para arquivos CSV formato americano (vírgula como separador e decimais como ponto) ou a função read.csv2() para arquivos CSV formato europeu/brasileiro (ponto-e-vírgula como separador e decimais como vírgula). Não esqueça de designar a leitura para uma variável com o designador <-.\n\n\ndf <- read.csv2(\"datasets/mtcars.csv\", row.names = 1)\nhead(df)\n\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\nExcel\nPara ler um arquivo Excel (.xls ou .xlsx) no R é necessário importar um pacote chamado readxl que contem a função read_excel. Para importar um pacote no R executamos o comando library() com um argumento único sendo o nome do pacote. Caso não tenha o pacote instalado, deve instalar ele com o comando install.packages(). Não esqueça de colocar o nome do pacote entre aspas \"nome_do_pacote\" dentro do parênteses da função.\n\n\n# install.packages(\"readxl\")\nlibrary(readxl)\ndf <- read_excel(\"datasets/mtcars.xlsx\")\nhead(df)\n\n\n[90m# A tibble: 6 x 12[39m\n  ...1       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n  [3m[90m<chr>[39m[23m    [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m\n[90m1[39m Mazda R…  21       6   160   110  3.9   2.62  16.5     0     1     4\n[90m2[39m Mazda R…  21       6   160   110  3.9   2.88  17.0     0     1     4\n[90m3[39m Datsun …  22.8     4   108    93  3.85  2.32  18.6     1     1     4\n[90m4[39m Hornet …  21.4     6   258   110  3.08  3.22  19.4     1     0     3\n[90m5[39m Hornet …  18.7     8   360   175  3.15  3.44  17.0     0     0     3\n[90m6[39m Valiant   18.1     6   225   105  2.76  3.46  20.2     1     0     3\n[90m# … with 1 more variable: carb [3m[90m<dbl>[90m[23m[39m\n\nGráficos\nGeralmente no R você pode plotar mostrar graficamente diversos objetos com o comando plot(). Quando você plota um dataset (conjunto de dados lido de um aquivo), o R retorna um gráfico chamado Pair Plot:\nNa diagonal: nome da variável (coluna do dataset)\nFora da diagonal: um gráfico de dispersão entre a variável no eixo horizontal e a variável no eixo vertical\nExemplo: na figura 1 veja a relação entre disp (cilindrada) e hp (cavalos de potência). Ela é uma relação positiva. Quanto maior disp maior hp.\n\n\nplot(mtcars)\n\n\n\n\nFigure 1: Pair Plot do dataset mtcars\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] readxl_1.3.1\n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.6        highr_0.8         cellranger_1.1.0 \n [4] compiler_4.0.3    pillar_1.4.7      tools_4.0.3      \n [7] digest_0.6.27     downlit_0.2.1     lubridate_1.7.9.2\n[10] jsonlite_1.7.2    evaluate_0.14     tibble_3.0.6     \n[13] lifecycle_0.2.0   lattice_0.20-41   pkgconfig_2.0.3  \n[16] rlang_0.4.10      Matrix_1.2-18     cli_2.3.0        \n[19] rstudioapi_0.13   distill_1.2       yaml_2.2.1       \n[22] xfun_0.21         stringr_1.4.0     xml2_1.3.2       \n[25] knitr_1.31        generics_0.1.0    vctrs_0.3.6      \n[28] rprojroot_2.0.2   grid_4.0.3        reticulate_1.18  \n[31] glue_1.4.2        fansi_0.4.2       rmarkdown_2.6    \n[34] bookdown_0.21     magrittr_2.0.1    htmltools_0.5.1.1\n[37] ellipsis_0.3.1    assertthat_0.2.1  utf8_1.1.4       \n[40] stringi_1.5.3     crayon_1.4.1     \n\n\nesse website foi todo feito com R↩︎\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "2-p-valores.html",
      "title": "p-Valores, Hipótese Nula e Pressupostos",
      "description": "Porque $p$-valor, hipótese nula e pressupostos são importantes.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nEstatística Inferencial\n\\(p\\)-valor e Hipótese Nula \\(H_0\\)\nAlgumas questões históricas\nO que o \\(p\\)-valor não é\nIntervalos de Confiança\nSignificância Estatística vs Significância Prática\n\nErro Tipo I e Erro Tipo II\nTamanho da Amostra\nPressupostos\nIndependência dos Dados\nNormalidade\nHomogeneidade das Variâncias\n\nCorrelação versus Causalidade\nComentários Finais\nAmbiente\n\n\nEsse conteúdo foi criado com o intuito de despertar o leitor para a importância da Estatística para a ciência e geração de conhecimento. Nossa ideia é apresentar conceitos da maneira que gostaríamos de ter sido apresentados quando alunos prestes a serem iniciados na ciência. Nossa abordagem é simplificar os conceitos o máximo possível sem perder a sua essência. E, quando necessário, aliando-os com sua trajetória histórica para compreensão do “porque as coisas são como são.” Não estamos atrás de formalismo matemático, mas sim de conseguir desenvolver uma intuição clara do que é cada conceito, quando se deve usá-lo e quais são os principais cuidados que se deve ter.\nA estatística é dividida em duas partes:\nEstatística Descritiva: Sumariza e quantifica as características de uma amostra de dados observados. Métricas comuns são: média, mediana, moda, desvio padrão, variância, correlação, percentis.\nEstatística Inferencial: Permite gerar inferências (afirmações) a partir de um conjunto de uma amostra de dados observados sobre real processo de geração de dados (população). Há diversas maneiras de se gerar tais inferências, mas os principais são os testes de hipóteses clássicos que usam uma hipótese nula \\(H_0\\) pré-especificada. A figura 1 mostra a relação entre dados observados e o processo de geração de dados sob a ótica da probabilidade e da estatística.\n\n\n\n{\"x\":{\"diagram\":\"\\n digraph estatistica_inferencial {\\n  forcelabels = true;\\n  graph [overlap = false,\\n         fontsize = 12,\\n         rankdir = TD]\\n  node [shape = oval,\\n        fontname = Helvetica]\\n  A [label = \\\"Processo de\\nGeração de Dados\\\"]\\n  B [label = \\\"Dados\\nObservados\\\"]\\n  A -> B [dir = forward,\\n          xlabel = \\\"  Probabilidade  \\\",\\n          tailport = \\\"e\\\",\\n          headport = \\\"e\\\"]\\n  B -> A [dir = backward,\\n          label = \\\"  Inferência  \\\",\\n          tailport = \\\"w\\\",\\n          headport = \\\"w\\\"]\\n}\\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nFigure 1: Estatística Inferencial\n\n\n\nEstatística Inferencial\nO nosso intuito nesse conjunto de tutoriais é focar na Estatística inferencial, porque, ao contrário da Estatística descritiva, a Estatística inferencial é raramente compreendida ao ponto do usuário e consumidor estarem aptos à realizar e consumir análises, respectivamente.\nA Estatística inferencial têm suas origens no final do século XIX, especialmente no trabalho de Karl Pearson1 e se baseia em um conjunto de técnicas e procedimentos para testar hipóteses sobre uma amostra generalizando para uma população-alvo.\n\n\n\nFigure 2: Karl Pearson. Figura de https://www.wikipedia.org\n\n\n\nA chave para compreensão da Estatística inferencial se baseia em entender os testes de hipóteses, também chamado de testes estatísticos. Todos testes estatísticos2 segue o mesmo padrão universal (Downey, 2016):\nCalculamos uma estatística da amostra. Aqui estatística (em letras minúsculas) significa uma medida dos dados. Para fins de exemplo vamos chamar essa medida de \\(\\delta\\) (letra grega delta). Essa é a medida que mais nos importamos: uma diferença de média, mediana ou proporções, entre outras…\nContrastamos essa estatística observada com uma estatística computada se o efeito fosse nulo. Em outras palavras, o que observamos é comparado com o resultado que esperaríamos caso estivéssemos vivendo em um mundo no qual essa medida (diferença de média, mediana ou proporções, …) fosse nula (zero). Geralmente esse universo paralelo no qual o efeito observado é zero ou nulo é chamado de Hipótese Nula e é representada com o seguinte símbolo \\(H_0\\). A estatística \\(\\delta\\) no mundo da \\(H_0\\) não é calculada, mas sim dada por um valor que fora matematicamente provado como o valor de \\(\\delta\\) no mundo da \\(H_0\\). Vamos chamar esse valor de \\(\\delta_0\\)\nCalculamos a probabidalide de obtermos algo como \\(\\delta\\) no mundo da \\(H_0\\): chamamos isso de \\(p\\)-valor. O \\(p\\)-valor é a probabilidade de observarmos um \\(\\delta\\) no mínimo tão grande quanto o observado num mundo no qual não há o efeito \\(\\delta\\). Ou seja \\(\\delta = 0\\), e consequentemente \\(\\delta = \\delta_0\\). Como sabemos do valor \\(\\delta_0\\) de antemão, basta compararmos o nosso \\(\\delta\\) com \\(\\delta_0\\) para gerar o \\(p\\)-valor. Por isso que muitos livros de Estatística possuem um vasto arsenal de tabelas. O leitor pode facilmente ver o seu \\(\\delta\\) e com alguns dados sobre a amostra, em especial o número da amostra, obter o \\(\\delta_0\\) e \\(p\\)-valor respectivos.\nDecidimos se \\(\\delta\\) possui significância estatística. Escolhemos um limiar de rejeição da \\(H_0\\), muitas vezes chamado de \\(\\alpha\\) (letra grega alpha). Esse limiar será o nosso critério de decisão se há evidências suficientes para rejeitarmos o mundo da \\(H_0\\).\nEste paradigma descrito nos quatro passos acima é chamado de Null Hypothesis Significance Testing – NHST (tradução: teste de significância de hipótese nula) e é o que predomina em grande parte da ciência do passado e atual.\nUma segunda chave para a compreensão da Estatística inferencial possui razões históricas. As técnicas de Estatística inferencial clássicas são em grande parte um mecanismo técnico de aproximações numéricas baseadas na distribuição Normal e suas muitas engrenagens subsidiárias. Essa máquina já foi necessária, porque a alternativa conceitualmente mais simples baseada em permutações estava computacionalmente além de nosso alcance3. Antes dos computadores, os estatísticos não tinham escolha (Cobb, 2007).\n\nQuem ficou curioso com a história da Estatística. Recomendo um livro de Stephen Stigler intitulado Statistics on the Table: The History of Statistical Concepts and Methods. O primeiro autor comprou uma cópia em um sebo online.\n\\(p\\)-valor e Hipótese Nula \\(H_0\\)\n\n\\(p\\)-valores são de difícil entendimento, \\(p < 0.05\\).\n\n\n\n\nSem dúvida, esta parte da Estatística inferencial é a mais complicada e menos intuitiva. Parafraseando Andrew Gelman, estatístico da Columbia University, “Para definir \\(p\\)-valores, escolha uma das duas características: intuitiva ou precisa. Ou sua definição é intuitiva mas imprecisa, ou sua definição é precisa mas não intuitiva.” A grande maioria dos pesquisadores4 possui uma definição incorreta do que é um \\(p\\)-valor (Cumming, 2009). E quando vemos evidências do campo da medicina, que talvez seja o campo com maior quantidade de recursos disponíveis para pesquisa e avanço do conhecimento, também encontramos muitos problemas no uso dos \\(p\\)-valores (Ioannidis, 2019). Antes de entrarmos nas definições de \\(p\\)-valores, vale a pena tranquilizá-los: \\(p\\)-valores são uma coisa complicada e se você não entender na primeira vez que ler as definições abaixo, não se preocupe, você não estará em má companhia; respire fundo e tente ler mais uma vez.\nPrimeiramente a definição estatística:\n\n\\(p\\)-valor é a probabilidade de obter resultados no mínimo tão extremos quanto os que foram observados, dado que a hipótese nula \\(H_0\\) é verdadeira.\n\nSe você escrever essa definição em qualquer prova, livro ou artigo científico, você estará 100% preciso e correto na definição do que é um \\(p\\)-valor. Agora, a compreensão dessa definição é algo complicado. Para isso, vamos quebrar essa definição em algumas partes para melhor compreensão:\n“probabilidade de obter resultados…”: vejam que \\(p\\)-valores são uma característica dos seus dados e não da sua teoria ou hipótese.\n“…no mínimo tão extremos quanto os que foram observados…”: “no minimo tão” implica em definir um limiar para a caracterização de algum achado relevante, que é comumente chamado de \\(\\alpha\\). Geralmente estipulamos alpha em 5% (\\(\\alpha = 0.05\\)) e qualquer coisa mais extrema que alpha (ou seja menor que 5%) caracterizamos como significante5.\n“..dado que a hipótese nula é verdadeira…”: Todo teste estatístico que possui um \\(p\\)-valor possui uma Hipótese Nula (geralmente escrita como \\(H_0\\)). Hipótese nula, sempre tem a ver com algum efeito nulo. Por exemplo, a hipótese nula do teste Shapiro-Wilk e Komolgorov-Smirnov é “os dados são distribuídos conforme uma distribuição Normal” e a do teste de Levene é “as variâncias dos dados são iguais.” Sempre que ver um \\(p\\)-valor, se pergunte: “Qual a hipótese nula que este teste presupõe correta?6”\nPara entender o \\(p\\)-valor qualquer teste estatístico primeiro descubra qual é a hipótese nula por trás daquele teste. A definição do \\(p\\)-valor não mudará. Em todo teste ela é sempre a mesma. O que muda com o teste é a hipótese nula. Cada teste possui sua \\(H_0\\).\n\n\n\n\\(p\\)-valor é a probabilidade dos dados que você obteve dado que a hipótese nula é verdadeira. Para os que gostam do formalismo matemático: \\(p = P(D|H_0)\\). Em português, essa expressão significa “a probabilidade de \\(D\\) condicionado à \\(H_0\\).” Antes de avançarmos para alguns exemplos e tentativas de formalizar uma intuição sobre os \\(p\\)-valores, é importante ressaltar que \\(p\\)-valores dizem algo à respeito dos dados e não de hipóteses. Para o \\(p\\)-valor, a hipótese nula é verdadeira, e estamos apenas avaliando se os dados se conformam à essa hipótese nula ou não. Se vocês saírem desse tutorial munidos com essa intuição, o mundo será agraciado com pesquisadores mais preparados para qualificar e interpretar evidências (\\(p < 0.05\\)).\nExemplo intuitivo:\n\nImagine que você tem uma moeda que suspeita ser enviesada para uma probabilidade maior de dar cara. (Sua hipótese nula é então que a moeda é justa.) Você joga a moeda 100 vezes e obtém mais cara do que coroa. O \\(p\\)-valor não dirá se a moeda é justa, mas dirá a probabilidade de você obter pelo menos tantas caras quanto se a moeda fosse justa. É isso - nada mais.\n\n\nApesar de termos falado anterior que definições intuitivas não são precisas, elas sem dúvida facilitam o entendimento do \\(p\\)-valor.\nAlgumas questões históricas\nNão tem como entendermos \\(p\\)-valores se não compreendermos as suas origens e trajetória histórica. A primeira menção do termo foi feita pelo estatístico Ronald Fisher7 em 1925 (Fisher, 1925) que define o \\(p\\)-valor como um “índice que mede a força da evidência contra a hipótese nula.” Para quantificar a força da evidência contra a hipótese nula, Fisher defendeu “\\(p<0.05\\) (5% de significância) como um nível padrão para concluir que há evidência contra a hipótese testada, embora não como uma regra absoluta.” Fisher não parou por aí mas classificou a força da evidência contra a hipótese nula. Ele propôs “se \\(p\\) está entre 0.1 e 0.9, certamente não há razão para suspeitar da hipótese testada. Se estiver abaixo de 0.02, é fortemente indicado que a hipótese falha em explicar o conjunto dos fatos. Não seremos frequentemente perdidos se traçarmos uma linha convencional de 0.05” Desde que Fisher fez esta declaração há quase 100 anos, o limiar de 0.05 foi usado por pesquisadores e cientistas em todo o mundo e tornou-se ritualístico usar 0.05 como limiar como se outros limiares não pudessem ser usados.\n\n\n\nFigure 3: Ronald Fisher. Figura de https://www.wikipedia.org\n\n\n\nApós isso, o limiar de 0.05 agora instaurado como inquestionável influenciou fortemente a estatística e a ciência. Mas não há nenhuma razão contra a adoção de outros limiares (\\(\\alpha\\)) como 0.1 ou 0.01. Se bem argumentados, a escolha de limiares diferentes de 0.05 pode ser bem-vista por editores, revisores e orientadores. Como o \\(p\\)-valor é uma probabilidade, ele não é um quantidade contínua. Não há razão para diferenciarmos um \\(p\\) de 0.049 contra um \\(p\\) de 0.051. Robert Rosenthal, um psicólogo já dizia “Deus ama \\(p\\) de 0.06 tanto quanto um \\(p\\) de 0.05” (Rosnow & Rosenthal, 1989).\n\n\n\nO que o \\(p\\)-valor não é\nCom a definição e intuição do que é um \\(p\\)-valor bem ancoradas, podemos avançar para o que o \\(p\\)-valor não é!\n\n\n\n\\(p\\)-valor não é a probabilidade da Hipótese nula - Famosa confusão entre \\(P(D|H_0)\\) e \\(P(H_0|D)\\). \\(p\\)-valor não é a probabilidade da hipótese nula, mas sim a probabilidade dos dados que você obteve. Por exemplo: a probabilidade de você tossir dado que você está com COVID é diferente da probabilidade de você estar com COVID dado que você tossiu: \\(P(\\text{tosse} | \\text{COVID}) \\neq P(\\text{COVID} | \\text{tosse})\\). Acredito que a primeira, \\(P(\\text{tosse} | \\text{COVID})\\) é bem alta, enquanto a segunda, \\(P(\\text{COVID} | \\text{tosse})\\) deve ser bem baixa (afinal tossimos a todo momento).\n\nO primeiro autor tentou explicar essa diferença para uma senhora que o viu tossir na fila do mercado, mas os seus esforços foram em vão…\n\\(p\\)-valor não é a probabilidade dos dados serem produzidos pelo acaso - Não! Ninguém falou nada de acaso. Mais uma vez: \\(p\\)-valor é probabilidade de obter resultados no mínimo tão extremos quanto os que foram observados, dado que a hipótese nula é verdadeira.\n\\(p\\)-valor mensura o tamanho do efeito de um teste estatístico - Também não… \\(p\\)-valor não diz nada sobre o tamanho do efeito. Apenas sobre se o quanto os dados observados divergem do esperado sob a hipótese nula. É claro que efeitos grandes são mais prováveis de serem estatisticamente significantes que efeitos pequenos. Mas isto não é via de regra e nunca julguem um achado pelo seu \\(p\\)-valor, mas sim pelo seu tamanho de efeito. Além disso, \\(p\\)-valores podem ser “hackeados” de diversas maneiras (Head, Holman, Lanfear, Kahn, & Jennions, 2015) e muitas vezes seu valor é uma consequência direta do tamanho da amostra. Mais sobre isso no conteúdo auxiliar sobre tamanho de amostra.\nIntervalos de Confiança\nIntervalos de confiança foram criados como uma solução para os problemas de má-interpretação dos \\(p\\)-valores e sua aplicação se destina ao tamanho do efeito. Se você achou \\(p\\)-valor confuso, se prepare! Intervalos de confiança são ainda mais confusos e muitos pesquisadores e cientistas também não possuem a compreensão correta (Hoekstra, Morey, Rouder, & Wagenmakers, 2014)8…Vamos para a definição estatística do idealizador dos intervalos de confiança, Jerzy Neyman, em 1937 (Neyman, 1937):\n\n“Um intervalo de confiança de X% para um parâmetro é um intervalo (a, b) gerado por um procedimento que em amostragem repetida tem uma probabilidade de X% de conter o valor verdadeiro do parâmetro, para todos os valores possíveis do parâmetro.”9 (Neyman, 1937)\n\nMais uma vez vamos quebrar essa definição em em algumas partes para melhor compreensão:\n“… intervalo (a,b) …”: intervalo de confiança sempre serão expressados como um intervalo \\(a\\) - \\(b\\), onde \\(a\\) é menor que \\(b\\) (\\(a < b\\)).\n“… gerado por um procedimento que em amostragem repetida…”: aqui estamos falando de população. E o que você geralmente tem nas suas mãos quando está fazendo uma análise estatística é uma amostra. Uma população é um conjunto de pessoas, itens ou eventos sobre os quais você quer fazer inferências. Uma amostra é um é um subconjunto de pessoas, itens ou eventos de uma população maior que você coleta e analisa para fazer inferências. Geralmente o tamanho da amostra é bem menor que o tamanho da população. Então, intervalos de confiança expressam a frequência de longo-prazo que vocês esperaria obter de um tamanho de efeito caso replicasse o teste estatístico para diversas amostras da MESMA população.\n“… tem uma probabilidade de X% de conter o valor verdadeiro do parâmetro, para todos os valores possíveis do parâmetro.”: os intervalos de confiança sempre serão expressados acompanhados de uma probabilidade (algo entre 0.001% e 99.999%) que quantifica a certeza de encontrar o intervalo em uma replicações do teste estatístico para diversas amostras da MESMA população.\nPor exemplo: digamos que você executou uma análise estatística para comparar eficácia de uma política pública em dois grupos e você obteve a diferença entre a média desses grupos. Você pode expressar essa diferença como um intervalo de confiança. Geralmente escolhemos a confiança de 95% (sim, está relacionado com o 0.05 do \\(p\\)-valor). Você então escreve no seu artigo que a “diferença entre grupos observada é de 10.5 - 23.5 (95% IC).” Isso quer dizer que 95 estudos de 100, que usem o mesmo tamanho de amostra e população-alvo, aplicando o mesmo teste estatístico, esperarão encontrar um resultado de diferenças de média entre grupos entre 10.5 e 23.5. Aqui as unidades são arbitrárias, mas para continuar o exemplo vamos supor que sejam expectativa de vida.\nFalácias\nEm um artigo bem controverso, Morey, Hoekstra, Rouder, Lee, & Wagenmakers (2016) mostram as três grandes falácias (qualquer enunciado ou raciocínio falso que entretanto simula a veracidade) dos intervalos de confiança (a tradução é livre e feita por nós):\nA falácia fundamental dos intervalos de confiança: Um intervalo de confiança de X% para um parâmetro é um intervalo (a, b) gerado por um procedimento que na amostragem repetida tem uma probabilidade de X% de conter o valor verdadeiro do parâmetro, para todos os valores possíveis do parâmetro. A probabilidade de que um intervalo aleatório contém o valor verdadeiro é X%, então a plausibilidade ou probabilidade de que um determinado intervalo observado contém o valor verdadeiro também é X%; ou, alternativamente, podemos ter X% de confiança de que o intervalo observado contém o valor real10.\nA falácia da precisão: A largura de um intervalo de confiança indica a precisão de nosso conhecimento sobre o parâmetro. Intervalos de confiança estreitos correspondem a conhecimentos precisos, enquanto erros de confiança amplos correspondem a conhecimentos imprecisos11.\nA falácia da probabilidade: Um intervalo de confiança contém os valores prováveis para o parâmetro. Os valores dentro do intervalo de confiança são mais prováveis do que os externos. Essa falácia existe em várias variedades, às vezes envolvendo plausibilidade, credibilidade ou razoabilidade de crenças sobre o parâmetro12.\nNote que todas essas três falácias estão erradas e são uma compreensão errônea ou incompleta de intervalos de confiança.\nRelação entre intervalos de confiança e \\(p\\)-valores\nIntervalos de confiança estão profundamente relacionados com \\(p\\)-valores. Primeiro, para que uma estimativa tenha um \\(p\\)-valor menor que 0.05, seu intervalo de confiança 95% não pode capturar o zero. Ou seja, o intervalo não pode compreender o efeito nulo (Hipótese Nula - \\(H_0\\)). Isso segue para outros valores de \\(p\\) correspondentes com outros níveis de confiança dos intervalos. Por exemplo, para uma estimativa com \\(p\\)-valor menor que 0.01, seu intervalo de confiança 99% não pode capturar o 0. Além disso, intervalos de confiança (assim como \\(p\\)-valores) estão intrinsicamente conectados com o tamanho da amostra. Quanto maior o tamanho de amostra, mais estreito será o intervalo de confiança. A intuição por trás disso é que conforme a sua amostra aumenta, também aumentarão a sua confiança e precisão em inferências sobre a população-alvo. Por fim, intervalos de confiança (assim como \\(p\\)-valores) não falam nada sobre a sua teoria ou hipótese, mas sobre a relação dos seus dados (amostra) com a população-alvo. Eles não são a probabilidade do parâmetro estimado (\\(P(\\text{parâmetro} | D)\\), no nosso exemplo diferença entre médias de grupos), mas sim a probabilidade de amostras com o mesmo parâmetro estimado (\\(P(D | \\text{parâmetro})\\)).\nUma boa maneira de resumir \\(p\\)-valores e intervalos de confiança é a seguinte:\n\nConsidere \\(p\\)-valores algo que mensura a possibilidade de existir um efeito ou não e intervalos de confiança quantificam o tamanho desse efeito.\n\n\nMas sempre se atente nas definições. Lembre-se que se tentarmos ser intuitivos com \\(p\\)-valores e intervalos de confiança não seremos precisos nas definições.\nSignificância Estatística vs Significância Prática\n\nConsidere isso uma introdução rápida à \\(p\\)-hacking.\nPara encerrar esse tour de \\(p\\)-valores e intervalos de confiança, temos que nos atentar que significância estatística não é a mesma coisa que significância prática. Significância estatística é se algum achado de um teste/modelo estatístico diverge o suficiente da hipótese nula e, sendo que hipótese nula sempre são sobre efeitos ou diferenças nulas, podemos afirmar que significância estatística quer dizer um achado é diferente de um efeito nulo. Diversos testes da Estatística inferencial clássica quando submetidos à amostras grandes13 vão detectar uma diferença significante, mesmo que praticamente insignificante. Com uma amostra suficientemente grande nós conseguimos gerar \\(p\\)-valores significantes para diferenças minúsculas, como por exemplo uma diferença de 0.01cm altura entre dois grupos de uma amostra.\nPor isso que defendemos que nunca se interprete análises estatísticas somente com \\(p\\)-valores, mas sempre em conjunto com os intervalos de confiança que quantificam o tamanho do efeito. Nunca gere argumentos sobre evidências somente a partir de significância estatística, sempre inclua tamanho do efeito.\nErro Tipo I e Erro Tipo II\nNa Estatística inferencial temos dois erros possíveis quando estamos realizando um teste estatístico contra uma hipótese nula.\nErro tipo I, também chamado de “falso positivo”, é a chance de rejeitarmos a hipótese nula quando ela é verdadeira. Esse erro é o alpha \\(\\alpha\\) que é usado como limiar de significância do \\(p\\)-valor.\nErro tipo II, também chamado de “falso negativo”, é a chance de não rejeitarmos a hipótese nula quando ela é falsa. Esse erro é identificado como a letra grega beta \\(\\beta\\). Além disso, o poder de um teste estatístico é mensurado como \\(1 - \\beta\\). O poder de um teste estatístico aumenta proporcionalmente ao tamanho amostral. Quanto maior a amostra, maior o poder do teste.\n\nEsses conceitos foram criados por matemáticos, então a nomenclatura erro tipo I e erro tipo II é perfeita matematicamente, pois no contexto de testes estatísticos contra uma hipótese nula só existem dois tipos de erros. Mas para o ensino da Estatística e comunicação de incertezas é péssima. Sempre que possível optamos por usar termos como “falso positivo” e “falso negativo” ao invés de erro tipo I e erro tipo II.\n\n\n\nPor questões históricas, o erro tipo I14 foi considerado mais importante de ser controlado do que o erro tipo II. Portanto, quase todos os testes de hipótese nula focam no controle dos “falsos positivos” enquanto o controle dos “falsos negativos” são colocados em segundo plano. No mundo ideal, tanto \\(\\alpha\\) quando \\(\\beta\\) devem ser reduzidos o máximo possível. Isto requer um tamanho amostral frequentemente maior do que os recursos disponíveis para o pesquisador, portanto é comum pesquisadores usarem um \\(\\alpha\\) de 5% e um \\(\\beta\\) de 20% (poder de 80%).\nTamanho da Amostra\nA maioria dos testes estatísticos que computam um \\(p\\)-valor são extremamente sensíveis a tamanho da amostra. A hipótese nula sempre representa a ausência de qualquer efeito e nunca a diferença observada na amostra é igual a zero. Sempre há algum digito, menor que seja, que faz com que a diferença seja diferente de zero, ex: 0.00001. Quanto maior o tamanho da amostra maior a probabilidade de obtermos um \\(p\\)-valor significante, pois ele indica que o efeito é diferente de zero, mesmo que essa diferença seja insignificante do ponto de vista prático. Em certos contextos, defendemos que o \\(p\\)-valor é uma aproximação (proxy) de tamanho da amostra.\n\n\n\nPressupostos\nAntes de avançarmos, é necessário clarificar algo que muitos pesquisadores e cientistas não se atentam e acaba invalidando diversas análises15: pressupostos das técnicas estatísticas clássicas. Lembrando que as técnicas estatísticas clássicas são “um mecanismo técnico de aproximações numéricas baseadas na distribuição Normal e suas muitas engrenagens subsidiárias,” e, como consequência, essas aproximações numéricas se baseiam em um forte pressuposto sobre os dados da amostra. Os três principais pressupostos são: independência, normalidade e homogeneidade das variâncias. Se algum desses três pressupostos são violados, é sinal que sua análise requer atenção. Geralmente a escolha de uma técnica que é robusta à certas violações de pressupostos é o caminho ideal a ser trilhado16.\nAlém disso, tamanho da amostra também é um problema comum em análises estatísticas. Tamanho da amostra não é um pressuposto em si17, mas pode invalidar muitas análises e é um dos principais critérios de rejeição de artigos.\n\n\n\nIndependência dos Dados\nPrimeiramente, para quase toda a estatística inferencial, temos o pressuposto de independência dos dados. Isso é válido para teste \\(t\\), ANOVA, regressões, entre outros… O pressuposto de independência dos dados quer dizer que o valor de uma observação não influencia ou afeta o valor de outras observações. Caso você encontre dados que violam esse pressuposto, é necessário de alguma maneira incorporar tal dependência na sua análise18. Fontes comuns de não-independência são19:\nDependência Temporal: O valor de uma observação é influenciado pela dimensão temporal. Muito comum em séries temporais, tais como dados financeiros e econômicos. Nesse caso, o ideal é tentar incluir a dimensão temporal na sua análise.\nDependência Espacial: O valor de uma observação é influenciado pela dimensão espacial. Muito comum em dados geoespaciais e georeferenciados. Aqui, o ideal é incorporar a dimensão espacial na sua análise.\n\nDependência temporal e espacial não são os únicos tipos de dependências que existem nos dados. Se as observações tiverem algum tipo de relação que faz com que uma influencie a outra, considere o pressuposto de independência dos dados violado.\nSe esse pressuposto for violado, as técnicas clássicas de Estatística inferencial não serão válidas na sua análise. Sugerimos que você tente remover a fonte de dependência dos dados, recoletar os dados de maneira que não sejam geradas fontes de dependência, ou empregar técnicas que consigam incorporar a fonte de dependência na análise.\nNormalidade\nDados normais são dados que seguem uma distribuição Normal, também conhecida por distribuição Gaussiana20. Uma variável distribuída como uma distribuição Normal segue aquela forma clássica de sino. Mais especificamente, esse pressuposto de normalidade geralmante se aplica somente à variável dependente. Abaixo um exemplo de variável Normal.\n\nVariável dependente é aquela que estamos interessados na nossa análise. É a variável que se altera conforme outras variáveis (chamadas de independentes) se alteram.\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\ntibble(x = c(-4, 4)) %>%\nggplot(aes(x)) +\n    stat_function(size = 3, col = \"red\", fun = dnorm) +\n  labs(\n    x = NULL,\n    y = NULL\n  )\n\n\n\n\nFigure 4: Distribuição Normal\n\n\n\nComo eu sei que minha variável dependente é Normal?\nMuitos gostam de plotar um gráfico para bisolhar estimar se uma varíavel segue uma distribuição Normal ou não. Somos adeptos de visualizações e usamos constantemente nas nossas análises. Mas, na Estatística, as visualizações são muito boas para mostrar alguma tendência, característica ou peculiaridade dos dados. Agora, para provar algo, é necessário um teste estatístico.\nHá dois testes estatísticos para saber se uma variável é distribuída conforme uma distribuição Normal: Komolgorov-Smirnov e Shapiro-Wilk. Ambos possuem como hipótese nula (\\(H_0\\)) que “os dados são distribuídos conforme uma distribuição Normal.”\nKomolgorov-Smirnov vs Shapiro-Wilk\nAmbos os testes aceitam como input uma variável e dão como output um \\(p\\)-valor. Mas qual usar? Estudos comparativos (Saculinggan & Balase, 2013) de diferentes testes de normalidade demonstram que Shapiro-Wilk é o teste com maior poder estatístico21.\nAbaixo, no R, vamos simular 1.000 observações de uma variável distribuída conforme uma distribuição Normal com média 0 e desvio padrão 1. Além disso, vamos simular também 100 observações de uma variável bem longe de ser distribuída como uma distribuição Normal. Vamos usar uma variável distribuída conforme uma distribuição Log-Normal. Primeiramente, vamos mostrar graficamente as duas distribuições. Como vocês podem na figura 5, a distribuição Normal tem a forma característica de sino e a distribuição Log-Normal tem uma assimetria para a direita com uma cauda mais alongada.\n\n\ntibble(x = c(-8, 8)) %>%\nggplot(aes(x)) +\n  stat_function(size = 3, col = \"red\", fun = dnorm) +\n  stat_function(size = 3, col = \"blue\", fun = dlnorm) +\n  labs(\n    x = NULL,\n    y = NULL\n  )\n\n\n\n\nFigure 5: Distribuição Normal vs Distribuição Log-Normal\n\n\n\nAgora com as simulações! Na figura 6 é possível ver o histograma das distribuições simuladas. Em vermelho temos o histograma das 1.000 amostragens de uma distribuição Normal e, em azul da distribuição Log-Normal.\n\n\nset.seed(123)\nn_sim <- 1000\nsims <- tibble(\n  normal = rnorm(n_sim),\n  log_normal = rlnorm(n_sim)\n)\n\nggplot(sims) +\n  geom_density(aes(normal, fill = \"Normal\"), alpha = 0.5) +\n  geom_density(aes(log_normal, fill = \"Log-Normal\"), alpha = 0.5) +\n  labs(y = NULL, x = NULL) +\n  scale_fill_manual(name = \"Distribuição\", values = c(\"Normal\" = \"red\", \"Log-Normal\" = \"blue\")) +\n  theme(legend.position = \"bottom\")\n\n\n\n\nFigure 6: Histograma das Simulações de Normalidade\n\n\n\nTeste de Shapiro-Wilk\nO teste de Shapiro-Wilk está disponível como padrão no R pela função shapiro.test() que aceita uma variável como input.\n\n\nshapiro.test(sims$normal)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  sims$normal\nW = 0.99838, p-value = 0.4765\n\nshapiro.test(sims$log_normal)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  sims$log_normal\nW = 0.55782, p-value < 2.2e-16\n\nSobre o \\(p\\)-valor que aparece como resultado do teste, \\(p < 0.05\\) (\\(p\\) menor que 0.05) significa fortes evidências de que a variável testada não segue uma distribuição Normal.\n\nEm outras palavras, rejeita-se a hipótese nula \\(H_0\\).\nTeste de Komolgorov-Smirnov\nAdicionalmente mostramos como fazer um teste Komolgorov-Smirnof, também disponível como padrão no R pela função ks.test(). Aqui temos que ser um pouco mais específico pois o teste exige a especificação exata do que se quer comparar. No caso, estamos informando que a distribuição a ser testada contra é uma Normal \"pnorm\" e usamos os valores de média mean() e desvio padrão sd() da variável que estamos testando. Lembrando que a definição do \\(p\\)-valor para este teste é a mesma do Shapiro-Wilk.\n\n\nks.test(sims$normal, \"pnorm\", mean(sims$normal), sd(sims$normal))\n\n\n\n    One-sample Kolmogorov-Smirnov test\n\ndata:  sims$normal\nD = 0.014963, p-value = 0.9786\nalternative hypothesis: two-sided\n\nks.test(sims$log_normal,  \"pnorm\", mean(sims$log_normal), sd(sims$log_normal))\n\n\n\n    One-sample Kolmogorov-Smirnov test\n\ndata:  sims$log_normal\nD = 0.23774, p-value < 2.2e-16\nalternative hypothesis: two-sided\n\nHomogeneidade das Variâncias\nTambém chamado de homocedasticidade, homogeneidade das variâncias é um pressuposto que, para uma dada mensuração, a variação dessa mensuração dentro de estratos/grupos da sua amostra é similar. Em outras palavras, se você possui três grupos de indivíduos e está mensurando a altura, a variação da altura dentre os três grupos não pode ser muito diferentes entre os três grupos.\nUma boa maneira de visualizar isso é usarmos distribuições Normais com diferentes médias e desvio padrões. No caso de homogeneidade das variâncias, conseguimos visualizá-la com três distribuições Normais, sendo que todas possuem o mesmo desvio padrão, mas diferentes médias. Esse seria o gráfico da esquerda na figura 7. Já no caso de heterogeneidade, conseguimos demonstrar usando as mesmas três distribuições Normais mas agora introduzindo diferentes desvios padrões. Esta situação é o gráfico da direita na figura 7\n\n\nlibrary(patchwork)\np1 <- ggplot(data.frame(x = c(-4, 4)), aes(x)) +\n  mapply(function(mean, sd, col) {\n    stat_function(fun = dnorm, args = list(mean = mean, sd = sd), size = 3, col = col)\n  },\n  # enter means, standard deviations and colors here\n  mean = c(0, 1, -1),\n  sd = c(1, 1, 1),\n  col = c(\"red\", \"blue\", \"green\")\n)\n\np2 <- ggplot(data.frame(x = c(-4, 4)), aes(x)) +\n  mapply(function(mean, sd, col) {\n    stat_function(fun = dnorm, args = list(mean = mean, sd = sd), size = 3, col = col)\n  },\n  # enter means, standard deviations and colors here\n  mean = c(0, 1, .5),\n  sd = c(1, .5, 2),\n  col = c(\"red\", \"blue\", \"green\")\n)\n\np1 | p2\n\n\n\n\nFigure 7: Homogeneidade e Heterogeneidade das Variâncias\n\n\n\nHá dois testes estatísticos para saber se uma variável possui variâncias homogêneas conforme seus diferentes grupos ou estratos: Bartlett e Levene. Ambos possuem como hipótese nula (\\(H_0\\)) que “as variâncias dos grupos/estratos são iguais.” O teste de Bartlett é baseado na média dos grupos, portanto é influenciado por observações extremas (também chamadas de outliers). Já o teste de Levene é baseado na mediana dos grupos, o que faz com que seja robusto à outliers. Nós recomendamos que sempre usem o teste de Levene por conta de ser mais robusto que o teste de Bartlett.\nPara mostrarmos ambos os testes, mais uma vez usararemos simulações. Aqui vamos gerar um dataset de 500 observações em dois grupos: A com 250 e B com 250 observações. E vamos considerar dois cenários: o primeiro onde temos médias diferentes entre os grupos mas homogeneidade de variâncias (possuem o mesmo desvio padrão) e o segundo onde temos médias diferentes entre os grupos e com heterogeneidade de variâncias (possuem desvio padrões diferentes). Ambos cenários podem ser visualizados na figura 8.\n\n\nsims2 <- tibble(\n  group = c(rep(\"A\", n_sim / 4), rep(\"B\", n_sim / 4)),\n  homog = c(rnorm(n_sim / 4, 0, 1), rnorm(n_sim / 4, 1, 1)),\n  heterog = c(rnorm(n_sim / 4, 0, 0.1), rnorm(n_sim / 4, 1, 2))\n)\n\np3 <- ggplot(sims2, aes(homog, fill = group)) +\n  geom_density(alpha = 0.5, show.legend = FALSE)\n\np4 <- ggplot(sims2, aes(heterog, fill = group)) +\n  geom_density(alpha = 0.5, show.legend = FALSE)\n\np3 | p4\n\n\n\n\nFigure 8: Histograma das Simulações de Homogeneidade das Variâncias\n\n\n\nTeste de Bartlett\nO teste de Barlett está disponível como padrão no R pela função bartlett.test(). Como estamos trabalhando com um dataset que possui duas variáveis: uma que é a que queremos testar a homogeneidade e outra que representa os grupos ou estratos; geralmente usamos a síntaxe de fórmula no R. A fórmula é designada pela seguinte síntaxe: variavel ~ grupo.\nVocê tem que passar dois argumentos para a função bartlett.test():\nFórmula designando qual variável deve ser analisada a homogeneidade das variâncias em quais grupos.\nO dataset no qual deverá ser encontrados tanto a varíavel quanto os grupos.\n\n\nbartlett.test(homog ~ group, data = sims2)\n\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  homog by group\nBartlett's K-squared = 2.0602, df = 1, p-value = 0.1512\n\nbartlett.test(heterog ~ group, data = sims2)\n\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  heterog by group\nBartlett's K-squared = 1162.1, df = 1, p-value < 2.2e-16\n\nSobre o \\(p\\)-valor que aparece como resultado do teste de Bartlett, \\(p < 0.05\\) (\\(p\\) menor que 0.05) significa fortes evidências de que a variável testada não possui homogeneidade de variâncias para os grupos especificados.\n\nEm outras palavras, rejeita-se a hipótese nula \\(H_0\\).\nTeste de Levene\nO teste de Levene está disponível na biblioteca {car} (Fox & Weisberg, 2019) na função leveneTest() e você tem que passar dois argumentos:\nFórmula designando qual variável deve ser analisada a homogeneidade das variâncias em quais grupos.\nO dataset no qual deverá ser encontrados tanto a varíavel quanto os grupos.\n{car} não tem nada a ver com carros. Ele é um acrônimo para “Companion to Applied Regression” e é uma biblioteca com funções para acompanhar um livro intitulado “An R Companion to Applied Regression” de Fox & Weisberg. Ele tem diversas funções interessantes e testes estatísticos que não estão disponíveis como padrão no R.\n\n\nlibrary(car)\nleveneTest(homog ~ group, data = sims2)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(>F)\ngroup   1  1.7412 0.1876\n      498               \n\nleveneTest(heterog ~ group, data = sims2)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value    Pr(>F)    \ngroup   1  346.19 < 2.2e-16 ***\n      498                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSobre o \\(p\\)-valor que aparece como resultado do teste de Levene, \\(p < 0.05\\) (\\(p\\) menor que 0.05) significa fortes evidências de que a variável testada não possui homogeneidade de variâncias para os grupos especificados.\n\nEm outras palavras, rejeita-se a hipótese nula \\(H_0\\).\nCorrelação versus Causalidade\nCorrelação não é causalidade. Talvez você já tenha ouvido falar nessa expressão. Os testes estatísticos não sabem diferenciar de correlação com causalidade, eles apenas testam se o efeito não é nulo. Cabe ao pesquisador inferir se as consequências são causais ou associativas.\n\n\n\nMuitas vezes quando ensinamos Estatística, passamos muito tempo discutindo filosofia da ciência ao invés de Estatística. Coisas como “ausência de evidência não é evidência de ausência” viram focos de longas discussões. Causalidade é um campo da Estatística que está em grande destaque atualmente e acreditamos que irá revolucionar a maneira que enxergamos causalidade num futuro próximo.22 Mas, enquanto esta revolução não chega, adotamos o seguinte posicionamento: causalidade, para nós, implica em controlar totalmente um ambiente por meio de um experimento e introduzir uma intervenção por meio da manipulação de uma única variável. Somente assim conseguimos atribuir causalidade ao resultado de um teste estatístico. Caso contrário, estamos ainda sob o domínio da associação.\n\n\n\nComentários Finais\nSim, \\(p\\)-valores, intervalos de confiança, hipóteses nulas são conceitos complexos e muitos pesquisadores e cientistas não possuem a compreensão mínima necessária para a prática de Estatística inferencial. Acreditamos que a ciência (e a sociedade como um todo) se beneficiará de um maior número de cidadãos e pesquisadores que consigam avaliar, quantificar e qualificar evidências científicas. O paradigma da evidência científica atual (e, acreditamos que perdurará assim por bastante tempo) é o NHST e, apesar de termos algumas alternativas – como a Estatística Bayesiana – NHST irá predominar em boa parte da ciência pelas próximas décadas. Por isso, caro leitor, saiba que com “grandes poderes, vêm grandes responsabilidades.” Não deixe alguém torturar dados em práticas anti-éticas de \\(p\\)-hacking ou fundamentarem seus argumentos em compreensões incorretas de \\(p\\)-valor e \\(H_0\\).\n\nHá uma abordagem de Estatística inferencial que não se baseia em hipóteses nulas e \\(p\\)-valores: a Estatística Bayesiana. Caso fiquem curiosos o primeiro autor possui uma disciplina opensource de Estatística Bayesiana com R.\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] car_3.0-10         carData_3.0-4      patchwork_1.1.1   \n[4] dplyr_1.0.4        ggplot2_3.3.3      DiagrammeR_1.0.6.1\n[7] readxl_1.3.1      \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.6         lubridate_1.7.9.2  lattice_0.20-41   \n [4] visNetwork_2.0.9   assertthat_0.2.1   rprojroot_2.0.2   \n [7] digest_0.6.27      utf8_1.1.4         R6_2.5.0          \n[10] cellranger_1.1.0   evaluate_0.14      highr_0.8         \n[13] pillar_1.4.7       rlang_0.4.10       curl_4.3          \n[16] rstudioapi_0.13    data.table_1.13.6  Matrix_1.2-18     \n[19] reticulate_1.18    rmarkdown_2.6      labeling_0.4.2    \n[22] stringr_1.4.0      foreign_0.8-80     htmlwidgets_1.5.3 \n[25] munsell_0.5.0      compiler_4.0.3     xfun_0.21         \n[28] pkgconfig_2.0.3    htmltools_0.5.1.1  downlit_0.2.1     \n[31] tidyselect_1.1.0   tibble_3.0.6       bookdown_0.21     \n[34] rio_0.5.16         fansi_0.4.2        crayon_1.4.1      \n[37] withr_2.4.1        grid_4.0.3         jsonlite_1.7.2    \n[40] gtable_0.3.0       lifecycle_0.2.0    DBI_1.1.1         \n[43] magrittr_2.0.1     scales_1.1.1       zip_2.1.1         \n[46] cli_2.3.0          stringi_1.5.3      farver_2.0.3      \n[49] xml2_1.3.2         ellipsis_0.3.1     generics_0.1.0    \n[52] vctrs_0.3.6        openxlsx_4.2.3     distill_1.2       \n[55] RColorBrewer_1.1-2 tools_4.0.3        forcats_0.5.1     \n[58] glue_1.4.2         purrr_0.3.4        hms_1.0.0         \n[61] abind_1.4-5        yaml_2.2.1         colorspace_2.0-0  \n[64] knitr_1.31         haven_2.3.1       \n\n\n\n\nBaird, D. (1983). The fisher/pearson chi-squared controversy: A turning point for inductive inference. The British Journal for the Philosophy of Science, 34(2), 105–118. Retrieved from http://www.jstor.org/stable/687444\n\n\nCobb, G. W. (2007). The introductory statistics course: A ptolemaic curriculum? Technology Innovations in Statistics Education, 1(1).\n\n\nCumming, G. (2009). Inference by eye: Reading the overlap of independent confidence intervals. Statistics in Medicine, 28(2), 205–220.\n\n\nDowney, A. (2016). Probably overthinking it: There is still only one test. Retrieved from http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html\n\n\nFisher, R. A. (1925). Statistical methods for research workers. Oliver; Boyd.\n\n\nFox, J., & Weisberg, S. (2019). An R companion to applied regression (Third). Retrieved from https://socialsciences.mcmaster.ca/jfox/Books/Companion/\n\n\nHead, M. L., Holman, L., Lanfear, R., Kahn, A. T., & Jennions, M. D. (2015). The extent and consequences of p-hacking in science. PLoS Biol, 13(3), e1002106.\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164. https://doi.org/10.3758/s13423-013-0572-3\n\n\nIoannidis, J. P. A. (2019). What Have We (Not) Learnt from Millions of Scientific Papers with <i>P<\/i> Values? The American Statistician, 73(sup1), 20–25. https://doi.org/10.1080/00031305.2018.1447512\n\n\nMorey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., & Wagenmakers, E.-J. (2016). The fallacy of placing confidence in confidence intervals. Psychonomic Bulletin & Review, 23(1), 103–123. https://doi.org/10.3758/s13423-015-0947-8\n\n\nNeyman, J. (1937). Outline of a theory of statistical estimation based on the classical theory of probability. Philosophical Transactions of the Royal Society of London. Series A, Mathematical and Physical Sciences, 236(767), 333–380.\n\n\nNeyman, J., & Pearson, E. S. (1933). On the problem of the most efficient tests of statistical hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694-706), 289–337.\n\n\nPearl, J. (2009). Causality. Cambridge university press.\n\n\nRosnow, R. L., & Rosenthal, R. (1989). Statistical procedures and the justification of knowledge in psychological science. American Psychologist, 44, 1276–1284.\n\n\nSaculinggan, M., & Balase, E. A. (2013). Empirical power comparison of goodness of fit tests for normality in the presence of outliers. Journal of physics: Conference series, 435, 012041. IOP Publishing.\n\n\nStigler, S. M., & others. (2007). The epic story of maximum likelihood. Statistical Science, 22(4), 598–620.\n\n\nMatemático inglês que viveu entre 1857-1936. Considerado o fundador do campo da Estatística.↩︎\nem especial as técnicas clássicas/frequentistas de Estatística inferencial.↩︎\nTeoricamente não precisamos da hipótese nula se, no passo 2, simulássemos e permutássemos valores da amostra para calcular um \\(\\delta_0\\) (é provado matematicamente que se gerarmos amostras e permutações simuladas o suficiente, conseguiremos ter um \\(\\delta_0\\) no mínimo tão verídico que a abordagem clássica) ao invés de nos embasarmos em uma aproximação numérica pré-estabelecida de \\(\\delta_0\\). É claro que todas essas permutações e simulações são computacionalmente intensas.↩︎\nInclusive muitos renomados e citados em abundância em suas áreas.↩︎\nCuidado com essa palavra. Ela é precisa e somente deve ser usada em contextos estatísticos. Significância estatística quer dizer que os dados observados são mais extremos que um alpha prédefinido de que a hipótese nula é verdadeira.↩︎\nEsse conselho é extremamente útil. Por diversas vezes temos alunos que nos procuram com uma pergunta mais ou menos assim: “Professor, o que é o teste de Sobrenome que nunca ouvi falar na minha vida hífen outro sobrenome ainda mais estranho?” Graças a Wikipedia e Google, nós simplesmente vamos atrás da \\(H_0\\) desse teste (busca Google: “sobrenome1-sobrenome2 null hypothesis”) e com isso conseguimos responder ao aluno.↩︎\nA controvérsia da personalidade e vida de Ronald Fisher merece uma nota de rodapé. Suas contribuições, sem dúvida, foram cruciais para o avanço da ciência e da estatística. Seu intelecto era brilhante e seu talento já floresceu jovem: antes de completar 33 anos de idade ele tinha proposto o método de estimação por máxima verossimilhança (maximum likelihood estimation) (Stigler & others, 2007) e também criou o conceito de graus de liberdade (degrees of freedom) ao propor uma correção no teste de chi-quadrado de Pearson (Baird, 1983). Também inventou a Análise de Variância (ANOVA) e foi o primeiro a propor randomização como uma maneira de realizar experimentos, sendo considerado o “pai” dos ensaios clínicos randomizados. Nem tudo é florido na vida de Fisher, ele foi um eugenista e possuía uma visão muito forte sobre etnia e raça preconizando a superioridade de certas etnias. Além disso, era extremamente invariante, perseguindo, prejudicando e debochando qualquer crítico à suas teorias e publicações. O que vemos hoje no monopólio do paradigma Neyman-Pearson (Neyman & Pearson, 1933) com \\(p\\)-valores e hipóteses nulas é resultado desse esforço Fisheriano em calar os críticos e deixar apenas sua voz ecoar.↩︎\ninclusive muitos professores de estatística, veja a referência↩︎\nOriginal em ingles: “An X% confidence interval for a parameter is an interval (a, b) generated by a procedure that in repeated sampling has an X% probability of containing the true value of the parameter, for all possible values of the parameter.”↩︎\nOriginal em inglês: If the probability that a random interval contains the true value is X%, then the plausibility or probability that a particular observed interval contains the true value is also X%;or, alternatively, we can have X% confidence that the observed interval contains the true value.↩︎\nOriginal em inglês: The width of a confidence interval indicates the precision of our knowledge about the parameter. Narrow confidence intervals correspond to precise knowledge, while wide confidence errors correspond to imprecise knowledge.↩︎\nOriginal em inglês: A confidence interval contains the likely values for the parameter. Values inside the confidence interval are more likely than those outside. This fallacy exists in several varieties, sometimes involving plausibility, credibility, or reasonableness of beliefs about the parameter.↩︎\nO que é muito comum em 2020s com o advento de Big Data e facilidade de obtenção de dados.↩︎\nJerzy Neyman, fundador do paradigma NHST, e criador dos erros tipo I e tipo II defendia a ideia de que é melhor absolver um culpado (erro tipo II) do que culpar um inocente (erro tipo I) (Neyman & Pearson, 1933).↩︎\nNão estamos exagerando, quando você aprender o que são os pressupostos de cada técnica estatística vai começar a identificar que muitos artigos por aí não estão nem aí para pressupostos.↩︎\nAlgumas vezes isso não é possível e precisamos recorrer a transformações dos dados, ou até mesmo uma recoleta de dados.↩︎\nAlguns testes demandam no mínimo 20 observações para serem válidas. O número 20 possui relação com a derivação da distribuição Normal como uma distribuição binomial na qual o tamanho amostral é maior que 20.↩︎\nIsso geralmente requer o uso de técnicas especificamente criadas para dados que naturalmente possuem um certo tipo de dependência.↩︎\nAnálises de séries temporais e análises de dados geoespaciais fazem parte de um projeto futuro nosso.↩︎\nHomenagem a Carl Friedrich Gauss, matemático Alemão que viveu entre 1777 e 1855.↩︎\nPoder estatístico é, para uma certa probabilidade de erro tipo I (\\(\\alpha\\)), 1 menos a probabilidade de erro tipo II (\\(1 - \\beta\\)). Veja mais no conteúdo auxiliar de Tamanho da Amostra.↩︎\nCaso o leitor se interesse pelo tema, sugerimos um livro de Judea Pearl ganhador do Prêmio Turing (Nobel da computação): Pearl (2009).↩︎\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "3-Teste_t.html",
      "title": "Teste de Médias - Teste t de Student e Testes não-Paramétricos",
      "description": "Como comparar a diferença de uma variável entre dois grupos.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nTeste \\(t\\) de Student\nStudent vs Welch\nTeste \\(t\\) para Amostras Independentes\nTeste \\(t\\) para duas Amostras Pareadas\n\nTestes \\(t\\) Não-Paramétricos\nTeste de Mann–Whitney\nTeste de Wilcoxon\n\nComo visualizar testes de média entre grupos com R\nAmbiente\n\n\nTodos os testes aqui descritos possuem uma única finalidade: identificar se a média de variável entre dois grupos é diferente. Todos possuem como hipótese nula a diferença entre os grupos é zero, então \\(p\\)-valores oriundos dos testes quantificam a probabilidade de você obter resultados tão extremos caso não haja diferença entre os grupos. Por fim, todos os testes possuem o pressuposto de independência dos dados, portanto, caso haja alguma fonte de dependência dos dados os resultados dos testes são inválidos.\nTeste \\(t\\) de Student\nWilliam Sealy Gosset (químico, 1876-1937) publicou o teste \\(t\\) sob o pseudônimo de “Student,” razão pela qual o teste às vezes é chamado de “teste \\(t\\) de Student” (Student, 1908). Há controvérsia sobre a origem e o significado de \\(t\\). Uma hipótese é que \\(s\\) era comumente usado na época para se referir a estatísticas de amostra, então Gosset escolheu \\(t\\) como a próxima letra, talvez indicando um “avanço” no pensamento sobre estatísticas de amostra. Gosset publicou sob um pseudônimo porque ele era um funcionário da Cervejaria Guinness na época, e ele foi contratado para examinar questões ao fazer inferências sobre pequenas amostras na fabricação de cerveja. O teste que ele desenvolveu poderia ser propriedade intelectual do Guinness, mas Gosset achou que o teste poderia ser amplamente usado, então ele o publicou sob um pseudônimo para proteger seu trabalho.\n\n\n\nFigure 1: William Sealy Gosset. Figura de https://www.wikipedia.org\n\n\n\nO teste \\(t\\) de Student assume os seguintes pressupostos com relação aos dados:\nOs dados são independentes: o valor de uma observação não influencia ou afeta o valor de outras observações.\nA variável dependente (aquela que estamos usando para calcular a média dos grupos) é distribuída conforme uma distribuição Normal.\nA variável dependente possui homogeneidade de variância dentre os grupos1.\n\nLembre-se que uma vez violados esses pressupostos, os resultados do teste \\(t\\) são inválidos.\nStudent vs Welch\nEm 1947, Bernard Lewis Welch, estatístico britânico adaptou o teste \\(t\\) de Student para ser robusto perante heterogeneidade das variâncias (Welch, 1947). O teste \\(t\\) de Welch é muita vezes confudido e reportado erroneamente como teste \\(t\\) de Student, uma vez que pela sua robustez é o teste \\(t\\) padrão de diversos softwares estatísticos (Delacre, Lakens, & Leys, 2017). No R a função t.test() possui como padrão o teste \\(t\\) de Welch e caso você queira explicitamente usar o teste \\(t\\) de Student você deve incluir o argumento var.equal = TRUE na função.\nTeste \\(t\\) para Amostras Independentes\nQuando temos dois grupos na mesma amostra, usamos o teste \\(t\\) para amostras independentes. A função t.test() é incluída como padrão no R. Aqui vamos simular dois grupos A e B cada um com 20 observações e vamos amostrar de uma distribuição Normal para cada um dos grupos com médias diferentes.\nA fórmula que deve ser passada na função t.test() segue a mesma lógica das fórmulas do Teste de Bartlett e de Levene, sendo que é necessário fornecer dois argumentos:\nFórmula designando a variável cuja média deve ser analisada e os grupos em relação aos quais as médias serão analisadas. A fórmula é designada pela seguinte síntaxe: variavel ~ grupo.\nO dataset no qual deverá ser encontrados tanto a varíavel quanto os grupos.\nO resultado para a simulação é um \\(p\\)-valor menor que 0.05, ou seja um resultado significante apontando que podemos rejeitar a hipótese nula (fortes evidências contrárias que as médias dos grupos são iguais).\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nn_sim_t <- 20\nsim3 <- tibble(\n  group = c(rep(\"A\", n_sim_t), rep(\"B\", n_sim_t)),\n  measure = c(rnorm(n_sim_t, mean = 0), rnorm(n_sim_t, mean = 5))\n)\n\nt.test(measure ~ group, data = sim3)\n\n\n\n    Welch Two Sample t-test\n\ndata:  measure by group\nt = -13.095, df = 37.88, p-value = 1.226e-15\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -5.086532 -3.724278\nsample estimates:\nmean in group A mean in group B \n      0.2039198       4.6093247 \n\n\nNotem que a saída da função t.test() possui um intervalo de confiança 95% (padrão, mas pode ser mudado)\nTeste \\(t\\) para duas Amostras Pareadas\nEm algumas situações temos amostras pareadas, como por exemplo quando fazemos uma mensuração antes e depois de algum acontecimento ou intervenção. Para isso a função t.test() tem o argumento paired que quando definido como TRUE faz com que o teste \\(t\\) seja pareado.\nA mesma simulação do teste \\(t\\) para amostras pareadas, mas agora não usamos a fórmula e passamos como argumento as mensurações das duas amostras pareadas:\n\n\namostra_1 <- tibble(measure = rnorm(n_sim_t, mean = 0))\namostra_2 <- tibble(measure = rnorm(n_sim_t, mean = 5))\n\nt.test(amostra_1$measure, amostra_2$measure, paired = TRUE)\n\n\n\n    Paired t-test\n\ndata:  amostra_1$measure and amostra_2$measure\nt = -14.839, df = 19, p-value = 6.656e-12\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -5.810596 -4.374036\nsample estimates:\nmean of the differences \n              -5.092316 \n\n\nNotem que a saída da função t.test() possui um intervalo de confiança 95% (padrão, mas pode ser mudado)\nTestes \\(t\\) Não-Paramétricos\nO que fazer se meus dados violam o pressuposto de normalidade? Nesse caso devemos usar uma abordagem não-paramétrica. O teste \\(t\\) de Student (e também de Welch) é uma abordagem paramétrica: dependem fortemente da suposição que os dados estejam distribuídos de acordo com uma distribuição específica. Testes não-paramétricos não fazem suposições sobre a distribuição dos dados e portanto podem ser usados quando os pressupostos dos testes paramétricos são violados.\nAtenção: testes não-paramétricos são menos sensíveis em rejeitar a hipótese nula quando ela é verdadeira (erro tipo I) do que testes paramétricos quando o pressuposto de normalidade não é violado (Zimmerman, 1998). Então não pense que deve sempre aplicar um teste não-paramétrico em todas as ocasiões.\nTeste de Mann–Whitney\nO teste de Mann-Whitney foi desenvolvido em 1947 para ser uma alternativa não-paramétrica ao teste \\(t\\) para amostras independentes (Mann & Whitney, 1947). Para aplicar o teste Mann-Whitney use a função wilcox.test()2 é incluída como padrão no R. Aqui vamos simular novemente dois grupos A e B cada um com 20 observações e vamos amostrar de uma distribuição Log-Normal para cada um dos grupos com médias diferentes. A síntaxe é a mesma que a função t.test().\n\n\nsim4 <- tibble(\n  group = c(rep(\"A\", n_sim_t), rep(\"B\", n_sim_t)),\n  measure = c(rlnorm(n_sim_t, mean = 0), rlnorm(n_sim_t, mean = 5))\n)\n\nwilcox.test(measure ~ group, data = sim4, conf.int = TRUE)\n\n\n\n    Wilcoxon rank sum exact test\n\ndata:  measure by group\nW = 0, p-value = 1.451e-11\nalternative hypothesis: true location shift is not equal to 0\n95 percent confidence interval:\n -197.1586 -106.6526\nsample estimates:\ndifference in location \n             -127.4953 \n\n\nNotem que a função wilcox.test() não calcula intervalos de confiança. Para isso é necessário adicionar o argumento conf.int = TRUE que resulta em intervalos de confiança 95% (padrão, mas pode ser mudado)\nTeste de Wilcoxon\nO teste de Wilcoxon foi desenvolvido em 1945 para ser uma alternativa não-paramétrica ao teste \\(t\\) para amostras pareadas (Wilcoxon, 1945). A função wilcox.test()3 tem o argumento paired que quando definido como TRUE faz com que o teste não-paramétrico seja pareado (muito similar a função t.test() para amostras pareadas).\nA mesma simulação do teste de Mann-Whitney para amostras pareadas, mas agora não usamos a fórmula e passamos como argumento as mensurações das duas amostras pareadas:\n\n\namostra_3 <- tibble(measure = rlnorm(n_sim_t, mean = 0))\namostra_4 <- tibble(measure = rlnorm(n_sim_t, mean = 5))\n\nwilcox.test(amostra_3$measure, amostra_4$measure, paired = TRUE, conf.int = TRUE)\n\n\n\n    Wilcoxon signed rank exact test\n\ndata:  amostra_3$measure and amostra_4$measure\nV = 0, p-value = 1.907e-06\nalternative hypothesis: true location shift is not equal to 0\n95 percent confidence interval:\n -214.98044  -98.24208\nsample estimates:\n(pseudo)median \n     -144.3723 \n\n\nNotem que a função wilcox.test() não calcula intervalos de confiança. Para isso é necessário adicionar o argumento conf.int = TRUE que resulta em intervalos de confiança 95% (padrão, mas pode ser mudado)\nComo visualizar testes de média entre grupos com R\nUma das bibliotecas que usamos bastante para visualização de testes estatísticos é a {ggpubr} (Kassambara, 2020). Veja um exemplo abaixo com um dos datasets que simulamos nesse tutorial.\nPrimeiramente criamos um diagrama de caixa (boxplot) com a função ggboxplot() na qual especificamos o eixo X, eixo Y, cor, paleta de cores etc. Na sequencia adicionamos a camada das estatísticas de comparação dos grupos com o stat_compare_means() especificando que tipo de método será utilizado na análise:\n\"wilcox.test\" – Teste não-paramétrico de Wilcoxon (padrão da função).\n\"t.test\" – Teste \\(t\\) paramétrico de Welch.\n\n\nlibrary(ggpubr)\nggboxplot(sim3, x = \"group\", y = \"measure\", color = \"group\",\n          palette = \"lancet\", add = \"jitter\") +\n  stat_compare_means(method = \"t.test\")\n\n\n\n\nFigure 2: Diagrama de Caixa usando o {ggpubr} – Amostras Independentes\n\n\n\nPara testes usando amostras pareadas é necessário usar a função ggpaired() e adicionar o argumento paired = TRUE dentro da função stat_compare_means()\n\n\nggpaired(sim3, x = \"group\", y = \"measure\", color = \"group\",\n         palette = \"lancet\", line.color = \"gray\", line.size = 0.4) +\n  stat_compare_means(method = \"t.test\", paired = TRUE)\n\n\n\n\nFigure 3: Diagrama de Caixa usando o {ggpubr} – Amostras Pareadas\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] ggpubr_0.4.0       car_3.0-10         carData_3.0-4     \n[4] patchwork_1.1.1    dplyr_1.0.4        ggplot2_3.3.3     \n[7] DiagrammeR_1.0.6.1 readxl_1.3.1      \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.6         lubridate_1.7.9.2  lattice_0.20-41   \n [4] tidyr_1.1.2        visNetwork_2.0.9   assertthat_0.2.1  \n [7] rprojroot_2.0.2    digest_0.6.27      utf8_1.1.4        \n[10] R6_2.5.0           cellranger_1.1.0   backports_1.2.1   \n[13] evaluate_0.14      highr_0.8          pillar_1.4.7      \n[16] rlang_0.4.10       curl_4.3           rstudioapi_0.13   \n[19] data.table_1.13.6  Matrix_1.2-18      reticulate_1.18   \n[22] rmarkdown_2.6      labeling_0.4.2     stringr_1.4.0     \n[25] foreign_0.8-80     htmlwidgets_1.5.3  munsell_0.5.0     \n[28] broom_0.7.4        compiler_4.0.3     xfun_0.21         \n[31] pkgconfig_2.0.3    htmltools_0.5.1.1  downlit_0.2.1     \n[34] tidyselect_1.1.0   tibble_3.0.6       bookdown_0.21     \n[37] rio_0.5.16         fansi_0.4.2        crayon_1.4.1      \n[40] withr_2.4.1        grid_4.0.3         jsonlite_1.7.2    \n[43] gtable_0.3.0       lifecycle_0.2.0    DBI_1.1.1         \n[46] magrittr_2.0.1     scales_1.1.1       zip_2.1.1         \n[49] cli_2.3.0          stringi_1.5.3      ggsignif_0.6.0    \n[52] farver_2.0.3       xml2_1.3.2         ellipsis_0.3.1    \n[55] generics_0.1.0     vctrs_0.3.6        openxlsx_4.2.3    \n[58] distill_1.2        ggsci_2.9          RColorBrewer_1.1-2\n[61] tools_4.0.3        forcats_0.5.1      glue_1.4.2        \n[64] purrr_0.3.4        hms_1.0.0          abind_1.4-5       \n[67] yaml_2.2.1         colorspace_2.0-0   rstatix_0.6.0     \n[70] knitr_1.31         haven_2.3.1       \n\n\n\n\nDelacre, M., Lakens, D., & Leys, C. (2017). Why psychologists should by default use welch’s t-test instead of student’s t-test. International Review of Social Psychology, 30(1).\n\n\nKassambara, A. (2020). Ggpubr: ’ggplot2’ based publication ready plots. Retrieved from https://CRAN.R-project.org/package=ggpubr\n\n\nMann, H. B., & Whitney, D. R. (1947). On a test of whether one of two random variables is stochastically larger than the other. Ann. Math. Statist., 18(1), 50–60. https://doi.org/10.1214/aoms/1177730491\n\n\nStudent. (1908). The probable error of a mean. Biometrika, 1–25.\n\n\nWelch, B. L. (1947). The generalization of student’s’ problem when several different population variances are involved. Biometrika, 34(1/2), 28–35.\n\n\nWilcoxon, F. (1945). Individual comparisons by ranking methods. Biometrics Bulletin, 1(6), 80–83. Retrieved from http://www.jstor.org/stable/3001968\n\n\nZimmerman, D. W. (1998). Invalidation of parametric and nonparametric statistical tests by concurrent violation of two assumptions. The Journal of Experimental Education, 67(1), 55–68. https://doi.org/10.1080/00220979809598344\n\n\nUma versão do teste \\(t\\) de Welch é robusta a heterogeneidade de variâncias e permite com que esse pressuposto seja violado.↩︎\nO teste Mann-Whitney também e chamado de teste de Mann–Whitney–Wilcoxon (MWW), teste da soma dos postos de Wilcoxon e teste de Wilcoxon–Mann–Whitney. Por isso o nome da função R para teste de Mann-Whitney é wilcox.test().↩︎\nTeste de Wilcoxon também e conhecido como testes dos postos sinalizados de Wilcoxon.↩︎\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "4-ANOVA.html",
      "title": "Teste de Médias -- ANOVA Paramétrica e Não-Paramétrica",
      "description": "Como comparar as diferenças de uma variável para mais de dois grupos.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nHistória da ANOVA\nDataset ToothGrowth\nANOVA\nANOVA Unidirecional\nANOVA Bidirecional\n\nANOVA Não-Paramétrica – Teste Kruskal-Wallis\nANOVA de Medidas Repetidas\nComparações Múltiplas entre Grupos\nTeste de Tukey\nTeste de Dunn\n\nComo visualizar ANOVAs com R\nAmbiente\n\n\nO teste \\(t\\) verifica a diferença de média entre dois grupos. E se eu tenho mais de dois grupos? A resposta mais inocente seria realizar múltiplos testes \\(t\\) entre os diversos grupos e comparar o tamanho de efeito e \\(p\\)-valor dos testes. Porém essa abordagem possui uma falha: conforme aumenta o número de testes1 a taxa de falsos positivos (erros tipo I) aumentam quase na mesma proporção.\nA fórmula para determinar a nova taxa de erro para múltiplos testes \\(t\\) não é tão simples quanto multiplicar 5% pelo número de testes. No entanto, se você estiver fazendo apenas algumas comparações múltiplas, os resultados serão muito semelhantes se você fizer isso. Como tal, três testes \\(t\\) seriam 15% (na verdade, 14.3%) e assim por diante.\nA taxa de erro para múltiplos testes de \\(t\\) é chamada de taxa de erro familiar2 e é definida como:\n\na probabilidade máxima de que um procedimento consistindo de mais de uma comparação conclua incorretamente que pelo menos uma das diferenças observadas é significativamente diferente da hipótese nula.\n\nPara controlar a taxa de erro familiar, temos um conjunto de técnicas chamada análise de variância, conhecida como Analysis of Variance (ANOVA). A ANOVA controla esses erros para que os falsos positivos (erros tipo I) permaneçam em 5% na comparação de média entre dois ou mais grupos. A ANOVA não irá dizer com precisão como que as médias dos grupos diferem, mas o seu resultado indica fortes evidências de que a diferença entre as médias dos grupos difere. Sua hipótese nula é que não há diferença entre as médias dos grupos. A ANOVA tradicional é uma técnica paramétrica (quando a variável dependente é distribuída conforme uma distribuição Normal), mas há também uma versão não-paramétrica (quando não temos pressupostos sobre de que distribuição probabilística a variável dependente é distribuída) chamada teste de Kruskal-Wallis.\nApós analisar os resultados de uma ANOVA, é muito comum realizar uma comparação post-hoc usando um conjunto de técnicas comparativas de média entre grupos que controlam a taxa de erro familiar. A principal técnica paramétrica é o teste de Tukey e a principal técnica não-paramétrica é o teste de Dunn.\nHistória da ANOVA\nA ANOVA foi primeira proposta por Ronald Fisher3 em 1921 (R. Fisher, 1921) e foi incluída no seu livro de 1925 que popularizou as técnicas de Estatística inferencial (R. A. Fisher, 1925). A estatística que a ANOVA calcula para testar sua hipótese nula é chamada de Estatística F, em homenagem à Fisher. Em 1919 Fisher foi trabalhar em um instituto de pesquisa agrícola chamado Rothamsted Experimental Station na Inglaterra, onde ficou até 1933. Foi nesse instituto que Fisher, ao ter acesso a uma vasta quantidade de dados sobre dados de safra agrícola acumulados desde 1842, desenvolveu e fez as primeiras aplicações de ANOVA.\n\n\n\nFigure 1: Ronald Fisher. Figura de https://www.wikipedia.org\n\n\n\nDataset ToothGrowth\nDessa vez não vamos simular dados, mas vamos usar um dataset que vem padrão com o R chamado ToothGrowth (Crampton, 1947), que examina os efeitos da vitamina C no crescimento dos dentes em porquinhos da índia. Cada animal foi atribuído a um de seis grupos de 10 sujeitos cada (\\(n = 10\\)) para um total de 60 cobaias ao todo (\\(N = 60\\)). As duas variáveis que foram manipuladas neste estudo foram o nível de dosagem de vitamina C dose (0.5, 1.0 ou 2.0 mg / dia) e o método de entrega da dosagem supp (suco de laranja OJ ou ácido absorvico VC). A variável dependente é o comprimento dos denteslen dos porquinhos da índia.\nNós, sempre que carregamos um dataset no R, temos o costume de usar a biblioteca {skimr} (Waring et al., 2020) para produzir um sumário dos dados.\n\n\nlibrary(skimr)\ndata(\"ToothGrowth\")\nToothGrowth$dose <- as.factor(ToothGrowth$dose)\nskim(ToothGrowth)\n\n\nTable 1: Data summary\nName\nToothGrowth\nNumber of rows\n60\nNumber of columns\n3\n_______________________\n\nColumn type frequency:\n\nfactor\n2\nnumeric\n1\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nsupp\n0\n1\nFALSE\n2\nOJ: 30, VC: 30\ndose\n0\n1\nFALSE\n3\n0.5: 20, 1: 20, 2: 20\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nlen\n0\n1\n18.81\n7.65\n4.2\n13.07\n19.25\n25.27\n33.9\n▅▃▅▇▂\n\nAlém disso é interessante computar uma tabela de frequência com a função padrão do R table() das duas variáveis independentes supp e dose:\n\n\ntable(ToothGrowth$supp, ToothGrowth$dose)\n\n\n    \n     0.5  1  2\n  OJ  10 10 10\n  VC  10 10 10\n\nANOVA\nA ANOVA é uma técnica paramétrica e seus pressupostos são similares ao teste \\(t\\) de Student:\nIndependência das observações: o valor de uma observação não influencia ou afeta o valor de outras observações.\nNormalidade: variável dependente distribuída conforme uma distribuição Normal.\nHomogeneidade das Variâncias: variável dependente possui homogeneidade de variância dentre os grupos.\nAlém disso, a ANOVA é utilizada apenas quando as variáveis independentes são categóricas (discretas, como por exemplo grupos diferentes).\nO pressuposto da normalidade, já coberto na tutorial de \\(p\\)-valores, pode ser testado com o teste de Shapiro-Wilk usando a função shapiro.test().\n\n\nshapiro.test(ToothGrowth$len)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  ToothGrowth$len\nW = 0.96743, p-value = 0.1091\n\nO \\(p\\)-valor do teste é 0.1091005 e com isso falhamos em rejeitar a hipótese nula de que len é distribuída conforma uma distribuição Normal. Ou seja, pressuposto de normalidade não violado.\nAvançando para o pressuposto de homogeneidade de variâncias, também já coberto na tutorial de \\(p\\)-valores, pode ser testado com o teste de Levene usando a função leveneTest() da biblioteca {car}.\n\n\nlibrary(car)\nleveneTest(len ~ supp, data = ToothGrowth)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  1  1.2136 0.2752\n      58               \n\nleveneTest(len ~ dose, data = ToothGrowth)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  2  0.6457 0.5281\n      57               \n\nO \\(p\\)-valor de ambos testes para a homogeneidade de variâncias de len nos grupos de supp e dose são respectivamente 0.28 e 0.53. Com isso falhamos em rejeitar a hipótese nula de que len possui variâncias homogêneas nos grupos tanto de supp quanto de dose. Ou seja, pressuposto de homogeneidade de variâncias não violado.\nANOVA Unidirecional4\nA ANOVA mais simples é chamada de ANOVA Unidirecional que examina a influência de uma variável independente categórica em uma variável contínua dependente.\nO R possui uma função padrão para calcular ANOVAs aov() e sua funcionalidade é muito similar à outras funções que já vimos de teste de hipótese, sendo que é necessário fornecer dois argumentos:\nFórmula designando a variável cuja média deve ser analisada e os grupos em relação aos quais as médias serão analisadas. A fórmula é designada pela seguinte síntaxe: variavel ~ grupo.\nO dataset no qual deverá ser encontrados tanto a varíavel quanto os grupos.\naov() quer dizer Analysis of Variance.\nA saída da função aov() é um objeto aov que pode ser passado para uma função summary() eu nos trás os resultados da ANOVA.\n\n\nfit1 <- aov(len ~ supp, data = ToothGrowth)\nsummary(fit1)\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nsupp         1    205  205.35   3.668 0.0604 .\nResiduals   58   3247   55.98                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nPodemos ver que a diferença do comprimento dos dentes len conforme o método de dosagem supp (suco de laranja vs ácido ascórbico) não é estatisticamente significante (\\(p>0.06\\)). Ao comparar o nível de significância do teste (\\(p=0.06\\)) com o limiar estabelecido (\\(p<0.05\\)) não conseguimos rejeitar a hipótese nula de que não há diferença no comprimento dos dentes.\n\n\nfit2 <- aov(len ~ dose, data = ToothGrowth)\nsummary(fit2)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ndose         2   2426    1213   67.42 9.53e-16 ***\nResiduals   57   1026      18                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nPorém, o comprimento dos dentes len muda conforme o tamanho da dose dose (0.5, 1.0 ou 2.0 mg) (\\(p<0.05\\)). Ao comparar o nível de significância do teste (\\(p=0.00000000000000095\\)) com o limiar estabelecido (\\(p<0.05\\)) conseguimos rejeitar a hipótese nula de que não há diferença no comprimento dos dentes.\nANOVA Bidirecional5\nA ANOVA Bidirecional é uma extensão da ANOVA Unidirecional que examina a influência de duas variáveis independentes categóricas em uma variável contínua dependente. Há duas maneiras de analisarmos essa influência:\nEfeitos principais: efeito de uma (ou mais) variável(is) independente(s) em uma variável dependente. Chamamos esses efeitos de aditivos pois podem ser quebrados em dois efeitos distintos e únicos que estão influenciando a variável dependente.\nEfeitos de interações: quando o efeito de uma (ou mais) variável(is) independente(s) em uma variável dependente é afetado pelo nível de outras variável(is) independente(s). Efeitos de interação não são aditivos pois podem ser quebrados em dois efeitos distintos e únicos que estão influenciando a variável dependente. Há uma interação entre as variáveis independentes.\nANOVA Bidirecional com efeitos principais6\nPrimeiro vamos executar uma ANOVA bidirecional com apenas efeitos principais. Usamos a mesma função aov() do R que gerará o mesmo objeto aov, porém agora precisamos incluir uma segunda variável independente. Fazemos isso incluindo na fórmula a segunda variável junto com a primeira e um sinal positivo de adição + indicando que as duas variáveis devem ser usadas como efeitos principais na análise:\n\n\nfit3 <- aov(len ~ supp + dose, data = ToothGrowth)\nsummary(fit3)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nsupp         1  205.4   205.4   14.02 0.000429 ***\ndose         2 2426.4  1213.2   82.81  < 2e-16 ***\nResiduals   56  820.4    14.7                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nPelos resultados, podemos ver que tanto supp e dose são estatisticamente significantes. Sendo que dose possui o maior tamanho de efeito (F value) 124.0 contra 11.4 de supp.\nANOVA Bidirecional com efeitos de interação7\nPara executarmos uma ANOVA bidirecional com efeitos de interações. Usamos novamente função aov() do R que gerará o mesmo objeto aov, porém agora precisamos incluir uma segunda variável independente e especificar a interação. Fazemos isso incluindo na fórmula a segunda variável junto com a primeira e um sinal de multiplicação8 * indicando que as duas variáveis devem ser usadas como efeitos principais e também de interação na análise:\n\n\nfit4 <- aov(len ~ supp * dose, data = ToothGrowth)\nsummary(fit4)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nsupp         1  205.4   205.4  15.572 0.000231 ***\ndose         2 2426.4  1213.2  92.000  < 2e-16 ***\nsupp:dose    2  108.3    54.2   4.107 0.021860 *  \nResiduals   54  712.1    13.2                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nComo resultado vemos que os efeitos principais tanto de supp e dose se mantiveram com \\(p\\)-valores e tamanho de efeitos similares. Mas a grande novidade agora é que a interação supp:dose também é estatisticamente significante. Nesse caso devemos usar a ANOVA com efeito de interação e não a ANOVA com efeitos principais. Caso a interação supp:dose não fosse estatisticamente significante deveríamos usar a ANOVA com efeitos principais e não a ANOVA com efeito de interação.\nANOVA Não-Paramétrica – Teste Kruskal-Wallis9\nO que fazer se minha variável dependente viola os pressupostos de normalidade ou de homogeneidade de variâncias? Nesse caso devemos usar uma abordagem não-paramétrica. A ANOVA clássica é uma abordagem paramétrica: depende fortemente da suposição que os dados estejam distribuídos de acordo com uma distribuição específica e que as variâncias entre os grupos é igual. Testes não-paramétricos não fazem suposições sobre a distribuição dos dados e portanto podem ser usados quando os pressupostos dos testes paramétricos são violados.\nAtenção: testes não-paramétricos são menos sensíveis em rejeitar a hipótese nula quando ela é verdadeira (erro tipo I) do que testes paramétricos quando o pressuposto de normalidade não é violado (Zimmerman, 1998). Então não pense que deve sempre aplicar um teste não-paramétrico em todas as ocasiões.\nA versão não-paramétrica da ANOVA é o teste de Kruskal-Wallis (também chamado de teste de Kruskal-Wallis por postos ou teste H de Kruskal-Wallis) foi desenvolvido em 1952 por William Kruskal e W. Allen Wallis (Kruskal & Wallis, 1952). O teste pode ser encontrada na função padrão que vem com o R kruskal.test() e funciona identicamente a aov(), com a exceção de que aceita somente uma variável independente. kruskal.test() aceita dois argumentos:\n\nNão é recomendado empregar ANOVAS bidirecionais não-paramétricas. Caso o leitor precise usar uma técnica não-paramétrica para mais de duas variáveis independentes, recomendamos um abordagem que empregue algum modelo linear (tutorial 6) ou modelo linear generalizado (tutorial 7).\nFórmula designando a variável cuja média deve ser analisada e os grupos em relação aos quais as médias serão analisadas. A fórmula é designada pela seguinte síntaxe: variavel ~ grupo.\nO dataset no qual deverá ser encontrados tanto a varíavel quanto os grupos.\nAqui vamos fazer apenas o exemplo com supp usando o dataset ToothGrowth:\n\n\nkruskal.test(len ~ supp, data = ToothGrowth)\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  len by supp\nKruskal-Wallis chi-squared = 3.4454, df = 1, p-value = 0.06343\n\nComo podem ver, o resultado é o mesmo que o da ANOVA paramétrica aov().\nANOVA de Medidas Repetidas10\nCaso você esteja procurando por uma extensão natural ao teste \\(t\\) para duas amostras pareadas na ANOVA. Sim, ela existe e se chama ANOVA de Medidas Repetidas, mas nós recomendamos fortemente que você não use ANOVA de Medidas Repetidas.\n\n\n\nHá bastante evidências que demonstram a inadequação de ANOVAs de medidas repetidas (Camilli & Shepard, 1987; Chang, Pal, Lim, & Lin, 2010; Levy, 1978; Vasey & Thayer, 1987). Diversas referências sugerem trocar a ANOVA de medidas repetidas por um modelo logístico misto (Jaeger, 2008; Kristensen & Hansen, 2004), que se demonstrou mais flexível, acurado e sensível.\n\nNão vamos abordar modelos mistos nos tutoriais. Caso esteja interessado veja a função lme() da biblioteca {nlme}.\nComparações Múltiplas entre Grupos\nEmbora ANOVA seja uma abordagem paramétrica poderosa e útil para analisar dados aproximadamente normalmente distribuídos com mais de dois grupos, ela não fornece nenhuma visão mais profunda dos padrões ou comparações entre grupos específicos.\nApós analisar os resultados de uma ANOVA, é muito comum realizar uma comparação post-hoc usando um conjunto de técnicas comparativas de média entre grupos que controlam a taxa de erro familiar. A principal técnica paramétrica é o teste de Tukey e a principal técnica não-paramétrica é o teste de Dunn.\nTeste de Tukey11\nUm método comum e popular de análise post-hoc é o Teste de Tukey. O teste é conhecido por vários nomes diferentes: teste de Tukey da diferença honestamente significativa, teste de Tukey da diferença totalmente significativa, entre outros… O teste de Tukey compara as médias de todos os grupos entre si e é considerado o melhor método disponível nos casos em que os intervalos de confiança são desejados ou se os tamanhos das amostras são desiguais.\nA estatística de teste usada no teste de Tukey é denotada \\(q\\) e é essencialmente uma estatística \\(t\\) modificada que corrige múltiplas comparações.\nO teste de Tukey pode ser encontrado na função padrão que vem com o R tukeyHSD() e aceita como argumento um objeto aov resultante de uma ANOVA:\n\n\nTukeyHSD(fit3)\n\n\n\nComo resultado temos uma tabela com todos os grupos das variáveis independentes da ANOVA testados entre si:\ndiff – diferença entre os grupos.\nlwr – intervalo de confiança 95% inferior da diferença.\nupr – intervalo de confiança 95% superior da diferença.\np adj – estatística \\(q\\) do Teste de Tukey, aqui referida como um \\(p\\)-valor ajustado.\nTeste de Dunn12\nO teste de Tukey assume que a variável dependente é normalmente distribuída e, portanto, não é apropriado como um teste post-hoc após um teste não-paramétrico como Kruskal-Wallis. O único teste post-hoc não paramétrico para esse contexto é o teste de Dunn(Dunn, 1964).\nPara executar o teste de Dunn é necessário usar a função DunnTest() da biblioteca {DescTools} (Andri et mult. al., 2020). Ela aceita argumentos similares à função kruskal.test():\nFórmula designando a variável cuja média deve ser analisada e os grupos em relação aos quais as médias serão analisadas. A fórmula é designada pela seguinte síntaxe: variavel ~ grupo.\nO dataset no qual deverá ser encontrados tanto a varíavel quanto os grupos.\n\n\nlibrary(DescTools)\nDunnTest(len ~ dose, data = ToothGrowth)\n\n\n\n Dunn's test of multiple comparisons using rank sums : holm  \n\n      mean.rank.diff    pval    \n1-0.5         19.625 0.00076 ***\n2-0.5         35.125   6e-10 ***\n2-1           15.500 0.00499 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nUma coisa importante de se notar é que não é possível obter um intervalo de confiança de um teste de Dunn.\nComo visualizar ANOVAs com R\nMais uma vez vamos recorrer a biblioteca {ggpubr} (Kassambara, 2020) para visualização de testes estatísticos. Veja um exemplo abaixo com o dataset ToothGrowth.\nAdicionamos a camada das estatísticas de comparação dos grupos com o stat_compare_means() especificando que tipo de método será utilizado na análise:\n\"anova\" – ANOVA.\n\"kruskal.test\" – ANOVA não paramétrica.\n\n\nlibrary(ggpubr)\nggboxplot(ToothGrowth, x = \"dose\", y = \"len\",\n                color = \"supp\", palette = \"lancet\",\n                add = \"jitter\", shape = \"dose\") +\n  stat_compare_means(method = \"anova\")\n\n\n\n\nFigure 2: Diagrama de Caixa usando o {ggpubr} – ANOVA\n\n\n\n\n\nlibrary(ggpubr)\nggboxplot(ToothGrowth, x = \"dose\", y = \"len\",\n                color = \"supp\", palette = \"lancet\",\n                add = \"jitter\", shape = \"dose\") +\n  stat_compare_means(method = \"kruskal.test\")\n\n\n\n\nFigure 3: Diagrama de Caixa usando o {ggpubr} – ANOVA Não-Paramétrica\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] DescTools_0.99.40  skimr_2.1.2        ggpubr_0.4.0      \n [4] car_3.0-10         carData_3.0-4      patchwork_1.1.1   \n [7] dplyr_1.0.4        ggplot2_3.3.3      DiagrammeR_1.0.6.1\n[10] readxl_1.3.1      \n\nloaded via a namespace (and not attached):\n [1] lubridate_1.7.9.2  RColorBrewer_1.1-2 rprojroot_2.0.2   \n [4] ggsci_2.9          repr_1.1.3         tools_4.0.3       \n [7] backports_1.2.1    utf8_1.1.4         R6_2.5.0          \n[10] DBI_1.1.1          colorspace_2.0-0   withr_2.4.1       \n[13] tidyselect_1.1.0   Exact_2.1          downlit_0.2.1     \n[16] curl_4.3           compiler_4.0.3     cli_2.3.0         \n[19] expm_0.999-6       xml2_1.3.2         labeling_0.4.2    \n[22] bookdown_0.21      scales_1.1.1       mvtnorm_1.1-1     \n[25] stringr_1.4.0      digest_0.6.27      foreign_0.8-80    \n[28] rmarkdown_2.6      rio_0.5.16         base64enc_0.1-3   \n[31] pkgconfig_2.0.3    htmltools_0.5.1.1  highr_0.8         \n[34] htmlwidgets_1.5.3  rlang_0.4.10       rstudioapi_0.13   \n[37] visNetwork_2.0.9   farver_2.0.3       generics_0.1.0    \n[40] jsonlite_1.7.2     zip_2.1.1          distill_1.2       \n[43] magrittr_2.0.1     Matrix_1.2-18      Rcpp_1.0.6        \n[46] munsell_0.5.0      fansi_0.4.2        abind_1.4-5       \n[49] reticulate_1.18    lifecycle_0.2.0    stringi_1.5.3     \n[52] yaml_2.2.1         rootSolve_1.8.2.1  MASS_7.3-53       \n[55] grid_4.0.3         forcats_0.5.1      crayon_1.4.1      \n[58] lmom_2.8           lattice_0.20-41    haven_2.3.1       \n[61] hms_1.0.0          knitr_1.31         pillar_1.4.7      \n[64] boot_1.3-25        gld_2.6.2          ggsignif_0.6.0    \n[67] glue_1.4.2         evaluate_0.14      data.table_1.13.6 \n[70] vctrs_0.3.6        cellranger_1.1.0   gtable_0.3.0      \n[73] purrr_0.3.4        tidyr_1.1.2        assertthat_0.2.1  \n[76] xfun_0.21          openxlsx_4.2.3     broom_0.7.4       \n[79] e1071_1.7-4        rstatix_0.6.0      class_7.3-17      \n[82] tibble_3.0.6       ellipsis_0.3.1    \n\n\n\n\nAndri et mult. al., S. (2020). DescTools: Tools for descriptive statistics. Retrieved from https://cran.r-project.org/package=DescTools\n\n\nCamilli, G., & Shepard, L. A. (1987). The inadequacy of ANOVA for detecting test bias. Journal of Educational Statistics, 12(1), 87–99. https://doi.org/10.3102/10769986012001087\n\n\nChang, C.-H., Pal, N., Lim, W. K., & Lin, J.-J. (2010). Comparing several population means: A parametric bootstrap method, and its comparison with usual ANOVA f test as well as ANOM. Computational Statistics, 25(1), 71–95.\n\n\nCrampton, E. W. (1947). The Growth of the Odontoblasts of the Incisor Tooth as a Criterion of the Vitamin C Intake of the Guinea Pig: Five Figures. The Journal of Nutrition, 33(5), 491–504. https://doi.org/10.1093/jn/33.5.491\n\n\nDunn, O. J. (1964). Multiple comparisons using rank sums. Technometrics, 6(3), 241–252.\n\n\nFisher, R. (1921). On the ’probable error’ of a coeficient of correlation deduced from a small sample. Metron, 1, 3–32.\n\n\nFisher, R. A. (1925). Statistical methods for research workers. Oliver; Boyd.\n\n\nJaeger, T. F. (2008). Categorical data analysis: Away from ANOVAs (transformation or not) and towards logit mixed models. Journal of Memory and Language, 59(4), 434–446. https://doi.org/https://doi.org/10.1016/j.jml.2007.11.007\n\n\nKassambara, A. (2020). Ggpubr: ’ggplot2’ based publication ready plots. Retrieved from https://CRAN.R-project.org/package=ggpubr\n\n\nKristensen, M., & Hansen, T. (2004). Statistical analyses of repeated measures in physiological research: A tutorial. Advances in Physiology Education, 28(1), 2–14. https://doi.org/10.1152/advan.00042.2003\n\n\nKruskal, W. H., & Wallis, W. A. (1952). Use of ranks in one-criterion variance analysis. Journal of the American Statistical Association, 47(260), 583–621.\n\n\nLevy, K. J. (1978). An empirical comparison of the ANOVA f-test with alternatives which are more robust against heterogeneity of variance. Journal of Statistical Computation and Simulation, 8(1), 49–57. https://doi.org/10.1080/00949657808810247\n\n\nVasey, M. W., & Thayer, J. F. (1987). The continuing problem of false positives in repeated measures ANOVA in psychophysiology: A multivariate solution. Psychophysiology, 24(4), 479–486. https://doi.org/https://doi.org/10.1111/j.1469-8986.1987.tb00324.x\n\n\nWaring, E., Quinn, M., McNamara, A., Arino de la Rubia, E., Zhu, H., & Ellis, S. (2020). Skimr: Compact and flexible summaries of data. Retrieved from https://CRAN.R-project.org/package=skimr\n\n\nZimmerman, D. W. (1998). Invalidation of parametric and nonparametric statistical tests by concurrent violation of two assumptions. The Journal of Experimental Education, 67(1), 55–68. https://doi.org/10.1080/00220979809598344\n\n\nO número de testes pode ser calculado pela combinação de \\(n\\) grupos tomados 2 a 2 \\({n \\choose 2}\\), então para 3 grupos temos 3 testes, para 4 grupos 6 testes e assim por diante…↩︎\nTermo inglês: Family-wise error rate – FWER.↩︎\nSim, o mesmo Fisher da tutorial de \\(p\\)-valores. Mais uma contribuição crucial para a ciência e Estatística. Lembrando que Fisher possuía uma visão muito forte sobre etnia e raça preconizando a superioridade de certas etnias.↩︎\nTermo inglês: One-Way ANOVA.↩︎\nTermo inglês: Two-Way ANOVA.↩︎\nTermo inglês: Main Effects Two-Way ANOVA.↩︎\nTermo inglês: Interaction Effects Two-Way ANOVA.↩︎\nmatematicamente falando interação é uma multiplicação entre as duas variáveis independentes↩︎\nTermos inglês: Kruskal–Wallis test by ranks ou Kruskal–Wallis H test.↩︎\nTermo inglês: Repeated Measures ANOVA↩︎\nTermo inglês: Tukey’s HSD (honestly significant difference) test.↩︎\nTermo inglês: Dunn’s Test.↩︎\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "5-Correlacoes.html",
      "title": "Relação entre Variáveis -- Correlações",
      "description": "Como que descrevemos a força de associação entre duas variáveis.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nCorrelações e Desvio Padrão\nPressupostos da Correlação\nTipos de correlação\nQuando usar Kendall ou Spearman?\n\nComo mensurar correlações no R\nCalculando a medida de correlação entre duas variáveis\nRealizando um teste estatístico de hipótese nula sobre a correlação de duas variáveis\n\nParadoxo de Simpson\nPinguins de Palmer\nDados agregados\n\nComentários Finais\nAmbiente\n\n\nCorrelações nos indicam a magnitude de associação que duas variáveis possuem. É uma métrica simétrica, isto quer dizer que a correlação entre \\(X\\) e \\(Y\\), \\(\\text{corr}(X,Y)\\), é a mesma que a correlação entre \\(Y\\) e \\(X\\), \\(\\text{corr}(Y,X)\\). Além disso é uma métrica padronizada entre -1 e +1:\n-1: correlação negativa perfeita.\n+1: correlação positiva perfeita.\nCorrelações e Desvio Padrão\nDesvio padrão é uma métrica descritiva de uma variável que indica a magnitude de variação (dispersão de uma centralidade) que uma variável possui. Veja o exemplo da figura 1, na qual temos três distribuições Normais com a mesma média 0, porém com desvio padrões diferentes. Quanto maior o desvio padrão, maior será a variação de uma variável.\n\n\nlibrary(ggplot2)\nggplot(data.frame(x = c(-4, 4)), aes(x)) +\n  mapply(function(mean, sd, col) {\n    stat_function(fun = dnorm,\n                  args = list(mean = mean,\n                              sd = sd),\n                  aes(col = col), size = 3)\n  },\n  mean = rep(0, 3),\n  sd = c(1, .5, 2),\n  col = c(\"1\", \"0.5\", \"2\")) +\n  scale_colour_brewer(\"Desvio\\nPadrão\", palette = \"Set1\",\n                      guide = guide_legend(ncol = 1,\n                                           nrow = 3,\n                                           byrow = TRUE))\n\n\n\n\nFigure 1: Distribuições Normais com diferentes Desvios Padrões\n\n\n\nA correlação mensura o quanto de variação em unidades de desvio padrão duas variáveis estão associadas. Por exemplo, uma correlação de +0.8 indica que conforme \\(X\\) varia 1 desvio padrão, observa-se uma variação de 0.8 desvio padrão em \\(Y\\) e vice-versa1. Na figura 2 é possível visualizar diagramas de dispersão de simulações com 50 observações de diferentes correlações acompanhadas de linhas de tendência em vermelho. No topo de cada diagrama de dispersão é possível ver a magnitude da correlação utilizada na simulação.\n\n\ncorrelação <- seq(-1, 1, 0.2)\n\nx <- 1:50\ny <- rnorm(50, sd = 10)\n\ncomplemento <- function(y, correlação, x) {\n  y.perp <- residuals(lm(x ~ y))\n  correlação * sd(y.perp) * y + y.perp * sd(y) * sqrt(1 - correlação^2)\n}\n\nX <- data.frame(z = as.vector(sapply(correlação,\n                                     function(correlação) complemento(y, correlação, x))),\n                correlação = ordered(rep(signif(correlação, 2),\n                                         each = length(y))),\n                y = rep(y, length(correlação)))\nggplot(X, aes(y, z, group = correlação)) +\n  geom_rug(sides = \"b\") +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", color = \"Red\", se = FALSE) +\n  facet_wrap(~ correlação, scales = \"free\", labeller = \"label_both\", ncol = 4) +\n  theme(legend.position = \"none\")\n\n\n\n\nFigure 2: Diagramas de Dispersão com linhas de tendências para as diversas correlações\n\n\n\nPressupostos da Correlação\nCorrelação deve ser aplicada somente em variáveis contínuas, intervalares ou ordinais. Correlação não podem ser usadas para variáveis nominais (também chamada de categóricas). A lógica por trás desse pressuposto é que magnitudes de associação somente podem ser mensuradas em variáveis que de alguma maneira sejam “mensuráveis e comparáveis numericamente” entre si.\nAlém disso, as variáveis tem que possuir um critério de linearidade entre elas. Isto quer dizer que quanto mais/menos de x mais/menos de y. Este conceito fica mais claro ao ser visualizado. Na figura 3 é possível ver duas relações entre variáveis x e y: à esquerda, uma relação linear; e à direita, uma relação não-linear.\n\n\n\nFigure 3: Linearidade vs Não-Linearidade\n\n\n\nTipos de correlação\nAté agora todas as correlações que mostramos são correlações de Pearson pois é o tipo de correlação padrão do R. Temos três tipos de correlações que são comumente empregadas:\nCorrelação de Pearson2 (Pearson, 1895): a correlação de Pearson é a correlação mais utilizada em análises estatísticas. Ela é uma técnica paramétrica e possui o pressuposto de que ambas as variáveis são distribuídas conforme uma distribuição Normal. Caso tenha dados que violem o pressuposto da normalidade, correlação de Pearson não é o tipo de correlação que você deva usar.\nCorrelação de Spearman3 (Spearman, 1904): a correlação de Spearman é uma técnica não-paramétrica, sendo a alternativa quando os dados violam o pressuposto de normalidade, pois não faz nenhuma suposição que os dados estejam distribuídos de acordo com uma distribuição específica.\nCorrelação de Kendall4 (Kendall, 1938): Assim, como a correlação de Spearman, a correlação de Kendall também é uma técnica não-paramétrica. Sendo também uma alternativa viável quando os dados violam o pressuposto de normalidade, pois não faz nenhuma suposição que os dados estejam distribuídos de acordo com uma distribuição específica.\n\n\n\nFigure 4: Da esquerda para direita: Karl Pearson, Charles Spearman e Maurice Kendall – Figuras de https://www.wikipedia.org\n\n\n\nQuando usar Kendall ou Spearman?\nAmbas devem ser usadas quando o pressuposto de normalidade para ambas ou qualquer uma das variáveis que estão sendo correlacionadas for violado.\nSugerimos usar a correlação de Kendall, especialmente quando estamos tratando de amostras pequenas (\\(n < 100\\)) (Reynolds, 1977). Porém, há alguns cenários que a correlação de Spearman é melhor indicada, conforme Khamis (2008): “Se a variável ordinal, \\(Y\\), tem um grande número de níveis (digamos, cinco ou seis ou mais), então pode-se usar o coeficiente de correlação de classificação de Spearman para medir a força da associação entre \\(X\\) e \\(Y\\)”5.\nAlém disso, as duas divergem em custo computacional. Isto pode ser um critério de decisão caso estejam lidando com um vasto número de observações. O cálculo da correlação de Kendall possui complexidade computacional na ordem de \\(O(n^2)\\), enquanto que o cálculo da correlação de Spearman possui complexidade computacional na ordem de \\(O(n \\log n)\\), sendo \\(n\\) o tamanho da amostra.\nComo mensurar correlações no R\nNo R é possível mensurar correlações de duas maneiras:\nCalculando a medida de correlação entre duas variáveis.\nRealizando um teste estatístico de hipótese nula sobre a correlação de duas variáveis.\nAntes de apresentar os dois métodos, vamos simular6 dois cenários de relações bivariadas. O primeiro cenário contém duas distribuições Normais com médias diferentes porém com uma correlação especificada em 0.6. O segundo cenário contém duas distribuições \\(t\\) de Student7 com a mesma correlação especificada em 0.6. Usaremos a biblioteca {mnormt} (Qu, Liu, & Zhang, 2019), que é específica para gerar distribuições multivariadas Normais e não-Normais.\n\n\nlibrary(mnormt)\n\nmedias <- c(0, 10)\ncovariancias <- matrix(c(1, 0.6, 0.6, 1), 2, 2)\n\nmv_normal <- as.data.frame(rmnorm(50, medias, covariancias))\nmv_student <- as.data.frame(rmt(50, medias, covariancias, df = 1))\n\n\n\nPara verificar se os pressupostos não serão violados, usaremos o teste de Shapiro-Wilk usando a função shapiro.test() em ambos cenários. Lembrando que a \\(H_0\\) do teste de Shapiro-Wilk é de que “os dados são distribuídos conforme uma distribuição Normal.”\n\n\nshapiro.test(mv_normal$V1)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  mv_normal$V1\nW = 0.97314, p-value = 0.3092\n\nshapiro.test(mv_normal$V2)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  mv_normal$V2\nW = 0.97163, p-value = 0.2693\n\nComo podem ver, ambos os testes para as distribuições multivariadas Normais geram \\(p\\)-valores acima de 0.05 o que faz com que falhemos em rejeitar a hipótese nula de que “os dados são distribuídos conforme uma distribuição Normal.”\n\n\nshapiro.test(mv_student$V1)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  mv_student$V1\nW = 0.7176, p-value = 1.737e-08\n\nshapiro.test(mv_student$V2)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  mv_student$V2\nW = 0.4848, p-value = 5.307e-12\n\nComo podem ver, ambos os testes para as distribuições multivariadas \\(t\\) de Student geram \\(p\\)-valores abaixo de 0.05 o que faz com que a hipótese nula de que “os dados são distribuídos conforme uma distribuição Normal” é rejeitada.\nCalculando a medida de correlação entre duas variáveis\nPara calcular a correlação de duas variáveis usamos a função padrão do R cor(). Devemos usar como argumento das duas variáveis que queremos calcular a correlação e como terceiro argumento o tipo de correlação que queremos8:\nmethod = \"pearson\" – Correlação de Pearson.\nmethod = \"spearman\" – Correlação de Spearman.\nmethod = \"kendall\" – Correlação de Kendall.\nPrimeiro cenário, distribuições Normais, técnica paramétrica de correlação de Pearson:\n\n\ncor(mv_normal$V1, mv_normal$V2, method = \"pearson\")\n\n\n[1] 0.6156231\n\nSegundo cenário, distribuições não-Normais, técnica não-paramétrica de correlação de Spearman:\n\n\ncor(mv_student$V1, mv_student$V2, method = \"spearman\")\n\n\n[1] 0.6829772\n\nSegundo cenário, distribuições não-Normais, técnica não-paramétrica de correlação de Kendall:\n\n\ncor(mv_student$V1, mv_student$V2, method = \"kendall\")\n\n\n[1] 0.5036735\n\nRealizando um teste estatístico de hipótese nula sobre a correlação de duas variáveis\nAlém de computarmos o valor da correlação entre duas variáveis, é possível também realizar um teste estatístico de hipótese nula sobre a correlação de duas variáveis. A hipótese nula \\(H_0\\) nesse caso é de que “as variáveis possuem correlação igual a zero”.\nPara fazermos um teste de hipótese de correlação usamos a função padrão do R cor.test() que funciona similar à cor(). Devemos usar como argumento das duas variáveis que queremos calcular a correlação e como terceiro argumento o tipo de correlação que queremos9:\nmethod = \"pearson\" – Correlação de Pearson.\nmethod = \"spearman\" – Correlação de Spearman.\nmethod = \"kendall\" – Correlação de Kendall.\nO output de cor.test() inclui um \\(p\\)-valor, mas somente a correlação de Pearson possui um intervalo de confiança padrão 95% (podendo ser alterado para outras porcentagens caso necessário). Notem que a intuição aqui é que o \\(p\\)-valor é probabilidade de obter resultados no mínimo tão extremos quanto os que foram observados, dado que a hipótese nula é verdadeira (\\(H_0\\): correlação entre as variáveis é zero/nula); e o intervalo de confiança expressa a frequência de longo-prazo que você esperaria obter de uma correlação caso replicasse o teste estatístico para diversas amostras da mesma população (nesse caso 95% das amostras de mesmo tamanho que a nossa, \\(n = 50\\), da mesma população-alvo, aplicando o mesmo teste estatístico de correlação, esperaríamos encontrar uma correlação entre os limites inferiores e superiores do intervalo de confiança).\nPrimeiro cenário, distribuições Normais, técnica paramétrica de correlação de Pearson:\n\n\ncor.test(mv_normal$V1, mv_normal$V2, method = \"pearson\")\n\n\n\n    Pearson's product-moment correlation\n\ndata:  mv_normal$V1 and mv_normal$V2\nt = 5.4124, df = 48, p-value = 1.954e-06\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4070214 0.7631922\nsample estimates:\n      cor \n0.6156231 \n\nNote que aqui temos um \\(p\\)-valor significante e um tamanho de efeito entre 0.4070214 e 0.7631922.\nSegundo cenário, distribuições não-Normais, técnica não-paramétrica de correlação de Spearman:\n\n\ncor.test(mv_student$V1, mv_student$V2, method = \"spearman\")\n\n\n\n    Spearman's rank correlation rho\n\ndata:  mv_student$V1 and mv_student$V2\nS = 6602, p-value = 1.519e-07\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6829772 \n\nAqui também temos um \\(p\\)-valor significante.\nSegundo cenário, distribuições não-Normais, técnica não-paramétrica de correlação de Kendall:\n\n\ncor.test(mv_student$V1, mv_student$V2, method = \"kendall\")\n\n\n\n    Kendall's rank correlation tau\n\ndata:  mv_student$V1 and mv_student$V2\nz = 5.1611, p-value = 2.455e-07\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.5036735 \n\nAqui também temos um \\(p\\)-valor significante.\nParadoxo de Simpson\nO paradoxo de Simpson é um fenômeno que surge na análise de dados, que se não for considerado pode levar a conclusões espúrias ou previsões enganosas (Pearl, 2014; Simpson, 1951). A ideia geral do paradoxo é que um conjunto de dados em geral pode parecer uma tendência em uma direção (positiva ou negativa), mas tender na direção oposta quando dividido por subgrupos. Isso é problemático porque olhar para dados agregados pode levar a acreditar que os dados têm uma associação positiva/negativa para todos os grupos, porém ao subdividirmos os dados em subgrupos e analisarmos as associações vemos que a tendência que era positiva/negativa é totalmente revertida.\nO paradoxo de Simpson já ocorreu em cenários como: estudo de viés de gênero na entrada de alunos de mestrado e doutorado em UC Berkeley (Bickel, Hammel, & O’Connell, 1975); estudo médico sobre tratamento de pedra de rim (Julious & Mullee, 1994); análise de médias de rebatidas em Baseball (Ross, 2007); análise da disparidade racial em penas de morte (Radelet, 1981); entre outros…\nPinguins de Palmer\nPara ilustrar o paradoxo de Simpson, vamos usar o dataset sobre pinguins que foram encontrados próximos da estação de Palmer na Antártica. O dataset pode ser carregado pela biblioteca {palmerpenguins} (Horst, Hill, & Gorman, 2020). Nós, sempre que carregamos um dataset no R, temos o costume de usar a biblioteca {skimr} (Waring et al., 2020) para produzir um sumário dos dados.\n\n\nlibrary(magrittr)\nlibrary(palmerpenguins)\nlibrary(skimr)\npenguins <- penguins %>% na.omit()\nskim(penguins)\n\n\nTable 1: Data summary\nName\npenguins\nNumber of rows\n333\nNumber of columns\n8\n_______________________\n\nColumn type frequency:\n\nfactor\n3\nnumeric\n5\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nspecies\n0\n1\nFALSE\n3\nAde: 146, Gen: 119, Chi: 68\nisland\n0\n1\nFALSE\n3\nBis: 163, Dre: 123, Tor: 47\nsex\n0\n1\nFALSE\n2\nmal: 168, fem: 165\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nbill_length_mm\n0\n1\n43.99\n5.47\n32.1\n39.5\n44.5\n48.6\n59.6\n▃▇▇▆▁\nbill_depth_mm\n0\n1\n17.16\n1.97\n13.1\n15.6\n17.3\n18.7\n21.5\n▅▆▇▇▂\nflipper_length_mm\n0\n1\n200.97\n14.02\n172.0\n190.0\n197.0\n213.0\n231.0\n▂▇▃▅▃\nbody_mass_g\n0\n1\n4207.06\n805.22\n2700.0\n3550.0\n4050.0\n4775.0\n6300.0\n▃▇▅▃▂\nyear\n0\n1\n2008.04\n0.81\n2007.0\n2007.0\n2008.0\n2009.0\n2009.0\n▇▁▇▁▇\n\nComo vocês podem verificar, temos observações de três espécies de pinguins:\nAdelie – 146 observações.\nChinstrap – 68 observações.\nGentoo – 119 observações.\nNa figura 5 é possível observar duas ilustrações: à esquerda as três diferentes espécies de pinguins observadas no dataset e à direita ilustrando o significado das variáveis comprimento de bico bill_length_mm e altura de bicobill_depth_mm.\n\n\n\nFigure 5: Da esquerda para direita: as diferentes espécies de pinguins Palmer e ilustração do bico do pinguim – Figuras de https://allisonhorst.github.io/palmerpenguins\n\n\n\nDados agregados\nPara iniciar a exemplificação do paradoxo de Simpson, mostraremos os dados agregados da associação entre o comprimento do bico bill_length_mm e a altura do bico bill_depth_mm dos pinguins, ambos mensurados em milímetros e independente de espécie. Na figura 6 é possível ver um diagrama de dispersão do comprimento e altura dos bicos dos pinguins, independente de espécie, e com uma linha de tendência em azul. A correlação, por esse gráfico de dispersão, mostra uma associação negativa entre comprimento e altura do bico. E, agora, perguntamos: isto faz sentido? Vocês acreditam que essa associação é realmente negativa: quanto maior o comprimento do bico menor a altura do bico?\n\n\npenguins %>%\n  ggplot(aes(bill_length_mm, bill_depth_mm)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, size = 2)  +\n  labs(x = \"comprimento do bico\",\n       y = \"altura do bico\",\n       caption = \"dados agregados\")\n\n\n\n\nFigure 6: Diagrama de dispersão agregado do comprimento e altura dos bicos dos pinguins\n\n\n\nVeja o que acontece quando dividimos os dados por subgrupos (no caso espécies). Na figura 7 é possível ver um diagrama de dispersão do comprimento e altura dos bicos dos pinguins, subdividos em espécie por cor, e com uma linha de tendência na cor de cada espécie. A correlação, por esse gráfico de dispersão, mostra uma associação positiva entre comprimento e altura do bico quando consideramos espécie.\n\n\npenguins %>%\n  ggplot(aes(bill_length_mm, bill_depth_mm, color = species)) +\n  geom_point() +\n  geom_smooth(aes(group = species), method = \"lm\", se = FALSE, size = 2)  +\n  labs(x = \"comprimento do bico\",\n       y = \"altura do bico\",\n       caption = \"dados subdividos por espécie\") +\n  scale_color_brewer(\"Espécie\", palette = \"Set1\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\nFigure 7: Diagrama de dispersão subdividido em espécies do comprimento e altura dos bicos dos pinguins\n\n\n\nComentários Finais\nA correlação é uma métrica extremamente útil para quantificar a magnitude de associação entre duas variáveis. Porém, são necessários alguns cuidados.\nSobre as técnicas de correlação em si, precisamos estar atentos a quais tipos de dados que temos. Caso as variáveis que desejamos correlacionar possuam uma distribuição similar à distribuição Normal (teste de Shapiro-Wilk com \\(p\\)-valor acima de 0.05) podemos usar a correlação de Pearson; caso contrário teremos que usar uma técnica de correlação não-paramétrica e escolher entre correlação de Spearman ou correlação de Kendall.\nSobre a interpretação das correlações e associações, não se esqueça do mantra da tutorial 2 sobre \\(p\\)-valores: “correlação não é causalidade.” Além disso, se atentem ao paradoxo de Simpson, especialmente quando estiverem com dados que podem ser subdividos em grupos.\nCaso tenha sido intrigado pelo paradoxo de Simpson, não deixe de olhar o nosso conteúdo auxiliar sobre o quarteto de Anscombe.\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] palmerpenguins_0.1.0 magrittr_2.0.1       mnormt_2.0.2        \n [4] cowplot_1.1.1        tidyr_1.1.2          DescTools_0.99.40   \n [7] skimr_2.1.2          ggpubr_0.4.0         car_3.0-10          \n[10] carData_3.0-4        patchwork_1.1.1      dplyr_1.0.4         \n[13] ggplot2_3.3.3        DiagrammeR_1.0.6.1   readxl_1.3.1        \n\nloaded via a namespace (and not attached):\n [1] nlme_3.1-149       lubridate_1.7.9.2  RColorBrewer_1.1-2\n [4] rprojroot_2.0.2    ggsci_2.9          repr_1.1.3        \n [7] tools_4.0.3        backports_1.2.1    utf8_1.1.4        \n[10] R6_2.5.0           mgcv_1.8-33        DBI_1.1.1         \n[13] colorspace_2.0-0   withr_2.4.1        tidyselect_1.1.0  \n[16] Exact_2.1          downlit_0.2.1      curl_4.3          \n[19] compiler_4.0.3     cli_2.3.0          expm_0.999-6      \n[22] xml2_1.3.2         labeling_0.4.2     bookdown_0.21     \n[25] scales_1.1.1       mvtnorm_1.1-1      stringr_1.4.0     \n[28] digest_0.6.27      foreign_0.8-80     rmarkdown_2.6     \n[31] rio_0.5.16         base64enc_0.1-3    pkgconfig_2.0.3   \n[34] htmltools_0.5.1.1  highr_0.8          htmlwidgets_1.5.3 \n[37] rlang_0.4.10       rstudioapi_0.13    visNetwork_2.0.9  \n[40] farver_2.0.3       generics_0.1.0     jsonlite_1.7.2    \n[43] zip_2.1.1          distill_1.2        Matrix_1.2-18     \n[46] Rcpp_1.0.6         munsell_0.5.0      fansi_0.4.2       \n[49] abind_1.4-5        reticulate_1.18    lifecycle_0.2.0   \n[52] stringi_1.5.3      yaml_2.2.1         rootSolve_1.8.2.1 \n[55] MASS_7.3-53        grid_4.0.3         forcats_0.5.1     \n[58] crayon_1.4.1       lmom_2.8           lattice_0.20-41   \n[61] splines_4.0.3      haven_2.3.1        hms_1.0.0         \n[64] tmvnsim_1.0-2      magick_2.6.0       knitr_1.31        \n[67] pillar_1.4.7       boot_1.3-25        gld_2.6.2         \n[70] ggsignif_0.6.0     glue_1.4.2         evaluate_0.14     \n[73] data.table_1.13.6  vctrs_0.3.6        cellranger_1.1.0  \n[76] gtable_0.3.0       purrr_0.3.4        assertthat_0.2.1  \n[79] xfun_0.21          openxlsx_4.2.3     broom_0.7.4       \n[82] e1071_1.7-4        rstatix_0.6.0      class_7.3-17      \n[85] tibble_3.0.6       ellipsis_0.3.1    \n\n\n\n\nBickel, P. J., Hammel, E. A., & O’Connell, J. W. (1975). Sex bias in graduate admissions: Data from berkeley. Science, 187(4175), 398–404.\n\n\nHorst, A. M., Hill, A. P., & Gorman, K. B. (2020). Palmerpenguins: Palmer archipelago (antarctica) penguin data. Retrieved from https://allisonhorst.github.io/palmerpenguins/\n\n\nJulious, S. A., & Mullee, M. A. (1994). Confounding and simpson’s paradox. BMJ, 309(6967), 1480–1481.\n\n\nKendall, M. G. (1938). A new measure of rank correlation. Biometrika, 30(1/2), 81–93.\n\n\nKhamis, H. (2008). Measures of association: How to choose? Journal of Diagnostic Medical Sonography, 24(3), 155–162.\n\n\nPearl, J. (2014). Comment: Understanding simpson’s paradox. The American Statistician, 68(1), 8–13.\n\n\nPearson, K. (1895). Notes on regression and inheritance in the case of two parents. Proceedings of the royal society of london, 58, 240–242. Royal Society of London.\n\n\nQu, W., Liu, H., & Zhang, Z. (2019). A method of generating multivariate non-normal random numbers with desired multivariate skewness and kurtosis. Behavior Research Methods, 1–8.\n\n\nRadelet, M. L. (1981). Racial characteristics and the imposition of the death penalty. American Sociological Review, 918–927.\n\n\nReynolds, H. T. (1977). The analysis of cross-classifications. Free Press New York.\n\n\nRoss, K. (2007). A mathematician at the ballpark: Odds and probabilities for baseball fans. Penguin.\n\n\nSimpson, E. H. (1951). The interpretation of interaction in contingency tables. Journal of the Royal Statistical Society: Series B (Methodological), 13(2), 238–241.\n\n\nSpearman, C. (1904). The proof and measurement of association between two things. American Journal of Psychology, 15, 72–101.\n\n\nWaring, E., Quinn, M., McNamara, A., Arino de la Rubia, E., Zhu, H., & Ellis, S. (2020). Skimr: Compact and flexible summaries of data. Retrieved from https://CRAN.R-project.org/package=skimr\n\n\ncorrelação é uma medida simétrica↩︎\ntambém chamado de \\(r\\) de Pearson↩︎\ntambém chamado de \\(\\rho\\) (letra grega rho) de Spearman↩︎\ntambém chamado de \\(\\tau\\) (letra grega tau) de Kendall↩︎\noriginal em inglês: If the ordinal variable, \\(Y\\), has a large number of levels (say, five or six or more), then one may use the Spearman rank correlation coefficient to measure the strength of association between \\(X\\) and \\(Y\\).↩︎\nsim, adoramos simulações, como vocês já devem ter percebido.↩︎\nestamos especificando 1 grau de liberdade↩︎\nesse argumento é opcional e caso não seja especificado cor() usará como padrão method = \"pearson\"↩︎\nesse argumento é opcional e caso não seja especificado cor.test() usará como padrão method = \"pearson\"↩︎\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "6-Regressao_Linear.html",
      "title": "Regressão Linear",
      "description": "Como mensurar efeitos de diversas variáveis independentes sobre uma variável dependente contínua.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nInterpretações\nInterpretação Geométrica\nInterpretação Matemática\nInterpretação Estatística\n\nHistória da Regressão\nPressupostos da Regressão Linear\nComo aplicar uma Regressão Linear no R\nInterpretação dos Coeficientes\nVariáveis Qualitativas\nEfeitos Principais e Efeitos de Interação\nEfeitos Não-Lineares\nVisualização de Regressão Linear\nVerificação de Pressupostos\n\n\\(R^2\\) e \\(R^2\\) ajustado\nCoeficientes Brutos versus Padronizados\nConexões com o Teste \\(t\\), ANOVA e Correlações\nTécnicas Avançadas de Regressão Linear\nRegressão Robusta\nRegressão Regularizada\nRegressão Aditiva - Modelos Aditivos Generalizados\nRegressão Multinível\n\nComentários Finais\nAmbiente\n\n\nMuitas vezes precisamos de técnicas que tolerem varíaveis independentes contínuas. Não conseguimos usar ANOVA pois as variáveis independentes são discretas e representam grupos distintos de observações (uma variável independente – Anova Unidireacional, duas variáveis independentes – Anova Bidirecional, etc.). Muito menos teste \\(t\\), pois segue o mesmo princípio da ANOVA mas se restringindo a apenas dois grupos, ou seja, apenas variável independente categórica binária. Para isso temos a técnica de Regressão Linear.\n\nRegressão Linear é a técnica preferida do autor 1\nRegressão linear permite com que você use uma ou mais variáveis discretas ou contínuas como variáveis independentes e mensurar o poder de associação com a variável dependente, que deve ser contínua1.\nInterpretações\nPara compreender regressão linear podemos usar de três interpretações distintas mas complementares:\nInterpretação Geométrica: Regressão como uma reta.\nInterpretação Matemática: Regressão como otimização.\nInterpretação Estatística: Regressão como poder de associação entre variáveis controlando para diversos outros efeitos.\nEssas interpretações descrevem a mesma técnica mas sob aspectos diferentes. Lembra um pouco a metáfora dos sete sábios e o elefante (figura 1):\n\nNuma pequena cidade viviam sete sábios cegos. Por conta de sua reconhecida sabedoria, as pessoas os procuravam em busca de conselhos para solução de seus problemas. Apesar de amigos, os sábios mantinham entre si uma competitividade acirrada, discutiam o tempo todo tentando provar quem era o mais sábio. Um dia trouxeram um elefante para a cidade. Os cegos rodearam o elefante para tocá-lo. Cada um pegou em uma parte distinta do animal e o descreve de acordo com aquela parte. Eles estão descrevendo o mesmo animal, mas cada um descrevendo apenas uma parte e pensando que é o todo. Eles estão, ao mesmo tempo, certos e errados2.\n\n\n\n\nFigure 1: Os Sete Sábios e o Elefante. Figura de https://nsjour.wordpress.com/2012/10/21/seven-blind-men-and-the-elephant/\n\n\n\nInterpretação Geométrica\nImagine que seus dados são pontos que vivem em um espaço multidimensional. A regressão é uma técnica para encontrar a melhor reta3 entre o conjunto de dados levando em conta todas as observações.\nIsto é valido para qualquer espaço multidimensional, até para além de 3-D. Vamos mostrar um exemplo em 2-D da relação entre x e y4, mas isto poder ser estendido para a relação x1, x2, … e y.\n\n\n\nFigure 2: Uma relação entre variáveis representada por uma reta de tendência\n\n\n\nVejam que regressão linear usando apenas uma variável dependente e uma variável independente é a mesma coisa que que correlação5.\nInterpretação Matemática\nA interpretação matemática é vista como uma otimização: encontrar a melhor reta entre os pontos que minimiza o erro quadrático médio (mean squared error – MSE). Ao escolhermos a melhor reta, devemos escolher a melhor reta que minimiza as distâncias entre os pontos, sendo que podemos errar para mais ou para menos. Para evitarmos que os erros se cancelem, precisamos eliminar o sinal negativo de alguns erros e convertê-los para valores positivos. Para isso, pegamos todas os erros (diferenças entre o valor previsto pela reta e o valor verdadeiro) e elevamos ao quadrado (assim todo número negativo se tornará positivo e todo positivo se manterá positivo)6. Portanto, a regressão se torna a busca do menor valor de uma função erro (MSE)7.\n\n\n\nFigure 3: A melhor reta que minimiza a distância dos erros\n\n\n\nInterpretação Estatística\nA regressão linear usando uma única variável independente contínua se torna exatamente uma correlação8. Agora quando empregamos mais de uma variável independente, a interpretação da regressão se torna: “O efeito de X em Y mantendo Z fixo”. Isto quer dizer que a regressão linear controla os efeitos das diferentes variáveis independentes ao calcular o efeito de uma certa variável independente. Esta é o que chamamos de interpretação estatística da regressão linear.\nPor exemplo, digamos que você esteja em busca dos fatores que acarretam ataque cardíaco. Você coleta dados de pessoas que quantifiquem as seguintes variáveis: sono, stress, tabagismo, sedentarismo, entre outros… A regressão te permite mensurar o efeito de qualquer uma dessas variáveis na prevalência de ataque cardíaco controlando para outros efeitos. Em outras palavras, é possível mensurar o efeito de stress em ataque cardíaco, mantendo fixo os efeitos de sono, tabagismo, sedentarismo, etc… Isso permite você isolar o efeito de uma variável sem deixar que outras variáveis a influenciem na mensuração da sua relação com a variável dependente (no nosso caso: ataque cardíaco).\nHistória da Regressão\nO termo “regressão” foi cunhado por Francis Galton no século XIX para descrever um fenômeno biológico. O fenômeno era que as alturas dos descendentes de ancestrais altos tendem a regredir para uma média normal (um fenômeno também conhecido como regressão em direção à média) (Galton, 1890). Para Galton, a regressão tinha apenas este significado biológico [@ galton1877typical], mas seu trabalho foi posteriormente estendido por Udny Yule (Yule, 1897) e Karl Pearson (Pearson, 1903) para um contexto estatístico mais geral.\n\n\n\nFigure 4: Da esquerda para direita: Francis Galton, Karl Pearson e Udny Yule – Figuras de https://www.wikipedia.org\n\n\n\nPressupostos da Regressão Linear\nPara interpretar os resultados de uma regressão como uma quantidade estatística significativa que mede os relacionamentos do mundo real, precisamos contar com uma série de suposições clássicas. Os quatro principais pressupostos da regressão são:\nIndependência dos Dados: o valor de uma observação não influencia ou afeta o valor de outras observações. Este é o pressuposto clássico de todas as técnicas abordadas até agora.\nLinearidade dos Dados: a relação entre as variáveis independentes e a variável dependente é considerada linear (quanto mais/menos de uma, mais/menos de outra). Linearidade dos Dados pode ser verificada graficamente observando a dispersão dos resíduos com os valores previstos pela regressão.\nIndependência dos Erros / Resíduos: os erros (também chamados de resíduos) não devem possuir correlação. Este pressuposto pode ser testado pelo teste de Durbin-Watson e observando o gráfico quantil-quantil (Q-Q) dos resíduos padronizados.\nHomogeneidade de Variância dos Erros / Resíduos: os erros devem ter média zero e desvio padrão constante ao longo das observações. Similar ao teste de Levene, mas aplicado aos resíduos da regressão. Pode ser testado usando o Teste de Breusch-Pagan.\nAusência de Multicolinearidade: multicolinearidade é a ocorrência de alta correlação entre duas ou mais variáveis independentes e pode levar a resultados distorcidos. Em geral, a multicolinearidade pode fazer com que os intervalos de confiança se ampliem, ou até mudar o sinal de influência das variáveis independentes (de positivo para negativo, por exemplo). Portanto, as inferências estatísticas de uma regressão com multicolinearidade não são confiáveis. Pode ser testado usando o Fator de Inflação de Variância (Variance Inflation Factor – VIF).\nComo aplicar uma Regressão Linear no R\nPara exemplificar as regressões nesse tutorial, usaremos o dataset já incluído no R mtcars (Henderson & Velleman, 1981). mtcars é uma base de dados extraída da revista americana sobre carros Motor Trend US de 1974. Possui 32 observações de carros e 11 variáveis:\nmpg: Milhas por Galão (consumo)\ncyl: Número de cilíndros\ndisp: Cilindrada (em polegada cúbica)\nhp: Cavalos de Potência (HP)\ndrat: Relação do eixo traseiro\nwt: Peso em (1,000 libras)\nqsec: Tempo que atinge 400m (1/4 de milha)\nvs: Motor (0 = Forma em V, 1 = Reto)\nam: Transmissão (0 = Automático, 1 = Manual)\ngear: Número de marchas\ncarb: Número de carburadores\n\n\nlibrary(skimr)\ndata(mtcars)\nskim(mtcars)\n\n\nTable 1: Data summary\nName\nmtcars\nNumber of rows\n32\nNumber of columns\n11\n_______________________\n\nColumn type frequency:\n\nnumeric\n11\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nmpg\n0\n1\n20.09\n6.03\n10.40\n15.43\n19.20\n22.80\n33.90\n▃▇▅▁▂\ncyl\n0\n1\n6.19\n1.79\n4.00\n4.00\n6.00\n8.00\n8.00\n▆▁▃▁▇\ndisp\n0\n1\n230.72\n123.94\n71.10\n120.83\n196.30\n326.00\n472.00\n▇▃▃▃▂\nhp\n0\n1\n146.69\n68.56\n52.00\n96.50\n123.00\n180.00\n335.00\n▇▇▆▃▁\ndrat\n0\n1\n3.60\n0.53\n2.76\n3.08\n3.70\n3.92\n4.93\n▇▃▇▅▁\nwt\n0\n1\n3.22\n0.98\n1.51\n2.58\n3.33\n3.61\n5.42\n▃▃▇▁▂\nqsec\n0\n1\n17.85\n1.79\n14.50\n16.89\n17.71\n18.90\n22.90\n▃▇▇▂▁\nvs\n0\n1\n0.44\n0.50\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▆\nam\n0\n1\n0.41\n0.50\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▆\ngear\n0\n1\n3.69\n0.74\n3.00\n3.00\n4.00\n4.00\n5.00\n▇▁▆▁▂\ncarb\n0\n1\n2.81\n1.62\n1.00\n2.00\n2.00\n4.00\n8.00\n▇▂▅▁▁\n\nPara aplicar uma regressão linear no R usamos a função lm() (linear model) padrão do R. Sua funcionalidade é muito similar à outras funções que já vimos de teste de hipótese, sendo que é necessário fornecer dois argumentos:\nFórmula designando a variável dependente e a(s) variável(eis) independente(s) designada pela seguinte síntaxe: dependente ~ independente_1 + independente_2 + ....\nO dataset no qual deverá ser encontradas as variáveis presentes na fórmula.\nComeçaremos com um exemplo simples de regressão do mtcars usando como variável independente mpg e variáveis independentes hp e wt. Podemos inspecionar o resultado de uma regressão linear com a função summary().\n\n\nmodelo_simples <- lm(mpg ~ hp + wt, data = mtcars)\nsummary(modelo_simples)\n\n\n\nCall:\nlm(formula = mpg ~ hp + wt, data = mtcars)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.941 -1.600 -0.182  1.050  5.854 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 37.22727    1.59879  23.285  < 2e-16 ***\nhp          -0.03177    0.00903  -3.519  0.00145 ** \nwt          -3.87783    0.63273  -6.129 1.12e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.593 on 29 degrees of freedom\nMultiple R-squared:  0.8268,    Adjusted R-squared:  0.8148 \nF-statistic: 69.21 on 2 and 29 DF,  p-value: 9.109e-12\n\nInterpretação dos Coeficientes\nNa saída de summary() podemos ver que são produzidos os coeficientes da regressão na coluna Estimate, associados ao respectivos desvio padrão dos resíduos Std. Error e \\(p\\)-valores Pr(>|t|). Importante destacar que a hipótese nula dos coeficientes da regressão é de que “os coeficientes são nulos/zeros”, então os \\(p\\)-valores devem ser interpretados como a probabilidade de observamos valores de coeficientes tão extremos dado que a hipótese nula é verdadeira. Para facilitar, o R informa com asteriscos quais variáveis possuem coeficientes estatisticamente significantes: * para \\(p < 0.05\\), ** para \\(p < 0.01\\), e *** para \\(p < 0.001\\).\nOs coeficientes de objetos lm devem ser interpretados em escala bruta na qual o acréscimo de 1 unidade da variável independente gera o aumento de <coeficiente> unidade(s) da variável dependente. No nosso exemplo, a cada acréscimo de 1 hp, mpg reduz em -0.0317729; e a cada acréscimo de 1 wt, mpg reduz em -3.8778307. Além disso, a regressão linear controla os efeitos de outras variáveis independente. Então o impacto de hp em mpg no nosso exemplo controla o efeito de wt, matendo-o fixo ao calcular o coeficiente de hp.\nO coeficiente (Intercept) é o que chamamos de constante (intercept) da regressão. A constante representa o valor médio da variável dependente quando todas as variáveis independentes possuem valor nulo (zero). No nosso exemplo, as observações possuem em média 37.2272701 mpg quando tanto hp e wt são 0.\nNote que podemos produzir intervalos de confiança usando a função padrão do R confint() inserindo como argumento um objeto lm. confint() como padrão produz intervalos de confiança 95%.\n\n\nconfint(modelo_simples)\n\n\n                  2.5 %      97.5 %\n(Intercept) 33.95738245 40.49715778\nhp          -0.05024078 -0.01330512\nwt          -5.17191604 -2.58374544\n\nVariáveis Qualitativas\nAlém de variáveis independentes quantitativas, regressão linear também permite utilizarmos variáveis qualitativas (discretas) como variáveis independentes.\nVamos estender o nosso modelo simples adicionando a variável am. Note que vamos convertê-la para qualitativa (factor) usando a função padrão do R as.factor(), Isto é necessário para que o R interprete am como fator (nomenclatura do R para variáveis qualitativas).\n\n\nmodelo_quali <- mtcars %>%\n  mutate(am = as.factor(am)) %>%\n  lm(mpg ~ hp + wt + am, data = .)\nsummary(modelo_quali)\n\n\n\nCall:\nlm(formula = mpg ~ hp + wt + am, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4221 -1.7924 -0.3788  1.2249  5.5317 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 34.002875   2.642659  12.867 2.82e-13 ***\nhp          -0.037479   0.009605  -3.902 0.000546 ***\nwt          -2.878575   0.904971  -3.181 0.003574 ** \nam1          2.083710   1.376420   1.514 0.141268    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.538 on 28 degrees of freedom\nMultiple R-squared:  0.8399,    Adjusted R-squared:  0.8227 \nF-statistic: 48.96 on 3 and 28 DF,  p-value: 2.908e-11\n\nQuando convertemos uma variável para fator, o R rotula os diferentes níveis (levels) conforme ordem alfabética. Portanto, no nosso exemplo, am possui 2 níveis: 0 e 1 (apesar de serem números, na conversão o R usa uma ordem crescente para dígitos). Numa regressão linear que possua variáveis qualitativas codificadas como fatores, o R usará o primeiro nível do fator (no nosso caso am0) como referência. Portanto a interpretação do coeficiente am1 deve ser a seguinte: observações com am = 1 possuem um acréscimo em média de 2.0837101 mpg. Note também que a variável am não possui significância estatística para a diferença entre o nível de referência am0 e o nível am1 com \\(p = 0.14\\). É possível verificar os diferentes níveis das variáveis qualitativas de um objeto lm acessando seu atributo xlevels.\n\n\nmodelo_quali$xlevels\n\n\n$am\n[1] \"0\" \"1\"\n\nEfeitos Principais e Efeitos de Interação\nTodos os modelos de regressão que mostramos até aqui usaram apenas efeitos principais. Mas podemos também mostrar efeitos de interação (também chamados de efeitos de moderação) entre duas variáveis. Similar ao exposto no tutorial sobre ANOVA, podemos incluir dois tipos de efeitos na regressão linear:\nEfeitos principais: efeito de uma (ou mais) variável(is) independente(s) em uma variável dependente. Chamamos esses efeitos de aditivos pois podem ser quebrados em dois efeitos distintos e únicos que estão influenciando a variável dependente.\nEfeitos de interações: quando o efeito de uma (ou mais) variável(is) independente(s) em uma variável dependente é afetado pelo nível de outras variável(is) independente(s). Efeitos de interação não são aditivos pois podem ser quebrados em dois efeitos distintos e únicos que estão influenciando a variável dependente. Há uma interação entre as variáveis independentes.\nVeja na figura 5 uma representação gráfica da interação entre am e cyl. Note que a interação é observada pela diferença de inclinações entre as linhas coloridas que representam os diferentes valores de cyl9.\n\n\nmtcars %>%\n  mutate(across(c(am, cyl), as.factor)) %>%\n  group_by(am, cyl) %>%\n  summarise(mpg = mean(mpg)) %>%\n  ggplot(aes(x = am, y = mpg, color = cyl)) +\n  geom_line(aes(group = cyl)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Set1\")\n\n\n\n\nFigure 5: Interação entre am e cyl do dataset mtcars\n\n\n\nPara incluirmos efeitos de interações entre duas variáveis independentes em regressões lineares, incluímos na fórmula entre as duas variáveis um sinal de multiplicação10 * indicando que as duas variáveis devem ser usadas como efeitos principais e também de interação na análise.\n\n\nmodelo_interacao <- lm(mpg ~ hp + wt + cyl * am, data = mtcars)\nsummary(modelo_interacao)\n\n\n\nCall:\nlm(formula = mpg ~ hp + wt + cyl * am, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0803 -1.4815 -0.7691  1.3676  5.2401 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 34.65302    3.24278  10.686 5.23e-11 ***\nhp          -0.01641    0.01480  -1.109  0.27760    \nwt          -2.72198    0.90900  -2.994  0.00596 ** \ncyl         -0.66455    0.57644  -1.153  0.25946    \nam           6.32643    3.80414   1.663  0.10831    \ncyl:am      -0.89996    0.65523  -1.373  0.18133    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.469 on 26 degrees of freedom\nMultiple R-squared:  0.8592,    Adjusted R-squared:  0.8322 \nF-statistic: 31.74 on 5 and 26 DF,  p-value: 2.791e-10\n\nA interpretação do coeficiente cyl:am é a seguinte: cyl (ou am) modera positivamente a relação entre am (ou cyl) e mpg. Note que o \\(p\\)-valor de cyl:am não possui significância estatística (\\(p = 0.181\\)).\nEfeitos Não-Lineares\nPodemos também incluir efeitos não-lineares em modelos de regressão linear. Uma relação não-linear é aquela que a representação entre as variáveis não pode ser representada de maneira fidedigna de maneira linear (com uma reta, mas sim com uma curva). Na ciência, há diversos fenômenos que não podem ser representados linearmente. Na figura @(fig:mtcars-poly) é possível ver a relação entre hp e mpg: a linha vermelha mostra uma tendência linear e a linha azul uma tendência não-linear.\n\n\nmtcars %>%\n  ggplot(aes(hp, mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"Red\") +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 2), se = FALSE, color = \"Blue\")\n\n\n\n\nFigure 6: Relação Não-Linear entre hp e mpg do dataset mtcars\n\n\n\nPara inserirmos efeitos não-lineares, incluímos na fórmula a função poly() com as variáveis que desejamos efeitos não-linares. A função poly() gera polinômios das variáveis conforme o grau especificado. No nosso exemplo abaixo, usaremos um polinômio de grau 2 (efeito quadrático).\n\n\nmodelo_naolinear <- lm(mpg ~ poly(hp, 2) + wt, data = mtcars)\nsummary(modelo_naolinear)\n\n\n\nCall:\nlm(formula = mpg ~ poly(hp, 2) + wt, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0589 -1.2603 -0.5089  0.7028  4.9805 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   29.8389     2.2093  13.506 8.72e-14 ***\npoly(hp, 2)1 -15.1717     3.3984  -4.464  0.00012 ***\npoly(hp, 2)2   6.8997     2.7628   2.497  0.01867 *  \nwt            -3.0300     0.6741  -4.495  0.00011 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.387 on 28 degrees of freedom\nMultiple R-squared:  0.8583,    Adjusted R-squared:  0.8432 \nF-statistic: 56.55 on 3 and 28 DF,  p-value: 5.292e-12\n\nVeja que ambos os coeficientes poly(hp, 2)1 (que deve ser interpretado como \\(\\text{hp}^1\\)) e poly(hp, 2)2 (que deve ser interpretado como \\(\\text{hp}^2\\)) possuem significância estatística (\\(p < 0.05\\)).\nVisualização de Regressão Linear\nUma vez que as variáveis dos modelos de regressão começam a ficar numerosas, as visualizações podem ajudar. Em especial, gostamos bastante da biblioteca {sjPlot} (Lüdecke, 2020) e sua função plot_model(). Como padrão, a função plot_model() produz um gráfico de floresta (forest plot) e também conhecido como blobograma no qual podemos visualizar as variáveis no eixo vertical e o tamanho do efeito, os coeficientes, no eixo horizontal. Além disso, coeficientes positivos são representados com a cor azul e negativos em vermelho; e os intervalos de confiança 95% como uma linha ao redor do valor médio do coeficiente (ponto). Ao especificarmos o tipo como \"std\" em plot_model(), o gráfico de floresta produzido utiliza os valores padronizados em desvios padrões. Veja um exemplo na figura 7: no lado esquerdo temos o gráfico de floresta para coeficientes brutos e no lado direto para coeficientes padrões.\n\n\nlibrary(sjPlot)\nforest_raw <- plot_model(modelo_quali)\nforest_std <- plot_model(modelo_quali, type = \"std\")\nforest_raw + forest_std + plot_layout(nrow = 1, widths = 1)\n\n\n\n\nFigure 7: Gráfico de Floresta dos Coeficientes de uma Regressão Linear\n\n\n\nCaso queira mais opções de visualizações para modelos de regressão não deixe de conferir o site da biblioteca {sfPlot}.\nVerificação de Pressupostos\nA verificação de pressupostos se divide em visualizações e testes estatísticos.\nVisualizações\nPara visualização diagnóstica de modelos de regressão linear temos a opção plot() padrão do R para modelos lm. Mas essa visualização não é interessante pois usa o sistema padrão do R para visualizações ao invés do sistema {ggplot2} (Wickham, 2016) que permite maiores configurações e controle. Para visualizar diagnósticos de objetos lm usando o sistema {ggplot2} recomendamos a biblioteca {ggfortify} (Horikoshi & Tang, 2018).\nA a função autoplot() da biblioteca {ggfortify} mostra os resíduos em quatro gráficos diferentes:\nResiduals vs Fitted (Resíduos vs Valores Previstos): utilizado para verificar os pressupostos de linearidade. Uma linha horizontal, sem padrões distintos é um indicativo de uma relação linear, o que indica que o pressuposto não foi violado.\nNormal Q-Q (Q-Q dos Resíduos): utilizado para verificar se os resíduos estão normalmente distribuídos. Se os pontos residuais seguirem a linha reta tracejada, indica que o pressuposto de independência dos resíduos não foi violado.\nScale-Location (Resíduos “Studentizados” vs Valores Previstos): utilizado para verificar a homogeneidade da variância dos resíduos (homocedasticidade). Uma linha horizontal com pontos igualmente espalhados é uma boa indicação que o pressuposto não foi violado. Usa o formato “Studentizado” dos resíduos que é o quociente resultante da divisão de um resíduo por uma estimativa de seu desvio padrão. É uma forma de estatística \\(t\\) de Student, com a estimativa de erro variando entre os pontos.\nResiduals vs Leverage (Resíduos vs Influências): Utilizado para identificar casos influentes, ou seja, valores extremos que podem influenciar os resultados da regressão quando incluídos ou excluídos da análise.\nVeja um exemplo de visualização diagnóstica do modelo_simples na figura 8. É um bom exemplo que demonstra diversas patologias (problemas) do modelo. Os resíduos (gráfico superior esquerdo) possui um padrão evidente, o gráfico Q-Q dos resíduos (gráfico superior direito) evidencia algumas observações com resíduos que ferem o pressuposto de independência dos resíduos, e por fim possuímos uma observação extremamente influente (gráfico inferior direito – Maserati B) que talvez prejudique as inferências do modelo.\n\n\nlibrary(ggfortify)\nautoplot(modelo_simples)\n\n\n\n\nFigure 8: Diagnósticos de Regressão Linear\n\n\n\nTestes Estatísticos\nAlém de visualizações diagnóstica, podemos realizar diversos testes estatísticos de hipótese nula para verificar se o modelo de regressão linear possui pressupostos violados ou não. Para isso recomendamos a biblioteca {lmtest} (Zeileis & Hothorn, 2002).\nTeste de Breusch-Pagan\nO teste de Breusch-Pagan(Breusch & Pagan, 1979; Cook & Weisberg, 1983) usado para testar o pressuposto da independência dos resíduos possui como hipótese nula que “as variâncias de erro são todas iguais” e como hipótese alternativa que “as variâncias de erro são uma função multiplicativa de uma ou mais variáveis.” Recomendamos que usem os resíduos “Studentizados” (quociente resultante da divisão de um resíduo por uma estimativa de seu desvio padrão – uma forma de estatística \\(t\\) de Student, com a estimativa de erro variando entre os pontos) no teste de Breusch-Pagan (Koenker, 1981). A função bptest() da biblioteca {lmtest} aceita como argumento um modelo de regressão linear (objeto lm) e já possui como padrão resíduos “Studentizados.” Caso queira usar resíduos brutos indique o argumento studentize como FALSE.\n\n\nlibrary(lmtest)\nbptest(modelo_simples)\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_simples\nBP = 0.88072, df = 2, p-value = 0.6438\n\nNote que o \\(p\\)-valor do Teste de Breusch-Pagan para o modelo_simples é 0.6, demonstrando fortes evidências em favor da não-rejeição da hipótese nula de dependência dos resíduos.\nTeste de Durbin-Watson\nO teste de Durbin-Watson (Durbin & Watson, 1950, 1951) é um teste estatístico usado para detectar a presença de autocorrelação dos resíduos de um modelo de regressão e testa o pressuposto da homogeneidade de variância dos resíduos. Possui como hipótese nula que os “erros são serialmente não correlacionados.” A função dwtest() da biblioteca {lmtest} aceita como argumento um modelo de regressão linear (objeto lm).\n\n\ndwtest(modelo_simples)\n\n\n\n    Durbin-Watson test\n\ndata:  modelo_simples\nDW = 1.3624, p-value = 0.02061\nalternative hypothesis: true autocorrelation is greater than 0\n\nNote que o \\(p\\)-valor do Teste de Durbin-Watson para o modelo_simples é menor que 0.05, indicando a rejeição da hipótese nula de não-correlação entre os resíduos, violando o pressuposto da homogeneidade de variância dos resíduos.\nMulticolinearidade\nMulticolinearidade é a ocorrência de alta correlação entre duas ou mais variáveis independentes e pode levar a resultados distorcidos. Em geral, a multicolinearidade pode fazer com que os intervalos de confiança se ampliem, ou até mudar o sinal de influência das variáveis independentes (de positivo para negativo, por exemplo). Portanto, as inferências estatísticas de uma regressão com multicolinearidade não são confiáveis. Pode ser testado usando o Fator de Inflação de Variância (Variance Inflation Factor – VIF).\nOs VIFs medem o quanto da variância de cada coeficiente de regressão do modelo estatístico se encontra inflado em relação à situação em que as variáveis independentes não estão correlacionadas. Valores aceitáveis de VIF são menores que 10 (Hair et al., 1998). Para calcular os VIFs de uma modelo lm use a função vif() da biblioteca {car} (Fox & Weisberg, 2019).\n\n\nlibrary(car)\nvif(modelo_simples)\n\n\n      hp       wt \n1.766625 1.766625 \n\nNote que os valores de VIFs para as variáveis independentes do modelo_simples estão todos dentro do limite aceitável (\\(<10\\)), demonstrando ausência de multicolinearidade e evidenciando que o pressuposto não foi violado.\n\\(R^2\\) e \\(R^2\\) ajustado\nO leitor curioso e atencioso talvez tenha percebido que não comentamos uma métrica dos modelos de regressão: R-quadrado (\\(R^2\\)) e R-quadrado ajustado (\\(R^2\\) ajustado).\nO \\(R^2\\) também conhecido como coeficiente de determinação representa a proporção da variabilidade na variável dependente prevista11 pelas variáveis independentes. É uma métrica que quantifica o poder preditivo de um modelo de regressão.\nJá o \\(R^2\\) ajustado inclui uma pequena penalidade pelo número de variáveis independentes usada no modelo de regressão. Conforme você adiciona variáveis independentes à um modelo de regressão, o seu \\(R^2\\) sempre aumentará, mas o \\(R^2\\) ajustado somente aumentará se você adicionar variáveis independentes úteis ao modelo (variáveis que aumentem o \\(R^2\\) um valor maior que a penalidade pela sua inclusão).\n\n\nsummary(modelo_simples)\n\n\n\nCall:\nlm(formula = mpg ~ hp + wt, data = mtcars)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.941 -1.600 -0.182  1.050  5.854 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 37.22727    1.59879  23.285  < 2e-16 ***\nhp          -0.03177    0.00903  -3.519  0.00145 ** \nwt          -3.87783    0.63273  -6.129 1.12e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.593 on 29 degrees of freedom\nMultiple R-squared:  0.8268,    Adjusted R-squared:  0.8148 \nF-statistic: 69.21 on 2 and 29 DF,  p-value: 9.109e-12\n\nVeja que o modelo_simples possui como \\(R^2\\) um valor de 0.8267855: isto quer dizer que o modelo_simples possui um poder preditivo de 83% da variância de mpg. Além disso seu \\(R^2\\) ajustado é que pode ser útil na hora de comparar diferentes modelos que usem o mesmo conjunto de dados mtcars e a mesma variável dependente mpg.\nCoeficientes Brutos versus Padronizados\nAlém de coeficientes brutos, podemos também obter coeficientes padronizados por desvios padrões de regressão linear usando a biblioteca {lm.beta} (Behrendt, 2014). Tal interpretação é vantajosa quando temos variáveis na regressão que possuem medidas diversas e que a comparação não seria tão simples. Os coeficientes padronizados são disponibilizados na coluna Standardized.\n\n\nlibrary(lm.beta)\nmodelo_simples_padronizado <- lm.beta(modelo_simples)\nsummary(modelo_simples_padronizado)\n\n\n\nCall:\nlm(formula = mpg ~ hp + wt, data = mtcars)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.941 -1.600 -0.182  1.050  5.854 \n\nCoefficients:\n            Estimate Standardized Std. Error t value Pr(>|t|)    \n(Intercept) 37.22727      0.00000    1.59879  23.285  < 2e-16 ***\nhp          -0.03177     -0.36145    0.00903  -3.519  0.00145 ** \nwt          -3.87783     -0.62955    0.63273  -6.129 1.12e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.593 on 29 degrees of freedom\nMultiple R-squared:  0.8268,    Adjusted R-squared:  0.8148 \nF-statistic: 69.21 on 2 and 29 DF,  p-value: 9.109e-12\n\nA interpretação de coeficientes padronizados é quase a mesma que coeficientes padrões, apenas mudando a escala de comparação, que deve ser interpretada em escala padronizada em desvios padrões: o acréscimo de 1 unidade de desvio padrão variável independente gera o aumento de <coeficiente> unidade(s) de desvio padrão(ões) da variável dependente. No nosso exemplo, a cada acréscimo de 1 desvio padrão de hp, mpg reduz em -0.3614507 desvio padrão; e a cada acréscimo de 1 desvio padrão wt, mpg reduz em -0.6295545 desvio padrão.\nNote que a constante (Intercept) não deve ser usada em escalas padronizada por desvio padrão, por isso que a saída de objetos lm.beta possui valor 0 para a constante (Intercept).\nPara gerar intervalos de confiança podemos usar a função confint() para objetos lm.beta da mesma maneira que usamos para objetos lm:\n\n\nconfint(modelo_simples_padronizado)\n\n\n                 2.5 %     97.5 %\n(Intercept) -3.2698877  3.2698877\nhp          -0.3799185 -0.3429828\nwt          -1.9236398  0.6645308\n\nConexões com o Teste \\(t\\), ANOVA e Correlações\n\n\n\nTodos as técnicas estatísticas que vimos até agora (teste \\(t\\), ANOVA e correlação) são casos especiais de regressão linear12. Caso o leitor se interesse aconselhamos a leitura do capítulo 5 de Poldrack (2018) e o excelente tutorial de Lindelov (2019). Caso o leitor queira substituir todos os testes estatísticos pela função lm() veja a tabela abaixo:\n\nConforme o autor 2, regressão linear é pizza e “tudo acaba em pizza.”\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#ikksjwbyft .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ikksjwbyft .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ikksjwbyft .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ikksjwbyft .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ikksjwbyft .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ikksjwbyft .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ikksjwbyft .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ikksjwbyft .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ikksjwbyft .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ikksjwbyft .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ikksjwbyft .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ikksjwbyft .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ikksjwbyft .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ikksjwbyft .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ikksjwbyft .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ikksjwbyft .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ikksjwbyft .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#ikksjwbyft .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ikksjwbyft .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#ikksjwbyft .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ikksjwbyft .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ikksjwbyft .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ikksjwbyft .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ikksjwbyft .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ikksjwbyft .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ikksjwbyft .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ikksjwbyft .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ikksjwbyft .gt_left {\n  text-align: left;\n}\n\n#ikksjwbyft .gt_center {\n  text-align: center;\n}\n\n#ikksjwbyft .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ikksjwbyft .gt_font_normal {\n  font-weight: normal;\n}\n\n#ikksjwbyft .gt_font_bold {\n  font-weight: bold;\n}\n\n#ikksjwbyft .gt_font_italic {\n  font-style: italic;\n}\n\n#ikksjwbyft .gt_super {\n  font-size: 65%;\n}\n\n#ikksjwbyft .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nNome do Teste1\n      função do R\n      Modelo de Regressão equivalente no R\n    P: teste t para Amostras Independentes\n      t.test(y)\n      lm(y ~ 1)\n    N: Teste de Wilcoxon\n      wilcox.test(y)\n      lm(signed_rank(y) ~ 1)\n    P: Teste t para duas Amostras Pareadas\n      t.test(y1, y2, paired=TRUE)\n      lm(y2 - y1 ~ 1)\n    N: Teste de Wilcoxon para duas Amostras Pareadaspairs\n      wilcox.test(y1, y2, paired=TRUE)\n      lm(signed_rank(y2 - y1) ~ 1)\n    P: Correlação de Pearson\n      cor.test(x, y, method=’Pearson’)\n      lm(y ~ 1 + x)\n    N: Correlação de Spearman\n      cor.test(x, y, method=’Spearman’)\n      lm(rank(y) ~ 1 + rank(x))\n    P: Teste t para Duas Amostras não-Pareadas\n      t.test(y1, y2, var.equal=TRUE)\n      lm(y ~ 1 + G2)\n    N: Teste de Mann-Whitney\n      wilcox.test(y1, y2)\n      lm(signed_rank(y) ~ 1 + G2)\n    P: ANOVA Unidirecional\n      aov(y ~ group)\n      lm(y ~ 1 + G2 + G3 +…+ GN)\n    N: Teste de Kruskal-Wallis\n      kruskal.test(y ~ group)\n      lm(rank(y) ~ 1 + G2 + G3 +…+ GN)\n    P: ANOVA Bidirecional com efeitos principais\n      aov(y ~ group + x)\n      lm(y ~ 1 + G2 + G3 +…+ GN + x)\n    P: ANOVA Bidirecional com efeitos de interação\n      aov(y ~ group * sex)\n      lm(y ~ 1 + G2 + G3 +…+ GN + S2 + S3 +…+ SK + G2*S2 + G3*S3 + … + GN*SK)\n    Fonte: adaptado de Lindelov (2019).\n    \n        \n          1\n          P: paramétrico - N: não-paramétrico\n          \n      \n    \n\nTécnicas Avançadas de Regressão Linear\nNesta seção apenas apresentaremos alternativas avançadas, não é o foco desse conteúdo introdutório apresentar de maneira detalhada, mas sim de apontar o leitor na direção correta.\nRegressão Robusta\nRegressão Regularizada\nRegressão Aditiva - Modelos Aditivos Generalizados\nRegressão Multinível\nRegressão Robusta\nRegressão linear não é uma boa alternativa na presença de observações extremas (também chamadas de outliers). O pressuposto de que os erros (ou resíduos) são distribuidos conforme uma distribuição Normal com média 0 faz com que as estimativas de uma regressão linear fiquem instáveis. Para exemplificar isso, vamos fazer uma simulação com 50 observações sendo que 40 observações são distribuídas como uma distribuição Normal e 10 observações são extremas (estão além de dois desvios padrões – \\(\\pm 2 \\times \\sigma\\)).\n\n\nlibrary(dplyr)\n\nn_sims <- 50\n\nsims <- tibble(\n  x = 1:n_sims,\n  y = c(rnorm(floor(4 * n_sims / 5)), sample(c(-4:-3, 3:4), ceiling(n_sims / 5), 1)),\n  tipo = c(rep(\"normal\", floor(4 * n_sims / 5)), rep(\"extrema\", ceiling(n_sims / 5)))\n) %>%\n  sample_frac(1L)  ## Randomize!\n\n\n\nA figura 9 mostra um diagrama de pontos (dotplot) da simulação e duas distribuições estimadas com os dados: Normal e \\(t\\) de Student (graus de liberdade = 3). Devido às observações extremas, a distribuição Normal, para comportar todas as observações, se alarga e achata. Tal achatamento e alargamento não ocorrem na distribuição \\(t\\) de Student. Isto se traduz em estimativas mais estáveis dos coeficientes da regressão na presença de observações extremas. Por esses motivos, para nós, a melhor a maneira de aplicar um modelo de regressão na presença de observações extremas é por meio de Estatística Bayesiana usando uma distribuição \\(t\\) de Student como o “motor” de inferência.\n\nO primeiro autor possui um tutorial de Estatística Bayesiana com R e um dos tutoriais é sobre regressão robusta usando distribuição \\(t\\) de Student.\n\n\nlibrary(ggplot2)\nsims %>%\n  ggplot(aes(y, fill = tipo)) +\n  geom_dotplot(alpha = 0.5) +\n  stat_function(fun = dnorm,\n                args = list(mean = mean(sims$y), sd = sd(sims$y)),\n                aes(color = \"Distribuição\\nNormal\"), size = 3) +\n  stat_function(fun = dt,\n                args = list(df = 3),\n                aes(color = \"Distribuição t\\nde Student\"), size = 3) +\n  scale_fill_brewer(\"Tipo de Observação\", palette = \"Set1\",\n                    guide = guide_legend(ncol = 1, nrow = 2, byrow = TRUE)) +\n  scale_colour_brewer(\"Tipo de Distribuição\", palette = \"Set3\",\n                      guide = guide_legend(ncol = 1, nrow = 2, byrow = TRUE)) +\n  theme(legend.position = \"bottom\") +\n  ylim(c(0, 0.4))\n\n\n\n\nFigure 9: Simulação com Observações Normais e Extremas – Distribuição Normal vs t de Student\n\n\n\nCaso o leitor não queria sair do paradigma NHST (afinal em Estatística Bayesiana não temos \\(H_0\\) nem \\(p\\)-valores), há duas alternativas de regressão robusta:\nM-estimação13 (Huber, 1964): robusta à observações extremas na variável dependentes, mas não nas independentes.\nMínimos quadrados aparados14 (Rousseeuw, 1984): robusto tanto à observações extremas na variável dependente quanto nas independentes. O método recomendado atualmente por diversas fontes (Rousseeuw & Van Driessen, 2006; Ryan, 2008)\nRegressão Regularizada\nA regressão regularizada é um tipo de regressão em que as estimativas dos coeficientes são restritas a zero. A magnitude (tamanho) dos coeficientes, bem como a magnitude do termo de erro, são penalizados. Modelos complexos são desencorajados, principalmente para evitar overfitting.\nTipos de regressão regularizada\nDois tipos comumente usados de métodos de regressão regularizados são regressão Ridge e regressão de Lasso.\nA regressão de Ridge(Tikhonov, 1943) é uma forma de criar um modelo parcimonioso quando o número de variáveis preditoras em um conjunto excede o número de observações (\\(m > p\\)) ou quando um conjunto de dados tem forte multicolinearidade (correlações entre variáveis preditoras). A regressão Ridge pertence ao conjunto de ferramentas de regularização L2. A regularização L2 adiciona uma penalidade chamada penalidade L2, que é igual ao quadrado da magnitude dos coeficientes. Todos os coeficientes são reduzidos pelo mesmo fator, de modo que todos os coeficientes permanecem no modelo. A força do termo de penalidade é controlada por um parâmetro de ajuste. Quando este parâmetro de ajuste (\\(\\lambda\\)) é definido como zero, a regressão Ridge é igual à regressão linear. Se \\(\\lambda = \\infty\\), todos os coeficientes são reduzidos a zero. A penalidade ideal é, portanto, algo entre \\(0\\) e \\(\\infty\\).\nA regressão Lasso (least absolute shrinkage and selection operator – Lasso) (Efron & Hastie, 2016; Tibshirani, 1996) é um tipo de regressão linear que usa encolhimento (shrinkage). Encolhimento faz com os valores dos coeficientes sejam reduzidos em direção a um ponto central, como a média. Este tipo de redução é muito útil quando você tem altos níveis de muticolinearidade ou quando deseja automatizar certas partes da seleção de modelo, como seleção de variável / eliminação de parâmetro. Lasso usa a regularização L1 que limita o tamanho dos coeficientes adicionando uma penalidade L1 igual ao valor absoluto, ao invés do valor quadrado como L2, da magnitude dos coeficientes. Isso às vezes resulta na eliminação de alguns coeficientes completamente, o que pode resultar em modelos esparsos e seleção de variáveis.\nPara usar modelos de regressão regularizada use a biblioteca {glmnet} (Simon, Friedman, Hastie, & Tibshirani, 2011).\nRegressão Aditiva - Modelos Aditivos Generalizados\nEm estatística, um modelo aditivo generalizado (generalized additive model – GAM) é um modelo linear generalizado no qual a variável de resposta depende linearmente de funções suaves (chamadas de splines) desconhecidas de algumas variáveis preditoras, e o interesse se concentra na inferência sobre essas funções suaves. Os GAMs foram desenvolvidos originalmente por Trevor Hastie e Robert Tibshirani (Hastie, Tibshirani, & others, 1986). Para usar GAMs no R use a biblioteca {gam} (Hastie, 2020).\nRegressão Multinível\nModelos multiníveis (também conhecidos como modelos lineares hierárquicos, modelo linear de efeitos mistos, modelos mistos, modelos de dados aninhados, coeficiente aleatório, modelos de efeitos aleatórios, modelos de parâmetros aleatórios ou designs de gráfico dividido) são modelos estatísticos de parâmetros que variam em mais de um nível (Luke, 2019).\nModelos multiníveis são particularmente apropriados para projetos de pesquisa onde os dados dos participantes são organizados em mais de um nível (ou seja, dados aninhados). As unidades de análise geralmente são indivíduos (em um nível inferior) que estão aninhados em unidades contextuais / agregadas (em um nível superior).\nModelos multiníveis geralmente se dividem em três abordagens:\nRandom intercept model: Modelo no qual cada grupo recebe uma constante (intercept) diferente\nRandom slope model: Modelo no qual cada grupo recebe um coeficiente diferente para cada variável independente\nRandom intercept-slope model: Modelo no qual cada grupo recebe tanto uma constante (intercept) quanto um coeficiente diferente para cada variável independente\n\nO primeiro autor possui um tutorial de Estatística Bayesiana com R e um dos tutoriais é sobre regressão multinível.\nPara usar modelos multiníveis em R use a biblioteca {lme4} (Bates, Mächler, Bolker, & Walker, 2015).\nComentários Finais\nRegressão Linear é a porta de entrada para os modelos lineares. Tais modelos são o “pão-com-manteiga” das ciências sociais aplicadas, usado extensamente tanto em relatórios técnicos quanto na literatura científica, assim como tanto em contextos profissionais quanto acadêmicos. Acreditamos que regressão linear é o conteúdo mais importante (logo atrás de \\(p\\)-valores) desse conjunto de tutoriais. Tal importância se dá por dois fatores. Primeiro, todas as técnicas estatística que vimos até agora (teste \\(t\\), ANOVA e correlação) podem ser substituídas por casos especiais de regressão linear. Segundo, eles são a base de entendimento para todos os modelos de regressão existentes (alguns listados na seção de “Técnicas Avançadas”).\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] gt_0.2.2             lm.beta_1.5-1        lmtest_0.9-38       \n [4] zoo_1.8-8            ggfortify_0.4.11     sjPlot_2.8.7        \n [7] broom_0.7.4          palmerpenguins_0.1.0 magrittr_2.0.1      \n[10] mnormt_2.0.2         cowplot_1.1.1        tidyr_1.1.2         \n[13] DescTools_0.99.40    skimr_2.1.2          ggpubr_0.4.0        \n[16] car_3.0-10           carData_3.0-4        patchwork_1.1.1     \n[19] dplyr_1.0.4          ggplot2_3.3.3        DiagrammeR_1.0.6.1  \n[22] readxl_1.3.1        \n\nloaded via a namespace (and not attached):\n  [1] minqa_1.2.4        colorspace_2.0-0   ggsignif_0.6.0    \n  [4] ellipsis_0.3.1     class_7.3-17       rio_0.5.16        \n  [7] sjlabelled_1.1.7   rprojroot_2.0.2    estimability_1.3  \n [10] parameters_0.11.0  base64enc_0.1-3    gld_2.6.2         \n [13] rstudioapi_0.13    farver_2.0.3       fansi_0.4.2       \n [16] mvtnorm_1.1-1      lubridate_1.7.9.2  xml2_1.3.2        \n [19] splines_4.0.3      downlit_0.2.1      rootSolve_1.8.2.1 \n [22] knitr_1.31         sjmisc_2.8.6       jsonlite_1.7.2    \n [25] nloptr_1.2.2.2     ggeffects_1.0.1    effectsize_0.4.3  \n [28] compiler_4.0.3     emmeans_1.5.4      sjstats_0.18.1    \n [31] backports_1.2.1    assertthat_0.2.1   Matrix_1.2-18     \n [34] cli_2.3.0          visNetwork_2.0.9   htmltools_0.5.1.1 \n [37] tools_4.0.3        gtable_0.3.0       glue_1.4.2        \n [40] lmom_2.8           Rcpp_1.0.6         cellranger_1.1.0  \n [43] vctrs_0.3.6        nlme_3.1-149       insight_0.12.0    \n [46] xfun_0.21          stringr_1.4.0      lme4_1.1-26       \n [49] openxlsx_4.2.3     lifecycle_0.2.0    statmod_1.4.35    \n [52] rstatix_0.6.0      MASS_7.3-53        scales_1.1.1      \n [55] hms_1.0.0          expm_0.999-6       RColorBrewer_1.1-2\n [58] yaml_2.2.1         curl_4.3           Exact_2.1         \n [61] gridExtra_2.3      reticulate_1.18    sass_0.3.1        \n [64] distill_1.2        stringi_1.5.3      highr_0.8         \n [67] bayestestR_0.8.2   checkmate_2.0.0    e1071_1.7-4       \n [70] boot_1.3-25        zip_2.1.1          repr_1.1.3        \n [73] commonmark_1.7     rlang_0.4.10       pkgconfig_2.0.3   \n [76] evaluate_0.14      lattice_0.20-41    purrr_0.3.4       \n [79] htmlwidgets_1.5.3  labeling_0.4.2     tidyselect_1.1.0  \n [82] ggsci_2.9          bookdown_0.21      R6_2.5.0          \n [85] magick_2.6.0       generics_0.1.0     DBI_1.1.1         \n [88] pillar_1.4.7       haven_2.3.1        foreign_0.8-80    \n [91] withr_2.4.1        mgcv_1.8-33        abind_1.4-5       \n [94] tibble_3.0.6       performance_0.7.0  modelr_0.1.8      \n [97] crayon_1.4.1       utf8_1.1.4         tmvnsim_1.0-2     \n[100] rmarkdown_2.6      grid_4.0.3         data.table_1.13.6 \n[103] forcats_0.5.1      digest_0.6.27      xtable_1.8-4      \n[106] munsell_0.5.0     \n\n\n\n\nBates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1–48. https://doi.org/10.18637/jss.v067.i01\n\n\nBehrendt, S. (2014). Lm.beta: Add standardized regression coefficients to lm-objects. Retrieved from https://CRAN.R-project.org/package=lm.beta\n\n\nBreusch, T. S., & Pagan, A. R. (1979). A simple test for heteroscedasticity and random coefficient variation. Econometrica: Journal of the Econometric Society, 1287–1294.\n\n\nCook, R. D., & Weisberg, S. (1983). Diagnostics for heteroscedasticity in regression. Biometrika, 70(1), 1–10.\n\n\nDurbin, J., & Watson, G. S. (1950). Testing for serial correlation in least squares regression: i. Biometrika, 37(3/4), 409–428.\n\n\nDurbin, J., & Watson, G. S. (1951). Testing for serial correlation in least squares regression. II. Biometrika, 38(1/2), 159–179.\n\n\nEfron, B., & Hastie, T. (2016). Computer age statistical inference (Vol. 5). Cambridge University Press.\n\n\nFox, J., & Weisberg, S. (2019). An R companion to applied regression (Third). Retrieved from https://socialsciences.mcmaster.ca/jfox/Books/Companion/\n\n\nGalton, F. (1890). Kinship and correlation. The North American Review, 150(401), 419–431.\n\n\nHair, J. F., Black, W. C., Babin, B. J., Anderson, R. E., Tatham, R. L., & others. (1998). Multivariate data analysis (Vol. 5). Prentice hall Upper Saddle River, NJ.\n\n\nHastie, T. (2020). Gam: Generalized additive models. Retrieved from https://CRAN.R-project.org/package=gam\n\n\nHastie, T., Tibshirani, R., & others. (1986). Generalized additive models. Statistical Science, 1(3), 297–310.\n\n\nHenderson, H. V., & Velleman, P. F. (1981). Building multiple regression models interactively. Biometrics, 391–411.\n\n\nHorikoshi, M., & Tang, Y. (2018). Ggfortify: Data visualization tools for statistical analysis results. Retrieved from https://CRAN.R-project.org/package=ggfortify\n\n\nHuber, P. J. (1964). Robust estimation of a location parameter. Ann. Math. Statist., 35(1), 73–101. https://doi.org/10.1214/aoms/1177703732\n\n\nKoenker, R. (1981). A note on studentizing a test for heteroscedasticity. Journal of Econometrics, 17(1), 107–112.\n\n\nLindelov, J. K. (2019). Common statistical tests are linear models (or: How to teach stats). Retrieved from https://lindeloev.github.io/tests-as-linear/\n\n\nLuke, D. A. (2019). Multilevel modeling (Vol. 143). SAGE Publications, Incorporated.\n\n\nLüdecke, D. (2020). sjPlot: Data visualization for statistics in social science. Retrieved from https://CRAN.R-project.org/package=sjPlot\n\n\nPearson, K. (1903). The law of ancestral heredity. Biometrika, 2(2), 211–228.\n\n\nPoldrack, R. A. (2018). Statistical thinking for the 21st century. Retrieved from https://statsthinking21.org\n\n\nRousseeuw, P. J. (1984). Least median of squares regression. Journal of the American Statistical Association, 79(388), 871–880.\n\n\nRousseeuw, P. J., & Van Driessen, K. (2006). Computing LTS regression for large data sets. Data Mining and Knowledge Discovery, 12(1), 29–45.\n\n\nRyan, T. P. (2008). Modern regression methods (Vol. 655). John Wiley & Sons.\n\n\nSimon, N., Friedman, J., Hastie, T., & Tibshirani, R. (2011). Regularization paths for cox’s proportional hazards model via coordinate descent. Journal of Statistical Software, 39(5), 1–13. Retrieved from http://www.jstatsoft.org/v39/i05/\n\n\nTibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B (Methodological), 58(1), 267–288.\n\n\nTikhonov, A. N. (1943). On the stability of inverse problems. Dokl. Akad. Nauk SSSR, 39, 195–198.\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Retrieved from https://ggplot2.tidyverse.org\n\n\nYule, G. U. (1897). On the theory of correlation. Journal of the Royal Statistical Society, 60(4), 812–854.\n\n\nZeileis, A., & Hothorn, T. (2002). Diagnostic checking in regression relationships. R News, 2(3), 7–10. Retrieved from https://CRAN.R-project.org/doc/Rnews/\n\n\nvariáveis dependentes binárias ou discretas serão apresentadas na tutorial de Regressão Logística↩︎\nregressão também é o motor que tem por de trás de quase todos os algoritmos e modelos de machine learning.↩︎\ntecnicamente reta aqui se refere um hiperplano que é subespaço de dimensão \\(n-1\\) de um espaço de dimensão \\(n\\). Por exemplo, uma reta é um hiperplano 1-D de uma plano 2-D; um plano 2-D é um hiperplano de um plano 3-D; e assim por diante…↩︎\nacreditamos que visualizações 3-D de dados somente são aplicáveis em dois contextos: se você está usando mapas nas suas visualizações ou se você possui uma impressora 3D. Como não estamos fazendo nenhum dos dois, não nos aventuraremos em imagens 3D (#ficaadica).↩︎\nusando a técnica de Pearson.↩︎\ntecnicamente podemos também pegar o valor absoluto de cada erro. Isto se chama erro absoluto médio (mean absolute error – MAE). Mas não possui as mesmas propriedades analíticas que o MSE e é computacionalmente menos estável.↩︎\nPara os que tenham tido a oportunidade de estudar cálculo: estamos falando em achar o valor de x quando a derivada do MSE é zero (\\(\\text{MSE}^{\\prime} = 0\\)).↩︎\nusando a técnica de Pearson.↩︎\nconvertemos cyl em fator para que, no gráfico cyl seja representado como quantidades discretas ao invés de contínuas.↩︎\nmatematicamente falando interação é uma multiplicação entre as duas variáveis independentes↩︎\nmuitas definições usam o termo “explicada” o que evitamos pois implica intuitivamente em uma relação causal.↩︎\ninclusive a função aov() de ANOVA por de baixo dos panos faz um chamado à função lm(). Ou seja é um wrapper, também chamado de açúcar sintático (syntactic sugar), da função lm().↩︎\nTermo inglês: M-estimation↩︎\nTermo inglês: least trimmed squares – LTS↩︎\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "7-Regressao_Logistica.html",
      "title": "Regressão Logística",
      "description": "Regressão para o caso de uma variável dependente binária.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nFunção Logística\nPor que não usar Regressão Linear?\nPressupostos da Regressão Logística\nComo aplicar uma Regressão Logística no R\nInterpretação dos Coeficientes\nVariáveis Qualitativas\nEfeitos Principais e Efeitos de Interação\nVisualização de Regressão Logística\nVerificação de Pressupostos\n\nPseudo-\\(R^2\\)\nTécnicas Avançadas de Modelos Lineares Generalizados.\nModelos Lineares Generalizados Regularizados\nRegressão Aditiva - Modelos Aditivos Generalizados\nRegressão Multinível\n\nComentários Finais\nAmbiente\n\n\nA regressão linear é uma técnica tão ampla que originou diversas gambiarras extensões para acomodar os mais diferentes tipos de variáveis dependentes para além de apenas contínuas. Essas extensões da regressão linear são chamadas de modelos lineares generalizados e a sua lógica se baseia em transformar a variável dependente de alguma maneira para que ela se torne “linear” e “contínua”. Nesse tutorial vamos focar no caso da regressão logística que usa uma transformação logística de variáveis binárias (também chamadas de dicotômicas ou dummy) – que tomam apenas dois valores discretos1. Antes de continuar, recomendamos fortemente que leia o tutorial nosso de regressão linear, pois muitos conceitos serão abordados novamente.\nO foco em variáveis binárias (logo, em regressão logística) se dá pela quantidade de dados e modelos que são usados para modelar resultados binários. Por exemplo:\nComo a probabilidade de desenvolver câncer de pulmão (sim vs. não) muda para cada quilo adicional que uma pessoa está acima do peso e para cada maço de cigarros fumado por dia?\nO peso corporal, a ingestão de calorias, a ingestão de gordura e a idade influenciam a probabilidade de um ataque cardíaco (sim x não)?\nQuais palavras, qual hora do dia, quais assuntos e qual domínio do remetentem influenciam a probabilidade de um e-mail ser spam (sim x não)?\nTodos esses exemplos são questões que a regressão logística pode responder. Toda vez que precisamos responder uma pergunta na qual pode ser reduzida a uma pergunta de sim/não ou esse/aquele, regressão logística é a principal técnica a ser empregada.\nFunção Logística\nUma regressão logística se comporta exatamente como um modelo linear: faz uma predição simplesmente computando uma soma ponderada das variáveis independentes, mais uma constante. Porém ao invés de retornar um valor contínuo, como a regressão linear, retorna a função logística desse valor.\n\\[\\operatorname{Logística}(x) = \\frac{1}{1 + e^{(-x)}}\\]\nA função logística é uma gambiarra transformação que pega qualquer valor entre menos infinito \\(-\\infty\\) e mais infinito \\(+\\infty\\) e transforma em um valor entre 0 e 1. Veja na figura 1 uma representação gráfica da função logística.\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\ntibble(\n  x = seq(-10, 10, length.out = 100),\n  logit = 1 / (1 + exp(-x))) %>%\n  ggplot(aes(x, logit)) +\n  geom_line()\n\n\n\n\nFigure 1: Função Logística\n\n\n\nA função logística foi desenvolvida como modelo de crescimento populacional e denominada “logística” por Pierre François Verhulst nas décadas de 1830 e 1840, sob a orientação de Adolphe Quetelet. Regressão Logística como a empregamos hoje passou por vários refinamentos até Cox (1958) que é mais ou menos a versão atual que usamos.\n\n\n\nFigure 2: Da esquerda para direita: Pierre François Verhuls, Adolphe Quetelet e David Cox – Figuras de https://www.wikipedia.org\n\n\n\nPor que não usar Regressão Linear?\nPara responder essa pergunta recorreremos mais uma vez à simulações. Vamos gerar um dataset com 30 observações com duas variáveis: uma variável contínua idade e uma variável binária comprado. Para ilustrar o primeiro cenário, imagine que somente as pessoas com menos de 20 anos compraram algum produto, comprado = 1, e as pessoas com 20 anos ou mais não compraram o produto, comprado = 0. Veja na figura 3 o que acontece se usarmos uma regressão linear (em vermelho) ou uma regressão logística (em azul) neste cenário. Qual modelo explica melhor a relação entre os dados é evidente: regressão logística.\n\n\nsim1 <- tibble(\n  idade = 10:29,\n  comprado = c(rep(1, 10), rep(0, 10))\n)\n\nsim1 %>% ggplot(aes(idade, comprado)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se =  FALSE, color = \"Red\") +\n  geom_smooth(method = \"glm\",\n              method.args = list(family = \"binomial\"),\n              se = FALSE, color = \"Blue\") +\n  scale_y_continuous(breaks = c(0, 1))\n\n\n\n\nFigure 3: Reta vs Curva Logística\n\n\n\nVamos para uma segunda simulação, agora com dados desbalanceados. Vamos adicionar à nossa simulação mais 10 clientes com idades entre 60 e 69 que não comparam o produto comprado = 0. Nesse cenário, figura 4, a desvantagem da regressão linear (cor vermelha) comparada com a regressão logística (cor azul) é ainda mais evidente.\n\n\nsim2 <- tibble(\n  idade = c(10:29, 60:69),\n  comprado = c(rep(1, 10), rep(0, 20))\n)\n\nsim2 %>% ggplot(aes(idade, comprado)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se =  FALSE, color = \"Red\") +\n  geom_smooth(method = \"glm\",\n              method.args = list(family = \"binomial\"),\n              se= FALSE, color = \"Blue\") +\n  scale_y_continuous(breaks = c(0, 1))\n\n\n\n\nFigure 4: Reta vs Curva Logística – Dados Desbalanceados\n\n\n\nAcreditamos que com essas duas simulações o argumento a favor de regressão logística tenha sido aceito incondicionalmente.\nPressupostos da Regressão Logística\nPara interpretar os resultados de uma regressão logística como uma quantidade estatística significativa que mede os relacionamentos do mundo real, precisamos contar com uma série de suposições clássicas. Os quatro principais pressupostos da regressão logística são:\nIndependência dos Dados: o valor de uma observação não influencia ou afeta o valor de outras observações. Este é o pressuposto clássico de todas as técnicas abordadas até agora.\nLinearidade dos Dados: a relação entre as variáveis independentes e a curva logística da variável dependente é considerada linear (quanto mais/menos de uma, mais/menos de outra). Linearidade dos Dados pode ser verificada graficamente observando a dispersão dos resíduos com os valores previstos pela regressão.\nIndependência dos Erros / Resíduos: os erros (também chamados de resíduos) não devem possuir correlação. Este pressuposto pode ser testado pelo teste de Durbin-Watson e observando o gráfico quantil-quantil (Q-Q) dos resíduos padronizados.\nHomogeneidade de Variância dos Erros / Resíduos: os erros devem ter média zero e desvio padrão constante ao longo das observações. Similar ao teste de Levene, mas aplicado aos resíduos da regressão. Pode ser testado usando o Teste de Breusch-Pagan.\nAusência de Multicolinearidade: multicolinearidade é a ocorrência de alta correlação entre duas ou mais variáveis independentes e pode levar a resultados distorcidos. Em geral, a multicolinearidade pode fazer com que os intervalos de confiança se ampliem, ou até mudar o sinal de influência das variáveis independentes (de positivo para negativo, por exemplo). Portanto, as inferências estatísticas de uma regressão com multicolinearidade não são confiáveis. Pode ser testado usando o Fator de Inflação de Variância (Variance Inflation Factor – VIF).\nOs pressupostos de regressão logística são os mesmos da regressão linear, com a exceção de que o pressuposto de linearidade é aplicado à curva logística da variável dependente.\nComo aplicar uma Regressão Logística no R\nPara exemplificar as regressões nesse tutorial, usaremos o dataset TitanicSurvival da biblioteca {carData} (Fox & Weisberg, 2019). TitanicSurvival é uma base de dados com os tripulantes e passageiros do Titanic que afundou em 15 de Abril de 1912. Possui 1309 observações e 4 variáveis:\nsurvived – sobreviveu (binária qualitativa): 0 não sobreviveu, 1 sobreviveu\nsex – gênero (binária qualitativa): female feminino, male masculino\nage – idade (contínua)\npassengerClass – classe do passageiro (qualitativa): 1st primeira classe, 2nd segunda classe e 3rd terceira classe\n\n\nlibrary(skimr)\nlibrary(carData)\ndata(\"TitanicSurvival\", package = \"carData\")\nskim(TitanicSurvival)\n\n\nTable 1: Data summary\nName\nTitanicSurvival\nNumber of rows\n1309\nNumber of columns\n4\n_______________________\n\nColumn type frequency:\n\nfactor\n3\nnumeric\n1\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nsurvived\n0\n1\nFALSE\n2\nno: 809, yes: 500\nsex\n0\n1\nFALSE\n2\nmal: 843, fem: 466\npassengerClass\n0\n1\nFALSE\n3\n3rd: 709, 1st: 323, 2nd: 277\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nage\n263\n0.8\n29.88\n14.41\n0.17\n21\n28\n39\n80\n▂▇▅▂▁\n\nPara aplicar uma regressão logística no R usamos a função glm() (generalized linear model) padrão do R. Sua funcionalidade é idêntica à função lm() de regressão linear, sendo que, além de fórmula e dataset, é necessário fornecer um argumento extra family:\nFórmula designando a variável dependente e a(s) variável(eis) independente(s) designada pela seguinte síntaxe: dependente ~ independente_1 + independente_2 + ....\nO dataset no qual deverá ser encontradas as variáveis presentes na fórmula.\nfamily: tipo de modelo linear generalizado que deseja utilizar. Para regressão logística usamos family = binomial.\nComeçaremos com um exemplo simples de regressão logística do TitanicSurvival usando como variável independente survived e variáveis independentes age e sex. Podemos inspecionar o resultado de uma regressão logística com a função summary().\n\n\nmodelo_simples <- glm(survived ~ age + sex,\n                      data = TitanicSurvival, family = binomial)\nsummary(modelo_simples)\n\n\n\nCall:\nglm(formula = survived ~ age + sex, family = binomial, data = TitanicSurvival)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.7247  -0.6859  -0.6603   0.7555   1.8737  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.235414   0.192032   6.433 1.25e-10 ***\nage         -0.004254   0.005207  -0.817    0.414    \nsexmale     -2.460689   0.152315 -16.155  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1414.6  on 1045  degrees of freedom\nResidual deviance: 1101.3  on 1043  degrees of freedom\n  (263 observations deleted due to missingness)\nAIC: 1107.3\n\nNumber of Fisher Scoring iterations: 4\n\nInterpretação dos Coeficientes\nNa saída de summary() podemos ver que são produzidos os coeficientes da regressão na coluna Estimate, associados ao respectivos desvio padrão dos resíduos Std. Error e \\(p\\)-valores Pr(>|t|). Importante destacar que a hipótese nula dos coeficientes da regressão é de que “os coeficientes são nulos/zeros”, então os \\(p\\)-valores devem ser interpretados como a probabilidade de observamos valores de coeficientes tão extremos dado que a hipótese nula é verdadeira. Para facilitar, o R informa com asteriscos quais variáveis possuem coeficientes estatisticamente significantes: * para \\(p < 0.05\\), ** para \\(p < 0.01\\), e *** para \\(p < 0.001\\).\nOs coeficientes de regressão logística não são interpretáveis em escala bruta2. É necessário inverter a transformação logística exponenciando os coeficientes – \\(e^x\\). Isso faz com que os coeficientes se transformem em razões de chance (odds ratio – OR) que permite uma melhor interpretabilidade.\nRazões de chance funcionam muito similar com as chances de uma aposta. Quando a chance é justa tanto para a variável dependente ser 0 quanto 1 ela é expressada como uma chance 1 para 1 (1:1) – \\(\\frac{1}{1}\\). Qualquer valor abaixo de 0 faz com que a chance da variável dependente ser 0 aumentar, e qualquer valor acima de 1 a chance da variável dependente ser 1 aumenta. Para transformar os coeficientes de um modelo de regressão logística em OR, usamos a função exp() base do R nos coeficientes coef() do modelo.\n\n\nexp(coef(modelo_simples))\n\n\n(Intercept)         age     sexmale \n 3.43980286  0.99575479  0.08537609 \n\nA interpretação dessa saída de OR é a seguinte:\nage – A cada aumento de uma unidade de idade, há uma diminuição da chance de sobrevivência (variável dependente survived igual a 1) em 0.424521% (\\(1 - \\text{OR}_\\text{age}\\)).\nsexmale – A cada aumento de uma unidade de sexmal (ou seja sexomale é igual 1, em outras palavras sexo masculino), há uma diminuição da chance de sobrevivência (variável dependente survived igual a 1) em 91.4623909% (\\(1 - \\text{OR}_\\text{sexmale}\\)).\nPara produzir intervalos de confiança precisamos usar a função confint() do pacote MASS (Venables & Ripley, 2002), uma vez que a função confint() base do R não dá suporte à OR. Como padrão, MASS::confint(), assim como confint() base do R, produz intervalos de confiança 95%.\n\n\nconfint(modelo_simples)\n\n\n                  2.5 %      97.5 %\n(Intercept)  0.86469239  1.61820670\nage         -0.01450821  0.00592225\nsexmale     -2.76348286 -2.16607599\n\nVariáveis Qualitativas\nAlém de variáveis independentes quantitativas, regressão logística, assim como a linear, também permite utilizarmos variáveis qualitativas (discretas) como variáveis independentes.\nVamos estender o nosso modelo simples adicionando a variável passengerClass. Note que, no dataset TitanicSurvival, passengerClass já está convertida para qualitativa (factor), não sendo necessário usar a função padrão do R as.factor().\n\n\nmodelo_quali <- glm(survived ~ age + sex + passengerClass,\n                    data = TitanicSurvival, family = binomial)\nsummary(modelo_quali)\n\n\n\nCall:\nglm(formula = survived ~ age + sex + passengerClass, family = binomial, \n    data = TitanicSurvival)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.6399  -0.6979  -0.4336   0.6688   2.3964  \n\nCoefficients:\n                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        3.522074   0.326702  10.781  < 2e-16 ***\nage               -0.034393   0.006331  -5.433 5.56e-08 ***\nsexmale           -2.497845   0.166037 -15.044  < 2e-16 ***\npassengerClass2nd -1.280570   0.225538  -5.678 1.36e-08 ***\npassengerClass3rd -2.289661   0.225802 -10.140  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1414.62  on 1045  degrees of freedom\nResidual deviance:  982.45  on 1041  degrees of freedom\n  (263 observations deleted due to missingness)\nAIC: 992.45\n\nNumber of Fisher Scoring iterations: 4\n\nQuando uma variável é convertida para fator, o R rotula os diferentes níveis (levels) conforme ordem alfabética. Portanto, no nosso exemplo, passengerClass possui 3 níveis: 1st, 2nd e 3rd (apesar de serem números, na conversão o R usa uma ordem crescente para dígitos). Numa regressão logística que possua variáveis qualitativas codificadas como fatores, o R usará o primeiro nível do fator (no nosso caso 1st) como referência. Portanto a interpretações de passengerClass devem se atentar que a referência é passengerClass = 1st. É possível verificar os diferentes níveis das variáveis qualitativas de um objeto glm acessando seu atributo xlevels.\n\n\nmodelo_quali$xlevels\n\n\n$sex\n[1] \"female\" \"male\"  \n\n$passengerClass\n[1] \"1st\" \"2nd\" \"3rd\"\n\nEfeitos Principais e Efeitos de Interação\nTodos os modelos de regressão logística que mostramos até aqui usaram apenas efeitos principais. Mas podemos também mostrar efeitos de interação (também chamados de efeitos de moderação) entre duas variáveis. Similar ao exposto no tutorial sobre regressão linear, podemos incluir dois tipos de efeitos na regressão logística:\nEfeitos principais: efeito de uma (ou mais) variável(is) independente(s) em uma variável dependente. Chamamos esses efeitos de aditivos pois podem ser quebrados em dois efeitos distintos e únicos que estão influenciando a variável dependente.\nEfeitos de interações: quando o efeito de uma (ou mais) variável(is) independente(s) em uma variável dependente é afetado pelo nível de outras variável(is) independente(s). Efeitos de interação não são aditivos pois podem ser quebrados em dois efeitos distintos e únicos que estão influenciando a variável dependente. Há uma interação entre as variáveis independentes.\nVeja na figura 5 uma representação gráfica da interação entre sex e passengerClass. Note que a interação é observada pela diferença de inclinações entre as linhas coloridas que representam os diferentes valores de passengerClass.\n\n\nTitanicSurvival %>%\n  mutate(survived = ifelse(survived == \"yes\", 1, 0),\n         sex = forcats::fct_rev(sex)) %>%\n  group_by(sex, passengerClass) %>%\n  summarise(survived = mean(survived)) %>%\n  ggplot(aes(x = sex, y = survived, color = passengerClass)) +\n  geom_line(aes(group = passengerClass)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Set1\")\n\n\n\n\nFigure 5: Interação entre sex e passengerClass do dataset mtcars\n\n\n\nPara incluirmos efeitos de interações entre duas variáveis independentes em regressões logísticas, incluímos na fórmula entre as duas variáveis um sinal de multiplicação3 * indicando que as duas variáveis devem ser usadas como efeitos principais e também de interação na análise.\n\n\nmodelo_interacao <- glm(survived ~ age + sex * passengerClass,\n                        data = TitanicSurvival, family = binomial)\nsummary(modelo_interacao)\n\n\n\nCall:\nglm(formula = survived ~ age + sex * passengerClass, family = binomial, \n    data = TitanicSurvival)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.0778  -0.6604  -0.4943   0.4263   2.4935  \n\nCoefficients:\n                           Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                4.804345   0.546937   8.784  < 2e-16 ***\nage                       -0.038401   0.006743  -5.695 1.23e-08 ***\nsexmale                   -3.886389   0.492375  -7.893 2.95e-15 ***\npassengerClass2nd         -1.529875   0.566481  -2.701  0.00692 ** \npassengerClass3rd         -4.064965   0.510661  -7.960 1.72e-15 ***\nsexmale:passengerClass2nd -0.070404   0.630978  -0.112  0.91116    \nsexmale:passengerClass3rd  2.488808   0.540042   4.609 4.05e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1414.62  on 1045  degrees of freedom\nResidual deviance:  931.99  on 1039  degrees of freedom\n  (263 observations deleted due to missingness)\nAIC: 945.99\n\nNumber of Fisher Scoring iterations: 5\n\nA interpretação de interações de regressão logística é a mesma da interpretação de interações da regressão linear. Por exemplo, a interpretação do coeficiente sexmale:passengerClass3rd é a seguinte: ser um passageiros da terceira classe modera positivamente a relação entre sexo masculino e survived. Note que o \\(p\\)-valor de sexmale:passengerClass3rd possui significância estatística (\\(p < 0.001\\)).\nVisualização de Regressão Logística\nUma vez que as variáveis dos modelos de regressão começam a ficar numerosas, as visualizações podem ajudar. Em especial, gostamos bastante da biblioteca {sjPlot} (Lüdecke, 2020) e sua função plot_model(). Como padrão, a função plot_model() produz um gráfico de floresta (forest plot) e também conhecido como blobograma no qual podemos visualizar as variáveis no eixo vertical e o tamanho do efeito, os coeficientes, no eixo horizontal. Além disso, coeficientes positivos são representados com a cor azul e negativos em vermelho; e os intervalos de confiança 95% como uma linha ao redor do valor médio do coeficiente (ponto). Ao especificarmos o tipo como \"std\" em plot_model(), o gráfico de floresta produzido utiliza os valores padronizados em desvios padrões. Já mostramos a função plot_model() no tutorial de regressão linear e ela funciona de maneira idêntica à modelos de regressão logística, com uma exceção que os coeficientes já são apresentados em formato OR. Veja um exemplo na figura 6: na parte superior temos o gráfico de floresta para coeficientes brutos e na parte inferior para coeficientes padrões.\n\n\nlibrary(sjPlot)\nforest_raw <- plot_model(modelo_quali)\nforest_std <- plot_model(modelo_quali, type = \"std\")\nforest_raw + forest_std + plot_layout(nrow = 2, widths = 1)\n\n\n\n\nFigure 6: Gráfico de Floresta dos Coeficientes de uma Regressão Logística em formato Odds Ratio – OR\n\n\n\nCaso queira mais opções de visualizações para modelos de regressão não deixe de conferir o site da biblioteca {sfPlot}.\nVerificação de Pressupostos\nPodemos realizar diversos testes estatísticos de hipótese nula para verificar se o modelo de regressão logística possui pressupostos violados ou não. Para isso recomendamos a biblioteca {lmtest} (Zeileis & Hothorn, 2002).\nOs pressupostos de regressão logística são os mesmos da regressão linear, com a exceção de que o pressuposto de linearidade é aplicado à curva logística da variável dependente.\nTeste de Breusch-Pagan\nO teste de Breusch-Pagan(Breusch & Pagan, 1979; Cook & Weisberg, 1983) usado para testar o pressuposto da independência dos resíduos possui como hipótese nula que “as variâncias de erro são todas iguais” e como hipótese alternativa que “as variâncias de erro são uma função multiplicativa de uma ou mais variáveis.” Recomendamos que usem os resíduos “Studentizados” (quociente resultante da divisão de um resíduo por uma estimativa de seu desvio padrão – uma forma de estatística \\(t\\) de Student, com a estimativa de erro variando entre os pontos) no teste de Breusch-Pagan (Koenker, 1981). A função bptest() da biblioteca {lmtest} aceita como argumento um modelo de regressão logística (objeto glm) e já possui como padrão resíduos “Studentizados.” Caso queira usar resíduos brutos indique o argumento studentize como FALSE.\n\n\nlibrary(lmtest)\nbptest(modelo_simples)\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_simples\nBP = 19.793, df = 2, p-value = 5.035e-05\n\nNote que o \\(p\\)-valor do Teste de Breusch-Pagan para o modelo_simples é menor que 0.05, demonstrando fortes evidências em favor da não rejeição da hipótese nula de dependência dos resíduos.\nTeste de Durbin-Watson\nO teste de Durbin-Watson (Durbin & Watson, 1950, 1951) é um teste estatístico usado para detectar a presença de autocorrelação dos resíduos de um modelo de regressão e testa o pressuposto da homogeneidade de variância dos resíduos. Possui como hipótese nula que os “erros são serialmente não correlacionados.” A função dwtest() da biblioteca {lmtest} aceita como argumento um modelo de regressão logística (objeto glm).\n\n\ndwtest(modelo_simples)\n\n\n\n    Durbin-Watson test\n\ndata:  modelo_simples\nDW = 1.7134, p-value = 1.678e-06\nalternative hypothesis: true autocorrelation is greater than 0\n\nNote que o \\(p\\)-valor do Teste de Durbin-Watson para o modelo_simples é menor que 0.05, indicando a rejeição da hipótese nula de não-correlação, violando o pressuposto da homogeneidade de variância dos resíduos.\nMulticolinearidade\nMulticolinearidade é a ocorrência de alta correlação entre duas ou mais variáveis independentes e pode levar a resultados distorcidos. Em geral, a multicolinearidade pode fazer com que os intervalos de confiança se ampliem, ou até mudar o sinal de influência das variáveis independentes (de positivo para negativo, por exemplo). Portanto, as inferências estatísticas de uma regressão com multicolinearidade não são confiáveis. Pode ser testado usando o Fator de Inflação de Variância (Variance Inflation Factor – VIF).\nOs VIFs medem o quanto da variância de cada coeficiente de regressão do modelo estatístico se encontra inflado em relação à situação em que as variáveis independentes não estão correlacionadas. Valores aceitáveis de VIF são menores que 10 (Hair et al., 1998). Para calcular os VIFs de uma modelo de regressão logística glm use a função vif() da biblioteca {car} (Fox & Weisberg, 2019).\n\n\nlibrary(car)\nvif(modelo_simples)\n\n\n     age      sex \n1.001022 1.001022 \n\nNote que os valores de VIFs para as variáveis independentes do modelo_simples estão todos dentro do limite aceitável (\\(<10\\)), demonstrando ausência de multicolinearidade e evidenciando que o pressuposto não foi violado.\nPseudo-\\(R^2\\)\n\nObserve que, embora muitos softwares estatísticos computem um pseudo-\\(R^2\\) para modelos de regressão logística, essa medida de determinação não é diretamente comparável ao \\(R^2\\) calculado para modelos de regressão linear. Na verdade, alguns estatísticos recomendam evitar a publicação de \\(R^2\\) (Harrell Jr, 2015; Hosmer Jr, Lemeshow, & Sturdivant, 2013), uma vez que pode ser mal interpretado em um contexto de regressão logística.\n\nHá várias técnicas de como calcular um pseudo-\\(R^2\\) propostas na literatura sendo que a principal é o pseudo-\\(R^2\\) e pseudo-\\(R^2\\) ajustado de McFadden (McFadden & others, 1973).\nA função PseudoR2() da biblioteca {DescTools} (Andri et mult. al., 2020) possui todas as principais técnicas de cálculo de pseudo-\\(R^2\\) podendo ser especificadas com o argumento which4.\n\n\nlibrary(DescTools)\nPseudoR2(modelo_simples, which = c(\"McFadden\", \"McFaddenAdj\"))\n\n\n   McFadden McFaddenAdj \n  0.2214598   0.2172183 \n\nTécnicas Avançadas de Modelos Lineares Generalizados.\nAssim como no tutorial de Regressão Linear, nesta seção apenas apresentaremos alternativas avançadas, não é o foco desse conteúdo introdutório apresentar de maneira detalhada, mas sim de apontar o leitor na direção correta.5\nModelos Lineares Generalizados Regularizados\nModelos Aditivos Generalizados\nModelos Lineares Generalizados Multiníveis\nModelos Lineares Generalizados Regularizados\nModelos lineares generalizados regularizados são um tipo de modelos lineares generalizados em que as estimativas dos coeficientes são restritas a zero. A magnitude (tamanho) dos coeficientes, bem como a magnitude do termo de erro, são penalizados. Modelos complexos são desencorajados, principalmente para evitar overfitting.\nTipos de Modelos Lineares Generalizados Regularizados\nDois tipos comumente usados de métodos de modelos lineares generalizados regularizados são Ridge e Lasso.\nRidge(Tikhonov, 1943) é uma forma de criar um modelo parcimonioso quando o número de variáveis preditoras em um conjunto excede o número de observações (\\(m > p\\)) ou quando um conjunto de dados tem forte multicolinearidade (correlações entre variáveis preditoras). A regressão Ridge pertence ao conjunto de ferramentas de regularização L2. A regularização L2 adiciona uma penalidade chamada penalidade L2, que é igual ao quadrado da magnitude dos coeficientes. Todos os coeficientes são reduzidos pelo mesmo fator, de modo que todos os coeficientes permanecem no modelo. A força do termo de penalidade é controlada por um parâmetro de ajuste. Quando este parâmetro de ajuste (\\(\\lambda\\)) é definido como zero, a regressão Ridge é igual à um modelo linear generalizado. Se \\(\\lambda = \\infty\\), todos os coeficientes são reduzidos a zero. A penalidade ideal é, portanto, algo entre \\(0\\) e \\(\\infty\\).\nLasso (least absolute shrinkage and selection operator – Lasso) (Efron & Hastie, 2016; Tibshirani, 1996) é um tipo de modelo linear generalizado que usa encolhimento (shrinkage). Encolhimento faz com os valores dos coeficientes sejam reduzidos em direção a um ponto central, como a média. Este tipo de redução é muito útil quando você tem altos níveis de muticolinearidade ou quando deseja automatizar certas partes da seleção de modelo, como seleção de variável / eliminação de parâmetro. Lasso usa a regularização L1 que limita o tamanho dos coeficientes adicionando uma penalidade L1 igual ao valor absoluto, ao invés do valor quadrado como L2, da magnitude dos coeficientes. Isso às vezes resulta na eliminação de alguns coeficientes completamente, o que pode resultar em modelos esparsos e seleção de variáveis.\nPara usar modelos lineares generalizados regularizados use a biblioteca {glmnet} (Simon, Friedman, Hastie, & Tibshirani, 2011).\nRegressão Aditiva - Modelos Aditivos Generalizados\nEm estatística, um modelo aditivo generalizado (generalized additive model – GAM) é um modelo linear generalizado no qual a variável de resposta depende linearmente de funções suaves (chamadas de splines) desconhecidas de algumas variáveis preditoras, e o interesse se concentra na inferência sobre essas funções suaves. Os GAMs foram desenvolvidos originalmente por Trevor Hastie e Robert Tibshirani (Hastie, Tibshirani, & others, 1986). Para usar GAMs no R use a biblioteca {gam} (Hastie, 2020).\nRegressão Multinível\nModelos multiníveis (também conhecidos como modelos lineares hierárquicos, modelo linear de efeitos mistos, modelos mistos, modelos de dados aninhados, coeficiente aleatório, modelos de efeitos aleatórios, modelos de parâmetros aleatórios ou designs de gráfico dividido) são modelos estatísticos de parâmetros que variam em mais de um nível (Luke, 2019).\nModelos multiníveis são particularmente apropriados para projetos de pesquisa onde os dados dos participantes são organizados em mais de um nível (ou seja, dados aninhados). As unidades de análise geralmente são indivíduos (em um nível inferior) que estão aninhados em unidades contextuais / agregadas (em um nível superior).\nModelos multiníveis geralmente se dividem em três abordagens:\nRandom intercept model: Modelo no qual cada grupo recebe uma constante (intercept) diferente\nRandom slope model: Modelo no qual cada grupo recebe um coeficiente diferente para cada variável independente\nRandom intercept-slope model: Modelo no qual cada grupo recebe tanto uma constante (intercept) quanto um coeficiente diferente para cada variável independente\n\nO primeiro autor possui um tutorial de Estatística Bayesiana com R e uma dos tutoriais é sobre regressão multinível.\nPara usar modelos multiníveis em R use a biblioteca {lme4} (Bates, Mächler, Bolker, & Walker, 2015).\nComentários Finais\nRegressão logística é a principal técnica de modelos lineares generalizados – extensão da regressão linear, sendo usada amplamente tanto em relatórios técnicos quanto na literatura científica, assim como tanto em contextos profissionais quanto acadêmicos. Caso o leitor tenha se interessado, convidamos à conhecer as outras técnicas de modelos lineares generalizados (Nelder & Wedderburn, 1972), como regressão de Poisson, regressão Binomial negativa, entre outros…\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] gt_0.2.2             lm.beta_1.5-1        lmtest_0.9-38       \n [4] zoo_1.8-8            ggfortify_0.4.11     sjPlot_2.8.7        \n [7] broom_0.7.4          palmerpenguins_0.1.0 magrittr_2.0.1      \n[10] mnormt_2.0.2         cowplot_1.1.1        tidyr_1.1.2         \n[13] DescTools_0.99.40    skimr_2.1.2          ggpubr_0.4.0        \n[16] car_3.0-10           carData_3.0-4        patchwork_1.1.1     \n[19] dplyr_1.0.4          ggplot2_3.3.3        DiagrammeR_1.0.6.1  \n[22] readxl_1.3.1        \n\nloaded via a namespace (and not attached):\n  [1] minqa_1.2.4        colorspace_2.0-0   ggsignif_0.6.0    \n  [4] ellipsis_0.3.1     class_7.3-17       rio_0.5.16        \n  [7] sjlabelled_1.1.7   rprojroot_2.0.2    estimability_1.3  \n [10] parameters_0.11.0  base64enc_0.1-3    gld_2.6.2         \n [13] rstudioapi_0.13    farver_2.0.3       fansi_0.4.2       \n [16] mvtnorm_1.1-1      lubridate_1.7.9.2  xml2_1.3.2        \n [19] splines_4.0.3      downlit_0.2.1      rootSolve_1.8.2.1 \n [22] knitr_1.31         sjmisc_2.8.6       jsonlite_1.7.2    \n [25] nloptr_1.2.2.2     ggeffects_1.0.1    effectsize_0.4.3  \n [28] compiler_4.0.3     emmeans_1.5.4      sjstats_0.18.1    \n [31] backports_1.2.1    assertthat_0.2.1   Matrix_1.2-18     \n [34] cli_2.3.0          visNetwork_2.0.9   htmltools_0.5.1.1 \n [37] tools_4.0.3        gtable_0.3.0       glue_1.4.2        \n [40] lmom_2.8           Rcpp_1.0.6         cellranger_1.1.0  \n [43] vctrs_0.3.6        nlme_3.1-149       insight_0.12.0    \n [46] xfun_0.21          stringr_1.4.0      lme4_1.1-26       \n [49] openxlsx_4.2.3     lifecycle_0.2.0    statmod_1.4.35    \n [52] rstatix_0.6.0      MASS_7.3-53        scales_1.1.1      \n [55] hms_1.0.0          expm_0.999-6       RColorBrewer_1.1-2\n [58] yaml_2.2.1         curl_4.3           Exact_2.1         \n [61] gridExtra_2.3      reticulate_1.18    sass_0.3.1        \n [64] distill_1.2        stringi_1.5.3      highr_0.8         \n [67] bayestestR_0.8.2   checkmate_2.0.0    e1071_1.7-4       \n [70] boot_1.3-25        zip_2.1.1          repr_1.1.3        \n [73] commonmark_1.7     rlang_0.4.10       pkgconfig_2.0.3   \n [76] evaluate_0.14      lattice_0.20-41    purrr_0.3.4       \n [79] htmlwidgets_1.5.3  labeling_0.4.2     tidyselect_1.1.0  \n [82] ggsci_2.9          bookdown_0.21      R6_2.5.0          \n [85] magick_2.6.0       generics_0.1.0     DBI_1.1.1         \n [88] pillar_1.4.7       haven_2.3.1        foreign_0.8-80    \n [91] withr_2.4.1        mgcv_1.8-33        abind_1.4-5       \n [94] tibble_3.0.6       performance_0.7.0  modelr_0.1.8      \n [97] crayon_1.4.1       utf8_1.1.4         tmvnsim_1.0-2     \n[100] rmarkdown_2.6      grid_4.0.3         data.table_1.13.6 \n[103] forcats_0.5.1      digest_0.6.27      xtable_1.8-4      \n[106] munsell_0.5.0     \n\n\n\n\nAndri et mult. al., S. (2020). DescTools: Tools for descriptive statistics. Retrieved from https://cran.r-project.org/package=DescTools\n\n\nBates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1–48. https://doi.org/10.18637/jss.v067.i01\n\n\nBreusch, T. S., & Pagan, A. R. (1979). A simple test for heteroscedasticity and random coefficient variation. Econometrica: Journal of the Econometric Society, 1287–1294.\n\n\nCook, R. D., & Weisberg, S. (1983). Diagnostics for heteroscedasticity in regression. Biometrika, 70(1), 1–10.\n\n\nCox, D. R. (1958). The regression analysis of binary sequences. Journal of the Royal Statistical Society: Series B (Methodological), 20(2), 215–232.\n\n\nDurbin, J., & Watson, G. S. (1950). Testing for serial correlation in least squares regression: i. Biometrika, 37(3/4), 409–428.\n\n\nDurbin, J., & Watson, G. S. (1951). Testing for serial correlation in least squares regression. II. Biometrika, 38(1/2), 159–179.\n\n\nEfron, B., & Hastie, T. (2016). Computer age statistical inference (Vol. 5). Cambridge University Press.\n\n\nFox, J., & Weisberg, S. (2019). An R companion to applied regression (Third). Retrieved from https://socialsciences.mcmaster.ca/jfox/Books/Companion/\n\n\nHair, J. F., Black, W. C., Babin, B. J., Anderson, R. E., Tatham, R. L., & others. (1998). Multivariate data analysis (Vol. 5). Prentice hall Upper Saddle River, NJ.\n\n\nHarrell Jr, F. E. (2015). Regression modeling strategies: With applications to linear models, logistic and ordinal regression, and survival analysis. Springer.\n\n\nHastie, T. (2020). Gam: Generalized additive models. Retrieved from https://CRAN.R-project.org/package=gam\n\n\nHastie, T., Tibshirani, R., & others. (1986). Generalized additive models. Statistical Science, 1(3), 297–310.\n\n\nHosmer Jr, D. W., Lemeshow, S., & Sturdivant, R. X. (2013). Applied logistic regression (Vol. 398). John Wiley & Sons.\n\n\nKoenker, R. (1981). A note on studentizing a test for heteroscedasticity. Journal of Econometrics, 17(1), 107–112.\n\n\nLuke, D. A. (2019). Multilevel modeling (Vol. 143). SAGE Publications, Incorporated.\n\n\nLüdecke, D. (2020). sjPlot: Data visualization for statistics in social science. Retrieved from https://CRAN.R-project.org/package=sjPlot\n\n\nMcFadden, D., & others. (1973). Conditional logit analysis of qualitative choice behavior.\n\n\nNelder, J. A., & Wedderburn, R. W. (1972). Generalized linear models. Journal of the Royal Statistical Society: Series A (General), 135(3), 370–384.\n\n\nSimon, N., Friedman, J., Hastie, T., & Tibshirani, R. (2011). Regularization paths for cox’s proportional hazards model via coordinate descent. Journal of Statistical Software, 39(5), 1–13. Retrieved from http://www.jstatsoft.org/v39/i05/\n\n\nTibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B (Methodological), 58(1), 267–288.\n\n\nTikhonov, A. N. (1943). On the stability of inverse problems. Dokl. Akad. Nauk SSSR, 39, 195–198.\n\n\nVenables, W. N., & Ripley, B. D. (2002). Modern applied statistics with s (Fourth). Retrieved from http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nZeileis, A., & Hothorn, T. (2002). Diagnostic checking in regression relationships. R News, 2(3), 7–10. Retrieved from https://CRAN.R-project.org/doc/Rnews/\n\n\ncaso o leitor se interesse existe diversas outras transformações que dão origens a diferentes modelos lineares generalizados, veja Nelder & Wedderburn (1972).↩︎\nem sua escala bruta os coeficientes de uma regressão logística estão representados como o logaritmo da chance (log odds).↩︎\nmatematicamente falando interação é uma multiplicação entre as duas variáveis independentes↩︎\npodem ser escolhidas dentre as técnicas: \"McFadden\", \"McFaddenAdj\", \"CoxSnell\", \"Nagelkerke\", \"AldrichNelson\", \"VeallZimmermann\", \"Efron\", \"McKelveyZavoina\", \"Tjur\"; ou todas \"all\".↩︎\nNote que todas as técnicas avançadas listadas aqui são as mesmas listadas no tutorial de Regressão Linear apenas com a nomenclatura de “modelos lineares generalizados” ao invés de “regressão linear.”↩︎\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "aux-Anscombe.html",
      "title": "Quarteto de Anscombe",
      "description": "A importância de visualizar dados antes de aplicar testes estatísticos inferenciais e a limitação das estatísticas descritivas.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nDataset anscombe\nVisualizações\nEstatísticas Descritivas\nModelos de Regressão\nComentários Finais\nAmbiente\n\n\nO quarteto de Anscombe compreende quatro conjuntos de dados que têm estatísticas descritivas simples quase idênticas, mas têm distribuições muito diferentes e parecem muito diferentes quando representados graficamente. Cada conjunto de dados consiste em onze (x, y) pontos. Eles foram construídos em 1973 pelo estatístico Francis Anscombe (Anscombe, 1973) para demonstrar a importância dos dados gráficos antes de analisá-los e o efeito de outliers e outras observações influentes nas propriedades estatísticas. Ele descreveu o artigo como tendo a intenção de contrariar a impressão entre os estatísticos de que “os cálculos numéricos são exatos, mas os gráficos são aproximados.”\nFalamos na tutorial 2 de \\(p\\)-valores que “somos adeptos de visualizações e usamos constantemente nas nossas análises. Mas, na Estatística, as visualizações são muito boas para mostrar alguma tendência, característica ou peculiaridade dos dados. Agora, para provar algo, é necessário um teste estatístico.” Para mostrar a importância dos gráficos vamos explorar um pouco os 4 conjuntos de dados do quarteto de Anscombe. A moral da história aqui é que se deve olhar um conjunto de dados graficamente antes de começar a analisar de acordo com um tipo particular de relacionamento, além da inadequação das propriedades estatísticas básicas para descrever conjuntos de dados realistas.\nDataset anscombe\nO R possui como padrão o dataset anscombe que pode ser carregado pela função data() sem a instalação de qualquer biblioteca adicional. O dataset anscombe possui os quatro conjuntos de (x,y) como colunas (variáveis) e são identificadas de x1 e y1 à x4 e y4. Veja na tabela abaixo as onze observações dos quatro conjuntos de Anscombe do dataset anscombe1:\n\n\nlibrary(gt)\ndata(\"anscombe\")\ngt(anscombe, rownames_to_stub = TRUE) %>%\n  tab_header(title = \"Quarteto de Anscombe\")\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#baiwgmtnpg .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#baiwgmtnpg .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#baiwgmtnpg .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#baiwgmtnpg .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#baiwgmtnpg .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#baiwgmtnpg .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#baiwgmtnpg .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#baiwgmtnpg .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#baiwgmtnpg .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#baiwgmtnpg .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#baiwgmtnpg .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#baiwgmtnpg .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#baiwgmtnpg .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#baiwgmtnpg .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#baiwgmtnpg .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#baiwgmtnpg .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#baiwgmtnpg .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#baiwgmtnpg .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#baiwgmtnpg .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#baiwgmtnpg .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#baiwgmtnpg .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#baiwgmtnpg .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#baiwgmtnpg .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#baiwgmtnpg .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#baiwgmtnpg .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#baiwgmtnpg .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#baiwgmtnpg .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#baiwgmtnpg .gt_left {\n  text-align: left;\n}\n\n#baiwgmtnpg .gt_center {\n  text-align: center;\n}\n\n#baiwgmtnpg .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#baiwgmtnpg .gt_font_normal {\n  font-weight: normal;\n}\n\n#baiwgmtnpg .gt_font_bold {\n  font-weight: bold;\n}\n\n#baiwgmtnpg .gt_font_italic {\n  font-style: italic;\n}\n\n#baiwgmtnpg .gt_super {\n  font-size: 65%;\n}\n\n#baiwgmtnpg .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nQuarteto de Anscombe\n    \n    \n      x1\n      x2\n      x3\n      x4\n      y1\n      y2\n      y3\n      y4\n    1\n      10\n      10\n      10\n      8\n      8.04\n      9.14\n      7.46\n      6.58\n    2\n      8\n      8\n      8\n      8\n      6.95\n      8.14\n      6.77\n      5.76\n    3\n      13\n      13\n      13\n      8\n      7.58\n      8.74\n      12.74\n      7.71\n    4\n      9\n      9\n      9\n      8\n      8.81\n      8.77\n      7.11\n      8.84\n    5\n      11\n      11\n      11\n      8\n      8.33\n      9.26\n      7.81\n      8.47\n    6\n      14\n      14\n      14\n      8\n      9.96\n      8.10\n      8.84\n      7.04\n    7\n      6\n      6\n      6\n      8\n      7.24\n      6.13\n      6.08\n      5.25\n    8\n      4\n      4\n      4\n      19\n      4.26\n      3.10\n      5.39\n      12.50\n    9\n      12\n      12\n      12\n      8\n      10.84\n      9.13\n      8.15\n      5.56\n    10\n      7\n      7\n      7\n      8\n      4.82\n      7.26\n      6.42\n      7.91\n    11\n      5\n      5\n      5\n      8\n      5.68\n      4.74\n      5.73\n      6.89\n    \n\nVisualizações\nAqui na figura 1 vocês podem observar a diferença entre os quatro conjuntos de Anscombe:\nO primeiro gráfico de dispersão (canto superior esquerdo) parece ser uma relação linear simples, correspondendo a duas variáveis correlacionadas onde y pode ser modelado como gaussiano com a média linearmente dependente de x.\nO segundo gráfico (canto superior direito) não é distribuído Normalmente; embora uma relação entre as duas variáveis seja óbvia, não é linear e o coeficiente de correlação de Pearson não é relevante. Uma regressão usando um termo quadrático (\\(x^2\\)) seria mais apropriada.\nNo terceiro gráfico (canto inferior esquerdo), a distribuição é linear, mas deve ter uma linha de regressão diferente (uma regressão robusta teria sido necessária). A regressão calculada é compensada por um outlier que exerce influência suficiente para diminuir o coeficiente de correlação de 1 para 0.816.\nFinalmente, o quarto gráfico (canto inferior direito) mostra um exemplo em que um ponto de alta influência é suficiente para produzir um alto coeficiente de correlação, embora os outros pontos de dados não indiquem qualquer relação entre as variáveis.\n\n\nlibrary(ggplot2)\nanscombe %>%\n  ggplot(aes(x, y, group = conjunto)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"Red\", se = FALSE) +\n  facet_wrap(~ conjunto, labeller = \"label_both\", ncol = 2) +\n  theme(legend.position = \"none\")\n\n\n\n\nFigure 1: O quarteto de Anscombe\n\n\n\nEstatísticas Descritivas\nO mais intrigante é que esses quatro conjuntos, quando visualizados demonstram sem dúvida quatro naturezas de relações entre variáveis diferentes; mas quando analisamos apenas as estatísticas descritivas temos o mesmo resultado, conforme demonstrado na tabela com estatísticas descritivas dos quatro conjuntos2:\n\n\nlibrary(gtsummary)\ntheme_gtsummary_language(\"pt\")\ntbl_summary(anscombe,\n            by = conjunto,\n            type = all_continuous() ~ \"continuous2\",\n            statistic = list(\n              all_continuous() ~ c(\"{mean}\",\n                                   \"{sd}\")),\n  digits = all_continuous() ~ 2) %>%\n  bold_labels() %>%\n  italicize_levels() %>%\n  as_gt() %>%\n  tab_header(title = \"Estatísticas Descritivas do Quarteto de Anscombe\",\n             subtitle = \"Agrupadas por Conjunto\")\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#mlymtjilhg .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#mlymtjilhg .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#mlymtjilhg .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#mlymtjilhg .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#mlymtjilhg .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mlymtjilhg .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#mlymtjilhg .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#mlymtjilhg .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#mlymtjilhg .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#mlymtjilhg .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#mlymtjilhg .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#mlymtjilhg .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#mlymtjilhg .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#mlymtjilhg .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#mlymtjilhg .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#mlymtjilhg .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#mlymtjilhg .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#mlymtjilhg .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mlymtjilhg .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#mlymtjilhg .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mlymtjilhg .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#mlymtjilhg .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#mlymtjilhg .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mlymtjilhg .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#mlymtjilhg .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#mlymtjilhg .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#mlymtjilhg .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#mlymtjilhg .gt_left {\n  text-align: left;\n}\n\n#mlymtjilhg .gt_center {\n  text-align: center;\n}\n\n#mlymtjilhg .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#mlymtjilhg .gt_font_normal {\n  font-weight: normal;\n}\n\n#mlymtjilhg .gt_font_bold {\n  font-weight: bold;\n}\n\n#mlymtjilhg .gt_font_italic {\n  font-style: italic;\n}\n\n#mlymtjilhg .gt_super {\n  font-size: 65%;\n}\n\n#mlymtjilhg .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nEstatísticas Descritivas do Quarteto de Anscombe\n    Agrupadas por Conjunto\n    Características\n      1, N = 11\n      2, N = 11\n      3, N = 11\n      4, N = 11\n    x\n      \n      \n      \n      \n    Média\n      9.00\n      9.00\n      9.00\n      9.00\n    Desvio Padrão\n      3.32\n      3.32\n      3.32\n      3.32\n    y\n      \n      \n      \n      \n    Média\n      7.50\n      7.50\n      7.50\n      7.50\n    Desvio Padrão\n      2.03\n      2.03\n      2.03\n      2.03\n    \n\nAlém disso, a correlação é a mesma (0.8163662) nos quatro conjuntos:\n\n\nlibrary(dplyr)\nlibrary(purrr)\ntibble(conjunto = as.factor(1:4),\n       correlação = unique(anscombe$conjunto) %>%\n  map_dbl(~ cor(subset(anscombe, conjunto == .x, select = x),\n                subset(anscombe, conjunto == .x, select = y)))) %>%\n  gt() %>%\n  tab_header(title = \"Correlações do Quarteto de Anscombe\") %>%\n  tab_source_note(md(\"*Observação: Correlação calculada conforme a correlação de Pearson*\"))\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#yosqkgswzc .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#yosqkgswzc .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yosqkgswzc .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#yosqkgswzc .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#yosqkgswzc .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yosqkgswzc .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yosqkgswzc .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#yosqkgswzc .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#yosqkgswzc .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#yosqkgswzc .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#yosqkgswzc .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#yosqkgswzc .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#yosqkgswzc .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#yosqkgswzc .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#yosqkgswzc .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#yosqkgswzc .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#yosqkgswzc .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#yosqkgswzc .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yosqkgswzc .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#yosqkgswzc .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yosqkgswzc .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#yosqkgswzc .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#yosqkgswzc .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yosqkgswzc .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yosqkgswzc .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#yosqkgswzc .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yosqkgswzc .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#yosqkgswzc .gt_left {\n  text-align: left;\n}\n\n#yosqkgswzc .gt_center {\n  text-align: center;\n}\n\n#yosqkgswzc .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#yosqkgswzc .gt_font_normal {\n  font-weight: normal;\n}\n\n#yosqkgswzc .gt_font_bold {\n  font-weight: bold;\n}\n\n#yosqkgswzc .gt_font_italic {\n  font-style: italic;\n}\n\n#yosqkgswzc .gt_super {\n  font-size: 65%;\n}\n\n#yosqkgswzc .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nCorrelações do Quarteto de Anscombe\n    \n    conjunto\n      correlação\n    1\n      0.8164205\n    2\n      0.8162365\n    3\n      0.8162867\n    4\n      0.8165214\n    Observação: Correlação calculada conforme a correlação de Pearson\n    \n\nModelos de Regressão\nO mais interessante é que se formos aplicar uma regressão linear teremos os mesmo \\(p\\)-valores, coeficientes, \\(R^2\\) e \\(R^2\\) ajustado para todos os quatro conjuntos. Veja na tabela abaixo:\n\n\nlibrary(broom)\nmap_dfr(1:4,\n        ~ tidy(lm(y ~ x, subset(anscombe, conjunto == .x)), conf.int = TRUE)) %>%\n  filter(term == \"x\") %>%\n  mutate(Conjunto = unique(anscombe$conjunto)) %>%\n  inner_join(map_dfr(unique(anscombe$conjunto),\n                     ~ glance(lm(y ~ x, subset(anscombe, conjunto == .x)),\n                              conf.int = TRUE)) %>%\n               mutate(Conjunto = unique(anscombe$conjunto)),\n             by = \"Conjunto\") %>%\n  relocate(Conjunto) %>%\n  dplyr::select(Conjunto, estimate, std.error, p.value.x,\n          conf.low, conf.high, r.squared, adj.r.squared) %>%\n  gt() %>%\n  tab_header(\"Modelo de Regressão Linear do Quarteto de Anscombe\",\n             md(\"Fórmula: `y ~ x`\"))\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#fgdjqphucl .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#fgdjqphucl .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fgdjqphucl .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#fgdjqphucl .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#fgdjqphucl .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fgdjqphucl .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fgdjqphucl .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#fgdjqphucl .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#fgdjqphucl .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#fgdjqphucl .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#fgdjqphucl .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#fgdjqphucl .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#fgdjqphucl .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#fgdjqphucl .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#fgdjqphucl .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#fgdjqphucl .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#fgdjqphucl .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#fgdjqphucl .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fgdjqphucl .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#fgdjqphucl .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fgdjqphucl .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#fgdjqphucl .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#fgdjqphucl .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fgdjqphucl .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fgdjqphucl .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#fgdjqphucl .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fgdjqphucl .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#fgdjqphucl .gt_left {\n  text-align: left;\n}\n\n#fgdjqphucl .gt_center {\n  text-align: center;\n}\n\n#fgdjqphucl .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#fgdjqphucl .gt_font_normal {\n  font-weight: normal;\n}\n\n#fgdjqphucl .gt_font_bold {\n  font-weight: bold;\n}\n\n#fgdjqphucl .gt_font_italic {\n  font-style: italic;\n}\n\n#fgdjqphucl .gt_super {\n  font-size: 65%;\n}\n\n#fgdjqphucl .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nModelo de Regressão Linear do Quarteto de Anscombe\n    Fórmula: y ~ x\n    Conjunto\n      estimate\n      std.error\n      p.value.x\n      conf.low\n      conf.high\n      r.squared\n      adj.r.squared\n    1\n      0.5000909\n      0.1179055\n      0.002169629\n      0.2333701\n      0.7668117\n      0.6665425\n      0.6294916\n    2\n      0.5000000\n      0.1179637\n      0.002178816\n      0.2331475\n      0.7668525\n      0.6662420\n      0.6291578\n    3\n      0.4997273\n      0.1178777\n      0.002176305\n      0.2330695\n      0.7663851\n      0.6663240\n      0.6292489\n    4\n      0.4999091\n      0.1178189\n      0.002164602\n      0.2333841\n      0.7664341\n      0.6667073\n      0.6296747\n    \n\nUma maneira de diferenciar os quatro conjuntos de Anscombe numa regressão linear é analisar os seus resíduos, conforme figura 2. Aqui claramente vemos que apenas o gráfico do canto superior direito possui resíduos nos quais não é possível identificar nenhum padrão ou característica3.\n\n\nlibrary(patchwork)\nmap(1:4, ~ lm(y ~ x, subset(anscombe, conjunto == .x))) %>%\n  map2(1:4,\n     ~ ggplot(augment(.x), aes(x = .fitted, y = .resid)) +\n       geom_point() +\n       geom_smooth(se = FALSE, method = \"lm\") +\n       labs(\n         x = \"Valor de x\",\n         y = \"Resíduos\",\n         title = paste(\"Conjunto\", as.character(.y))\n       )) %>%\n  reduce(`+`) +\n  plot_layout(ncol = 2)\n\n\n\n\nFigure 2: Resíduos dos Modelos de Regressão Linear Quarteto de Anscombe\n\n\n\nInclusive quando fazemos o teste studentizado de Breusch-Pagan(Breusch & Pagan, 1979; Koenker, 1981), todos os modelos falham em rejeitar a hipótese nula de que “a variância dos resíduos são iguais.” Provavelmente isto se deve por conta do tamanho da amostra ser pequeno (\\(n=11\\)) em todos os quatro conjuntos.\n\n\nlibrary(lmtest)\nbptest(lm(y ~ x, subset(anscombe, conjunto == 1)))\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  lm(y ~ x, subset(anscombe, conjunto == 1))\nBP = 0.65531, df = 1, p-value = 0.4182\n\nbptest(lm(y ~ x, subset(anscombe, conjunto == 2)))\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  lm(y ~ x, subset(anscombe, conjunto == 2))\nBP = 8.0774e-31, df = 1, p-value = 1\n\nbptest(lm(y ~ x, subset(anscombe, conjunto == 3)))\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  lm(y ~ x, subset(anscombe, conjunto == 3))\nBP = 2.7234, df = 1, p-value = 0.09889\n\nbptest(lm(y ~ x, subset(anscombe, conjunto == 4)))\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  lm(y ~ x, subset(anscombe, conjunto == 4))\nBP = 1.1821, df = 1, p-value = 0.2769\n\nComentários Finais\nO quarteto de Anscombe (Anscombe, 1973) é uma maneira de ilustrar a importância de visualizações na análise de dados. Deve-se sempre olhar um conjunto de dados graficamente antes de começar a qualquer análise. Em especial, são ilustrados diversos contextos nos quais as propriedades estatísticas básicas para descrever conjuntos de dados são inadequadas.\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] purrr_0.3.4          gtsummary_1.3.6      gt_0.2.2            \n [4] lm.beta_1.5-1        lmtest_0.9-38        zoo_1.8-8           \n [7] ggfortify_0.4.11     sjPlot_2.8.7         broom_0.7.4         \n[10] palmerpenguins_0.1.0 magrittr_2.0.1       mnormt_2.0.2        \n[13] cowplot_1.1.1        tidyr_1.1.2          DescTools_0.99.40   \n[16] skimr_2.1.2          ggpubr_0.4.0         car_3.0-10          \n[19] carData_3.0-4        patchwork_1.1.1      dplyr_1.0.4         \n[22] ggplot2_3.3.3        DiagrammeR_1.0.6.1   readxl_1.3.1        \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1     repr_1.1.3          splines_4.0.3      \n  [4] usethis_2.0.1       digest_0.6.27       htmltools_0.5.1.1  \n  [7] magick_2.6.0        fansi_0.4.2         checkmate_2.0.0    \n [10] openxlsx_4.2.3      modelr_0.1.8        colorspace_2.0-0   \n [13] haven_2.3.1         xfun_0.21           crayon_1.4.1       \n [16] jsonlite_1.7.2      Exact_2.1           lme4_1.1-26        \n [19] survival_3.2-7      glue_1.4.2          gtable_0.3.0       \n [22] emmeans_1.5.4       sjstats_0.18.1      sjmisc_2.8.6       \n [25] abind_1.4-5         scales_1.1.1        mvtnorm_1.1-1      \n [28] DBI_1.1.1           rstatix_0.6.0       ggeffects_1.0.1    \n [31] Rcpp_1.0.6          xtable_1.8-4        performance_0.7.0  \n [34] tmvnsim_1.0-2       reticulate_1.18     foreign_0.8-80     \n [37] htmlwidgets_1.5.3   RColorBrewer_1.1-2  ellipsis_0.3.1     \n [40] pkgconfig_2.0.3     farver_2.0.3        sass_0.3.1         \n [43] utf8_1.1.4          tidyselect_1.1.0    labeling_0.4.2     \n [46] rlang_0.4.10        effectsize_0.4.3    munsell_0.5.0      \n [49] cellranger_1.1.0    tools_4.0.3         visNetwork_2.0.9   \n [52] cli_2.3.0           generics_0.1.0      sjlabelled_1.1.7   \n [55] evaluate_0.14       stringr_1.4.0       yaml_2.2.1         \n [58] fs_1.5.0            knitr_1.31          zip_2.1.1          \n [61] rootSolve_1.8.2.1   nlme_3.1-149        xml2_1.3.2         \n [64] compiler_4.0.3      rstudioapi_0.13     curl_4.3           \n [67] e1071_1.7-4         ggsignif_0.6.0      tibble_3.0.6       \n [70] statmod_1.4.35      broom.helpers_1.1.0 stringi_1.5.3      \n [73] highr_0.8           parameters_0.11.0   forcats_0.5.1      \n [76] lattice_0.20-41     Matrix_1.2-18       commonmark_1.7     \n [79] nloptr_1.2.2.2      ggsci_2.9           vctrs_0.3.6        \n [82] pillar_1.4.7        lifecycle_0.2.0     estimability_1.3   \n [85] data.table_1.13.6   insight_0.12.0      lmom_2.8           \n [88] R6_2.5.0            bookdown_0.21       gridExtra_2.3      \n [91] rio_0.5.16          gld_2.6.2           distill_1.2        \n [94] boot_1.3-25         MASS_7.3-53         assertthat_0.2.1   \n [97] rprojroot_2.0.2     withr_2.4.1         mgcv_1.8-33        \n[100] bayestestR_0.8.2    expm_0.999-6        hms_1.0.0          \n[103] grid_4.0.3          class_7.3-17        minqa_1.2.4        \n[106] rmarkdown_2.6       downlit_0.2.1       lubridate_1.7.9.2  \n[109] base64enc_0.1-3    \n\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American Statistician, 27(1), 17–21.\n\n\nBreusch, T. S., & Pagan, A. R. (1979). A simple test for heteroscedasticity and random coefficient variation. Econometrica: Journal of the Econometric Society, 1287–1294.\n\n\nKoenker, R. (1981). A note on studentizing a test for heteroscedasticity. Journal of Econometrics, 17(1), 107–112.\n\n\nCaso fique interessado em como montar tabelas para publicações, veja o nosso conteúdo auxiliar de tabelas para publicação.\n\n↩︎\nCaso fique interessado em como montar tabelas para publicações, veja o nosso conteúdo auxiliar de tabelas para publicação.\n\n↩︎\npara saber mais sobre regressão linear e seus pressupostos veja o conteúdo do tutorial sobre regressão linear↩︎\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "aux-Dados_Faltantes.html",
      "title": "Dados Faltantes",
      "description": "Como identificar, remover ou imputar valores de dados faltantes.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nO que são dados faltantes?\nComo testar para dados faltantes?\nO que fazer com dados faltantes?\nRemover dados faltantes\nImputar valores nos dados faltantes\n\nAmbiente\n\n\nDados faltantes são um problema comum em qualquer análise de dados.\nO que são dados faltantes?\nOs valores ausentes podem ser de três tipos gerais (Kang, 2013; Rubin, 1976):\nTotalmente ausente de maneira aleatória (missing completely at random – MCAR): Quando os dados ausentes são MCAR, a presença / ausência de dados é completamente independente das variáveis observáveis e dos parâmetros de interesse. Nesse caso, as análises realizadas nos dados são imparciais. Na prática, é altamente improvável. Pode haver perda de potência das técnicas estatísticas, mas os parâmetros estimados não são influenciados pela ausência de dados.\nAusente de maneira aleatória (missing at random – MAR): Quando os dados ausentes não são aleatórios, mas podem ser totalmente relacionados a uma variável onde há informações completas. Um exemplo1 é que os homens têm menos probabilidade de preencher uma pesquisa sobre depressão, mas isso não tem nada a ver com seu nível de depressão, após levar em conta a masculinidade. Esse tipo de dados ausentes pode induzir um viés em sua análise, especialmente se desequilibrar seus dados por causa de muitos valores ausentes em uma determinada categoria.\nAusente de maneira não-aleatória (missing not at random – MNAR): Quando os valores ausentes não são MCAR nem MAR. No exemplo anterior, esse seria o caso se as pessoas tendessem a não responder à pesquisa dependendo de seu nível de depressão. Os casos de dados MNAR são problemáticos. A única maneira de obter uma estimativa imparcial dos parâmetros em tal caso é modelar os dados ausentes2. O modelo pode então ser incorporado em um mais complexo para estimar os valores ausentes.\nComo testar para dados faltantes?\nUm teste muito usado é o Teste de MCAR de Little (R. J. A. Little, 1988) que possui como hipótese nula “os dados faltantes são totalmente ausentes de maneira aleatória (MCAR)”. Ou seja, um \\(p\\)-valor pequeno (\\(p < 0.05\\)) é geralmente interpretado como evidências contrárias que os dados são MCAR. O teste é baseado em um teste de chi-quadrado sobre frequências esperadas vs frequências observadas.\nA biblioteca {naniar} (Tierney, Cook, McBain, & Fay, 2020) possui a função mcar_test() que implementa o teste de MCAR de Little. Além disso, possui diversas outras funcionalidades para sumarizar, visualizar e manipular com dados faltantes. Caso queira incorporar na sua análise recomendamos ler o manual da biblioteca.\nO que fazer com dados faltantes?\nO melhor método possível de lidar com os dados ausentes é evitar o problema planejando bem o estudo e coletando os dados cuidadosamente. Caso isso não seja possível, temos duas abordagens básicas para lidar com dados faltantes:\nremover os dados faltantes.\nimputar valores nos dados faltantes.\nRemover dados faltantes\nA remoção de dados faltantes se divide em duas principais abordagens usando a função na.omit() padrão do R:\nremoção de observações com dados faltantes: aqui removemos as linhas com dados faltantes df <- na.omit(df).\nremoção de variáveis com dados faltantes: aqui removemos as colunas com dados faltantes df <- t(na.omit(t(df))).\nImputar valores nos dados faltantes\n\n“The idea of imputation is both seductive and dangerous” (R. J. Little & Rubin, 2019)\n\nA imputação de dados é um método aplicado para imputar um valor para cada item ausente. De acordo com R. J. Little & Rubin (2019), imputações de dados simples podem ser definidas como médias ou extrações de uma distribuição preditiva de valores ausentes, requerem um método de criação de uma distribuição preditiva para imputação com base nos dados observados e definem duas abordagens genéricas para gerar tal distribuição preditiva: modelagem explícita e modelagem implícita.\nNa modelagem explícita, a distribuição preditiva é baseada em um modelo estatístico formal, por exemplo, normal multivariado, portanto, as suposições são explícitas. Exemplos de modelagem explícita são imputação de média, imputação de regressão, imputação de regressão estocástica.\nNa modelagem implícita3, o foco está em um algoritmo, o que implica um modelo subjacente. Suposições estão implícitas, mas ainda precisam ser avaliadas com cuidado para garantir que sejam razoáveis.\nDentre as diversas maneiras de imputar valores ao dados faltantes, as mais comuns são três:\nimputar a média.\nimputar a mediana.\nimputar o último valor ocorrido (last observation carried forward – LOFC): muito usada em séries temporais.\nMas ainda há maneiras mais avançadas e que desempenham melhor em certas condições (não cobriremos essas técnicas aqui):\nImputação por \\(k\\)-vizinhos mais próximos (\\(k\\)-nearest neighbors imputation) (Troyanskaya et al., 2001).\nImputação por florestas aleatórias (random forest imputation) (Pantanowitz & Marwala, 2009).\nA biblioteca DescTools(Andri et mult. al., 2020) é uma coleção de funções focadas especialmente na parte descritiva de análise de um dataset. Inclusive a função Impute() – imputar valores em dados faltates usando qualquer função do R – e a função LOCF() que permite imputar o último valor ocorrido.\nPara mostrar as abordagens, geramos um dataset de uma série temporal de uma semana com dados faltantes:\n\n\nlibrary(DescTools)\nset.seed(123)\ndf <- data.frame(\n  dia = c(\"seg\", \"ter\", \"qua\", \"qui\", \"sex\", \"sab\", \"dom\"),\n  valor = runif(7))\nindices_aleatorios <- sample(1:nrow(df), 2)\ndf[indices_aleatorios[1], 2] <- NA\ndf[indices_aleatorios[2], 2] <- NA\n\n\n\nTeste MCAR de Little\n\n\nlibrary(naniar)\nmcar_test(df)\n\n\n[90m# A tibble: 1 x 4[39m\n  statistic    df p.value missing.patterns\n      [3m[90m<dbl>[39m[23m [3m[90m<dbl>[39m[23m   [3m[90m<dbl>[39m[23m            [3m[90m<int>[39m[23m\n[90m1[39m     0.700     1   0.403                2\n\nO teste retornou um \\(p\\)-valor de 0.4027837, e não conseguimos rejeitar a \\(H_0\\) de que “os dados faltantes são totalmente ausentes de maneira aleatória (MCAR).” Notem que o nosso dataset possui apenas 7 observações e por isso o teste não possui poder o suficiente para rejeitar a hipótese nula caso ela seja falsa.\nImputar a média\n\n\ndf$media <- Impute(df$valor, FUN = mean(df$valor, na.rm = TRUE))\n\n\n\nImputar a mediana\n\n\ndf$mediana <- Impute(df$valor, FUN = median(df$valor, na.rm = TRUE))\n\n\n\nImputar o último valor ocorrido – LOCF\n\n\ndf$LOCF <- LOCF(df$valor)\n\n\n\nComparação dos resultados\n\n\nlibrary(skimr)\nlibrary(gt)\ndf %>% gt() %>% tab_header(\"Dados Faltantes usando as diferentes Técnicas de Imputação\")\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#etnvyzesyy .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#etnvyzesyy .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#etnvyzesyy .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#etnvyzesyy .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#etnvyzesyy .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#etnvyzesyy .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#etnvyzesyy .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#etnvyzesyy .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#etnvyzesyy .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#etnvyzesyy .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#etnvyzesyy .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#etnvyzesyy .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#etnvyzesyy .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#etnvyzesyy .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#etnvyzesyy .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#etnvyzesyy .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#etnvyzesyy .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#etnvyzesyy .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#etnvyzesyy .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#etnvyzesyy .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#etnvyzesyy .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#etnvyzesyy .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#etnvyzesyy .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#etnvyzesyy .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#etnvyzesyy .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#etnvyzesyy .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#etnvyzesyy .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#etnvyzesyy .gt_left {\n  text-align: left;\n}\n\n#etnvyzesyy .gt_center {\n  text-align: center;\n}\n\n#etnvyzesyy .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#etnvyzesyy .gt_font_normal {\n  font-weight: normal;\n}\n\n#etnvyzesyy .gt_font_bold {\n  font-weight: bold;\n}\n\n#etnvyzesyy .gt_font_italic {\n  font-style: italic;\n}\n\n#etnvyzesyy .gt_super {\n  font-size: 65%;\n}\n\n#etnvyzesyy .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nDados Faltantes usando as diferentes Técnicas de Imputação\n    \n    dia\n      valor\n      media\n      mediana\n      LOCF\n    seg\n      0.2875775\n      0.2875775\n      0.2875775\n      0.2875775\n    ter\n      0.7883051\n      0.7883051\n      0.7883051\n      0.7883051\n    qua\n      NA\n      0.6854946\n      0.7883051\n      0.7883051\n    qui\n      0.8830174\n      0.8830174\n      0.8830174\n      0.8830174\n    sex\n      0.9404673\n      0.9404673\n      0.9404673\n      0.9404673\n    sab\n      NA\n      0.6854946\n      0.7883051\n      0.9404673\n    dom\n      0.5281055\n      0.5281055\n      0.5281055\n      0.5281055\n    \n\nskim(df)\n\n\nTable 1: Data summary\nName\ndf\nNumber of rows\n7\nNumber of columns\n5\n_______________________\n\nColumn type frequency:\n\ncharacter\n1\nnumeric\n4\n________________________\n\nGroup variables\nNone\nVariable type: character\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\ndia\n0\n1\n3\n3\n0\n7\n0\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nvalor\n2\n0.71\n0.69\n0.27\n0.29\n0.53\n0.79\n0.88\n0.94\n▃▃▁▃▇\nmedia\n0\n1.00\n0.69\n0.22\n0.29\n0.61\n0.69\n0.84\n0.94\n▂▂▁▇▅\nmediana\n0\n1.00\n0.71\n0.23\n0.29\n0.66\n0.79\n0.84\n0.94\n▂▂▁▇▅\nLOCF\n0\n1.00\n0.74\n0.24\n0.29\n0.66\n0.79\n0.91\n0.94\n▂▂▁▅▇\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] naniar_0.6.0.9000    purrr_0.3.4          gtsummary_1.3.6     \n [4] gt_0.2.2             lm.beta_1.5-1        lmtest_0.9-38       \n [7] zoo_1.8-8            ggfortify_0.4.11     sjPlot_2.8.7        \n[10] broom_0.7.4          palmerpenguins_0.1.0 magrittr_2.0.1      \n[13] mnormt_2.0.2         cowplot_1.1.1        tidyr_1.1.2         \n[16] DescTools_0.99.40    skimr_2.1.2          ggpubr_0.4.0        \n[19] car_3.0-10           carData_3.0-4        patchwork_1.1.1     \n[22] dplyr_1.0.4          ggplot2_3.3.3        DiagrammeR_1.0.6.1  \n[25] readxl_1.3.1        \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1     repr_1.1.3          splines_4.0.3      \n  [4] usethis_2.0.1       digest_0.6.27       htmltools_0.5.1.1  \n  [7] magick_2.6.0        fansi_0.4.2         checkmate_2.0.0    \n [10] openxlsx_4.2.3      modelr_0.1.8        colorspace_2.0-0   \n [13] haven_2.3.1         xfun_0.21           crayon_1.4.1       \n [16] jsonlite_1.7.2      Exact_2.1           lme4_1.1-26        \n [19] survival_3.2-7      glue_1.4.2          gtable_0.3.0       \n [22] emmeans_1.5.4       sjstats_0.18.1      sjmisc_2.8.6       \n [25] abind_1.4-5         scales_1.1.1        mvtnorm_1.1-1      \n [28] DBI_1.1.1           rstatix_0.6.0       ggeffects_1.0.1    \n [31] Rcpp_1.0.6          xtable_1.8-4        performance_0.7.0  \n [34] tmvnsim_1.0-2       reticulate_1.18     foreign_0.8-80     \n [37] htmlwidgets_1.5.3   RColorBrewer_1.1-2  ellipsis_0.3.1     \n [40] pkgconfig_2.0.3     farver_2.0.3        sass_0.3.1         \n [43] utf8_1.1.4          tidyselect_1.1.0    labeling_0.4.2     \n [46] rlang_0.4.10        effectsize_0.4.3    munsell_0.5.0      \n [49] cellranger_1.1.0    tools_4.0.3         visNetwork_2.0.9   \n [52] cli_2.3.0           generics_0.1.0      sjlabelled_1.1.7   \n [55] evaluate_0.14       stringr_1.4.0       yaml_2.2.1         \n [58] fs_1.5.0            knitr_1.31          zip_2.1.1          \n [61] visdat_0.5.3        rootSolve_1.8.2.1   nlme_3.1-149       \n [64] xml2_1.3.2          compiler_4.0.3      rstudioapi_0.13    \n [67] curl_4.3            e1071_1.7-4         ggsignif_0.6.0     \n [70] tibble_3.0.6        statmod_1.4.35      broom.helpers_1.1.0\n [73] stringi_1.5.3       highr_0.8           parameters_0.11.0  \n [76] forcats_0.5.1       lattice_0.20-41     Matrix_1.2-18      \n [79] commonmark_1.7      nloptr_1.2.2.2      ggsci_2.9          \n [82] vctrs_0.3.6         norm_1.0-9.5        pillar_1.4.7       \n [85] lifecycle_0.2.0     estimability_1.3    data.table_1.13.6  \n [88] insight_0.12.0      lmom_2.8            R6_2.5.0           \n [91] bookdown_0.21       gridExtra_2.3       rio_0.5.16         \n [94] gld_2.6.2           distill_1.2         boot_1.3-25        \n [97] MASS_7.3-53         assertthat_0.2.1    rprojroot_2.0.2    \n[100] withr_2.4.1         mgcv_1.8-33         bayestestR_0.8.2   \n[103] expm_0.999-6        hms_1.0.0           grid_4.0.3         \n[106] class_7.3-17        minqa_1.2.4         rmarkdown_2.6      \n[109] downlit_0.2.1       lubridate_1.7.9.2   base64enc_0.1-3    \n\n\n\n\nAndri et mult. al., S. (2020). DescTools: Tools for descriptive statistics. Retrieved from https://cran.r-project.org/package=DescTools\n\n\nKang, H. (2013). The prevention and handling of the missing data. Korean Journal of Anesthesiology, 64(5), 402.\n\n\nLittle, R. J. A. (1988). A test of missing completely at random for multivariate data with missing values. Journal of the American Statistical Association, 83(404), 1198–1202. https://doi.org/10.1080/01621459.1988.10478722\n\n\nLittle, R. J., & Rubin, D. B. (2019). Statistical analysis with missing data (Vol. 793). John Wiley & Sons.\n\n\nObadia, Y. (2017). The use of KNN for missing values. Retrieved from https://towardsdatascience.com/the-use-of-knn-for-missing-values-cf33d935c637\n\n\nPantanowitz, A., & Marwala, T. (2009). Missing data imputation through the use of the random forest algorithm. In W. Yu & E. N. Sanchez (Eds.), Advances in computational intelligence (pp. 53–62). Berlin, Heidelberg: Springer Berlin Heidelberg.\n\n\nRubin, D. B. (1976). Inference and missing data. Biometrika, 63(3), 581–592.\n\n\nTierney, N., Cook, D., McBain, M., & Fay, C. (2020). Naniar: Data structures, summaries, and visualisations for missing data. Retrieved from https://CRAN.R-project.org/package=naniar\n\n\nTroyanskaya, O., Cantor, M., Sherlock, G., Brown, P., Hastie, T., Tibshirani, R., … Altman, R. B. (2001). Missing value estimation methods for DNA microarrays. Bioinformatics, 17(6), 520–525.\n\n\nadaptado de Obadia (2017)↩︎\nalgo que não será demonstrado aqui. Recomendamos um livro-texto seminal de R. J. Little & Rubin (2019)↩︎\nnão abordaremos essas técnicas↩︎\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "aux-Likert.html",
      "title": "Likert e Escalas Ordinais",
      "description": "Como trabalhar com escalas Likert e dados ordinais.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nDados Ordinais\nEscala Likert\nComo aplicar uma Regressão Ordinal no R\nPrimeiro Cenário – Regressão Linear\nSegundo Cenário – Regressão Ordinal\n\nCenários mais Complexos\nComentários Finais\n\n\nOs dados ordinais são frequentemente analisados como se fossem métricos. Porém, a análise de dados ordinais como se fossem métricos pode sistematicamente levar a erros como falsos positivos (ou seja, detectando um efeito onde não existe nenhum, erros Tipo I), falsos negativos (ou seja, perda de poder estatístico, erros Tipo II); e até mesmo uma inversão de efeitos (efeitos positivos podem virar efeitos negativos) (Bürkner & Vuorre, 2019; Liddell & Kruschke, 2018).\nPrimeiramente apresentaremos o que são dados ordinais e como eles diferem de dados métricos. Na sequência abordaremos a principal origem de dados ordinais em pesquisas (escala Likert). E por fim, mostraremos uma alternativa à regressão linear que é mais indicada para dados ordinais: regressão ordinal.\nDados Ordinais\nDados ordinais são um tipo de dados categóricos e estatísticos em que as variáveis têm categorias naturais ordenadas e as distâncias entre as categorias não são conhecidas. A principal diferença entre os dados métricos e categóricos é justamente a questão da distância. Em dados métricos a distância entre 1 e 2 é a mesma entre 2 e 3. Porém, em dados categóricos tal distância não é assumida como igual ou conhecida. Portanto a distância entre uma categoria \\(X_1\\) e uma categoria \\(X_2\\) não é a mesma da distância entre a categoria \\(X_2\\) e uma categoria \\(X_3\\).\nPara exemplificar a diferença entre dados métricos e ordinais, veja a figura 1 que mostra dados ordinais em uma representação métrica de uma distribuição normal. É possível ver que cada valor de 1 a 5 (items de uma escala Likert, por exemplo) é mapeado para um ponto específico da distribuição normal. Além disso, a distância entre tais mapeamentos é a mesma, ou seja, as mensurações são equidistantes.\n\n\n\nFigure 1: Modelo Métrico. Figura adaptada de Liddell & Kruschke (2018)\n\n\n\nJá na figura 2 mostramos o modelo latente ordinal. Neste modelo os dados ordinais são representados de maneira discreta (gráfico de barras na parte superior) e não de maneira contínua como o modelo métrico. Além disso, os valores são mapeados para uma variável latente (não-observada) de uma distribuição normal que é contínua (histograma na parte inferior). Vejam que a direção da seta indica a causalidade dos dados. As opções discretas 1, 2, 3, 4 e 5 são originárias em uma variável latente contínua e se manifestam como opções discretas do respondente. Notem que no modelo latente ordinal as distâncias entre os mapeamentos na variável latente não são equidistantes.\n\n\n\nFigure 2: Modelo Latente Ordenado. Figura adaptada de Liddell & Kruschke (2018)\n\n\n\nEscala Likert\nNas ciências sociais temos um predomínio de escalas ordinais como maneiras de mensuração de opinião. Dentre as diversas maneiras de mensurar opiniões, a escala Likert é a escala mais utilizada por pesquisadores e cientistas. A escala Likert foi criada em 1932 por Rensis Likert (figura 3) na sua tese de doutorado como uma forma de identificar a extensão das atitudes e sentimentos de uma pessoa em relação à assuntos internacionais. Após isso, a escala Likert se tornou o principal instrumento quando usamos perguntas para a qual a resposta é indicada em uma escala ordenada discreta que varia de um ponto final qualitativo a outro ponto final qualitativo (por exemplo, discordo totalmente para concordar totalmente).\n\n\n\nFigure 3: Rensis Likert. Figura de https://www.wikipedia.org\n\n\n\nAs escalas Likert normalmente têm de 4 a 7 opções de resposta discretas. Um ponto importante é que escalas Likert ímpares permitem com que o respondente escolha uma opção neutra, em outras palavras, o respondente pode escolher ficar “em cima do muro.” Abaixo um exemplo de uma escala Likert ímpar, de “Discordo Fortemente” até “Concordo Fortemente.” Vejam que há a opção neutra (0) “Não Discordo nem Concordo.”\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#ichzgjisdn .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ichzgjisdn .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ichzgjisdn .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ichzgjisdn .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ichzgjisdn .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ichzgjisdn .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ichzgjisdn .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ichzgjisdn .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ichzgjisdn .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ichzgjisdn .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ichzgjisdn .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ichzgjisdn .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ichzgjisdn .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ichzgjisdn .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ichzgjisdn .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ichzgjisdn .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ichzgjisdn .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#ichzgjisdn .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ichzgjisdn .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#ichzgjisdn .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ichzgjisdn .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ichzgjisdn .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ichzgjisdn .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ichzgjisdn .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ichzgjisdn .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ichzgjisdn .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ichzgjisdn .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ichzgjisdn .gt_left {\n  text-align: left;\n}\n\n#ichzgjisdn .gt_center {\n  text-align: center;\n}\n\n#ichzgjisdn .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ichzgjisdn .gt_font_normal {\n  font-weight: normal;\n}\n\n#ichzgjisdn .gt_font_bold {\n  font-weight: bold;\n}\n\n#ichzgjisdn .gt_font_italic {\n  font-style: italic;\n}\n\n#ichzgjisdn .gt_super {\n  font-size: 65%;\n}\n\n#ichzgjisdn .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nDiscordo Fortemente\n      Discordo\n      Não Discordo nem Concordo\n      Concordo\n      Concordo Fortemente\n    -2\n      -1\n      0\n      1\n      2\n    \n\nJá escalas Likert pares não permitem com que respondente escolha uma opção neutra. Elas forçam o respondente a escolher uma polaridade positiva ou negativa. Abaixo um exemplo de uma escala Likert par, de “Discordo Fortemente” até “Concordo Fortemente.” Vejam que há a opção neutra (0) como na escala ímpar.\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#qkgulojmgi .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#qkgulojmgi .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#qkgulojmgi .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#qkgulojmgi .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#qkgulojmgi .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#qkgulojmgi .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#qkgulojmgi .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#qkgulojmgi .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#qkgulojmgi .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#qkgulojmgi .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#qkgulojmgi .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#qkgulojmgi .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#qkgulojmgi .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#qkgulojmgi .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#qkgulojmgi .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#qkgulojmgi .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#qkgulojmgi .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#qkgulojmgi .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qkgulojmgi .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#qkgulojmgi .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qkgulojmgi .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#qkgulojmgi .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#qkgulojmgi .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#qkgulojmgi .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#qkgulojmgi .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#qkgulojmgi .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#qkgulojmgi .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#qkgulojmgi .gt_left {\n  text-align: left;\n}\n\n#qkgulojmgi .gt_center {\n  text-align: center;\n}\n\n#qkgulojmgi .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#qkgulojmgi .gt_font_normal {\n  font-weight: normal;\n}\n\n#qkgulojmgi .gt_font_bold {\n  font-weight: bold;\n}\n\n#qkgulojmgi .gt_font_italic {\n  font-style: italic;\n}\n\n#qkgulojmgi .gt_super {\n  font-size: 65%;\n}\n\n#qkgulojmgi .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nDiscordo Fortemente\n      Discordo\n      Concordo\n      Concordo Fortemente\n    -2\n      -1\n      1\n      2\n    \n\nComo aplicar uma Regressão Ordinal no R\nPara demonstrar dados ordinais, usaremos a biblioteca {likert} (Bryer & Speerschneider, 2016) que possui o dataset pisaitems que contém resultados do Programme of International Student Assessment (PISA) de 2009 para a América do Norte (Estados Unidos, Canadá e México). Vamos apenas utilizar as 11 questões do grupo de perguntas 24 sobre atitudes de alunos:\nST24Q01 I read only if I have to. – Eu leio apenas se for necessário.\nST24Q02 Reading is one of my favorite hobbies. – Ler é um dos meus passatempos favoritos.\nST24Q03 I like talking about books with other people. – Gosto de conversar sobre livros com outras pessoas.\nST24Q04 I find it hard to finish books. – Acho difícil terminar livros.\nST24Q05 I feel happy if I receive a book as a present. – Fico feliz se recebo um livro de presente.\nST24Q06 For me, reading is a waste of time. – Para mim, ler é perda de tempo.\nST24Q07 I enjoy going to a bookstore or a library. – Gosto de ir a uma livraria ou biblioteca.\nST24Q08 I read only to get information that I need. – Eu leio apenas para obter as informações de que preciso.\nST24Q09 I cannot sit still and read for more than a few minutes. – Não consigo ficar parado e ler por mais de alguns minutos.\nST24Q10 I like to express my opinions about books I have read. – Gosto de expressar minhas opiniões sobre os livros que li.\nST24Q11 I like to exchange books with my friends. – Gosto de trocar livros com meus amigos.\nNós, sempre que carregamos um dataset no R, temos o costume de usar a biblioteca {skimr} (Waring et al., 2020) para produzir um sumário dos dados. Como vocês podem ver a escala usada para as perguntas 24 é uma Likert de 4 items: Strongly disagree, Disagree, Agree, Strongly agree.\n\n\nlibrary(likert)\nlibrary(dplyr)\nlibrary(skimr)\ndata(pisaitems)\npisa <- pisaitems %>%\n  dplyr::select(starts_with(\"ST24\"))\nskim(pisa)\n\n\nTable 1: Data summary\nName\npisa\nNumber of rows\n66690\nNumber of columns\n11\n_______________________\n\nColumn type frequency:\n\nfactor\n11\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nST24Q01\n1199\n0.98\nFALSE\n4\nDis: 23515, Agr: 20000, Str: 14947, Str: 7029\nST24Q02\n1134\n0.98\nFALSE\n4\nDis: 23811, Agr: 20935, Str: 13323, Str: 7487\nST24Q03\n1276\n0.98\nFALSE\n4\nAgr: 23525, Dis: 22072, Str: 13900, Str: 5917\nST24Q04\n1210\n0.98\nFALSE\n4\nDis: 26449, Agr: 17358, Str: 16343, Str: 5330\nST24Q05\n1214\n0.98\nFALSE\n4\nAgr: 26304, Dis: 18106, Str: 12625, Str: 8441\nST24Q06\n1300\n0.98\nFALSE\n4\nStr: 27621, Dis: 26579, Agr: 7177, Str: 4013\nST24Q07\n1319\n0.98\nFALSE\n4\nAgr: 24111, Dis: 21815, Str: 11663, Str: 7782\nST24Q08\n1234\n0.98\nFALSE\n4\nAgr: 23407, Dis: 23183, Str: 9806, Str: 9060\nST24Q09\n1301\n0.98\nFALSE\n4\nDis: 28201, Str: 21655, Agr: 11063, Str: 4470\nST24Q10\n1193\n0.98\nFALSE\n4\nAgr: 28702, Dis: 18037, Str: 9892, Str: 8866\nST24Q11\n1135\n0.98\nFALSE\n4\nDis: 21648, Agr: 21030, Str: 14762, Str: 8115\n\nA biblioteca {likert} ainda tem uma função bem conveniente para plotar gráficos de dados ordinais que usam escala Likert, veja um exemplo na figura 4.\n\n\nplot(likert(pisa))\n\n\n\n\nFigure 4: Dados das 11 questões do PISA do grupo de perguntas 24 sobre atitudes de alunos\n\n\n\nPrimeiro Cenário – Regressão Linear\nAqui vamos aplicar uma regressão linear para a variável ST24Q02 que é a pergunta Reading is one of my favorite hobbies. (Ler é um dos meus passatempos favoritos). Como variável independente vamos usar o país do aluno CNT (Mexico, EUA ou Canadá). Aqui estamos convertendo a variável ordinal ST24Q02 como numérica (contínua).\n\n\nlinear_reg <- pisaitems %>%\n  dplyr::select(CNT, ST24Q02) %>%\n  mutate(ST24Q02 = as.numeric(ST24Q02)) %>%\n  lm(ST24Q02 ~ CNT, data = .)\n\nsummary(linear_reg)\n\n\n\nCall:\nlm(formula = ST24Q02 ~ CNT, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.4357 -0.4356 -0.2465  0.5644  1.8932 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       2.246538   0.006126  366.72   <2e-16 ***\nCNTMexico         0.189115   0.007744   24.42   <2e-16 ***\nCNTUnited States -0.139727   0.014200   -9.84   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.921 on 65553 degrees of freedom\n  (1134 observations deleted due to missingness)\nMultiple R-squared:  0.01458,   Adjusted R-squared:  0.01455 \nF-statistic:   485 on 2 and 65553 DF,  p-value: < 2.2e-16\n\nComo ilustrado no tutorial sobre regressão linear, o resultado pode ser interpretado pela coluna do \\(p\\)-valor (Pr(>|t|)) e pela coluna do coeficiente estimado (Estimate). Vemos que, na amostra de 2009, alunos do México concordam muito mais com a frase que “Ler é um dos meus passatempos favoritos” do que alunos do Canadá (categoria basal de comparação). E alunos dos Estados Unidos discordam muito mais que alunos do Canadá.\nSegundo Cenário – Regressão Ordinal\nPara o segundo cenário vamos usar os mesmos dados do primeiro só que agora estamos usando a função polr() da biblioteca {MASS} (Venables & Ripley, 2002) que aplica uma regressão ordinal. Vejam que aqui não precisamos converter a variável ST24Q02 como numérica, pois polr() aceita (e prefere) uma variável ordinal como variável dependente. Além disso precisamos especificar a função de ligação que irá fazer a inferência da regressão com o argumento method. O padrão é a função logit (\"logistic\") que é o inverso da função logística, mas no nosso caso especificamos a função de ligação probit (\"probit\") que é o inverso da função de distribuição normal acumulada padrão, pois acreditamos que a variável latente por trás da ST24Q02 segue uma distribuição normal. Uma última observação: o argumento Hess é necessário ser TRUE caso queira extrair um sumário da regressão com summary().\n\n\nlibrary(MASS)\nordinal_reg <- pisaitems %>%\n  dplyr::select(CNT, ST24Q02) %>%\n  polr(ST24Q02 ~ CNT, data = ., Hess = TRUE, method = \"probit\")\nsummary(ordinal_reg)\n\n\nCall:\npolr(formula = ST24Q02 ~ CNT, data = ., Hess = TRUE, method = \"probit\")\n\nCoefficients:\n                   Value Std. Error t value\nCNTMexico         0.2184    0.00902  24.218\nCNTUnited States -0.1620    0.01662  -9.743\n\nIntercepts:\n                           Value    Std. Error t value \nStrongly disagree|Disagree  -0.7247   0.0079   -91.5349\nDisagree|Agree               0.2855   0.0077    37.0243\nAgree|Strongly agree         1.3262   0.0088   151.3259\n\nResidual Deviance: 170017.64 \nAIC: 170027.64 \n(1134 observations deleted due to missingness)\n\nComo vocês podem ver o resultado da regressão ordinal é diferente. A regressão ordinal possui (no nosso caso) três constantes (intercepts) mapeando aonde na variável latente o limiar de cada valor ordinal foi mapeado. Além disso, o valor do coeficiente para México e Estados Unidos são maiores em termos absolutos, demonstrando uma melhor sensibilidade (poder estatístico) da regressão ordinal do que a regressão linear em dados ordinais.\nCenários mais Complexos\nCaso o leitor queira experimentar com modelos de regressão ordinais mais complexos sugerimos a biblioteca {ordinal} (Christensen, 2019) que permite modelos ordinais complexos frequentistas e a biblioteca {brms} (Bürkner, 2018) que permite modelos ordinais complexos Bayesianos. Ambas bibliotecas possuem diversas funções de ligação e também é possível especificar modelos multiníveis (também chamados de modelos hierárquicos, modelos mistos, modelos de dois estágios etc.)\n\nO primeiro autor possui um tutorial de Estatística Bayesiana com R.\nComentários Finais\nDados ordinais, especialmente mensurados por escala Likert, aparecem com muita frequência em pesquisas. Tratar dados ordinais como se fossem métricos (contínuos) não é apropriado e portanto regressão linear não é a técnica correta quando a variável dependente é ordinal. Para isso recomendamos a regressão ordinal.\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] MASS_7.3-53          likert_1.3.5         xtable_1.8-4        \n [4] naniar_0.6.0.9000    purrr_0.3.4          gtsummary_1.3.6     \n [7] gt_0.2.2             lm.beta_1.5-1        lmtest_0.9-38       \n[10] zoo_1.8-8            ggfortify_0.4.11     sjPlot_2.8.7        \n[13] broom_0.7.4          palmerpenguins_0.1.0 magrittr_2.0.1      \n[16] mnormt_2.0.2         cowplot_1.1.1        tidyr_1.1.2         \n[19] DescTools_0.99.40    skimr_2.1.2          ggpubr_0.4.0        \n[22] car_3.0-10           carData_3.0-4        patchwork_1.1.1     \n[25] dplyr_1.0.4          ggplot2_3.3.3        DiagrammeR_1.0.6.1  \n[28] readxl_1.3.1        \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1     plyr_1.8.6          repr_1.1.3         \n  [4] splines_4.0.3       usethis_2.0.1       digest_0.6.27      \n  [7] htmltools_0.5.1.1   magick_2.6.0        fansi_0.4.2        \n [10] checkmate_2.0.0     openxlsx_4.2.3      modelr_0.1.8       \n [13] colorspace_2.0-0    haven_2.3.1         xfun_0.21          \n [16] crayon_1.4.1        jsonlite_1.7.2      Exact_2.1          \n [19] lme4_1.1-26         survival_3.2-7      glue_1.4.2         \n [22] gtable_0.3.0        emmeans_1.5.4       sjstats_0.18.1     \n [25] sjmisc_2.8.6        abind_1.4-5         scales_1.1.1       \n [28] mvtnorm_1.1-1       DBI_1.1.1           rstatix_0.6.0      \n [31] ggeffects_1.0.1     Rcpp_1.0.6          performance_0.7.0  \n [34] tmvnsim_1.0-2       reticulate_1.18     foreign_0.8-80     \n [37] htmlwidgets_1.5.3   RColorBrewer_1.1-2  ellipsis_0.3.1     \n [40] pkgconfig_2.0.3     farver_2.0.3        sass_0.3.1         \n [43] utf8_1.1.4          reshape2_1.4.4      tidyselect_1.1.0   \n [46] labeling_0.4.2      rlang_0.4.10        effectsize_0.4.3   \n [49] munsell_0.5.0       cellranger_1.1.0    tools_4.0.3        \n [52] visNetwork_2.0.9    cli_2.3.0           generics_0.1.0     \n [55] sjlabelled_1.1.7    evaluate_0.14       stringr_1.4.0      \n [58] yaml_2.2.1          fs_1.5.0            knitr_1.31         \n [61] zip_2.1.1           visdat_0.5.3        rootSolve_1.8.2.1  \n [64] nlme_3.1-149        xml2_1.3.2          compiler_4.0.3     \n [67] rstudioapi_0.13     curl_4.3            e1071_1.7-4        \n [70] ggsignif_0.6.0      tibble_3.0.6        statmod_1.4.35     \n [73] broom.helpers_1.1.0 stringi_1.5.3       highr_0.8          \n [76] parameters_0.11.0   forcats_0.5.1       lattice_0.20-41    \n [79] Matrix_1.2-18       psych_2.0.12        commonmark_1.7     \n [82] nloptr_1.2.2.2      ggsci_2.9           vctrs_0.3.6        \n [85] norm_1.0-9.5        pillar_1.4.7        lifecycle_0.2.0    \n [88] estimability_1.3    data.table_1.13.6   insight_0.12.0     \n [91] lmom_2.8            R6_2.5.0            bookdown_0.21      \n [94] gridExtra_2.3       rio_0.5.16          gld_2.6.2          \n [97] distill_1.2         boot_1.3-25         assertthat_0.2.1   \n[100] rprojroot_2.0.2     withr_2.4.1         parallel_4.0.3     \n[103] mgcv_1.8-33         bayestestR_0.8.2    expm_0.999-6       \n[106] hms_1.0.0           grid_4.0.3          class_7.3-17       \n[109] minqa_1.2.4         rmarkdown_2.6       downlit_0.2.1      \n[112] lubridate_1.7.9.2   base64enc_0.1-3    \n\n\n\n\nBryer, J., & Speerschneider, K. (2016). Likert: Analysis and visualization likert items. Retrieved from https://CRAN.R-project.org/package=likert\n\n\nBürkner, P.-C. (2018). Advanced Bayesian multilevel modeling with the R package brms. The R Journal, 10(1), 395–411. https://doi.org/10.32614/RJ-2018-017\n\n\nBürkner, P.-C., & Vuorre, M. (2019). Ordinal Regression Models in Psychology: A Tutorial. Advances in Methods and Practices in Psychological Science, 2(1), 77–101. https://doi.org/10.1177/2515245918823199\n\n\nChristensen, R. H. B. (2019). Ordinal—regression models for ordinal data.\n\n\nLiddell, T. M., & Kruschke, J. K. (2018). Analyzing ordinal data with metric models: What could possibly go wrong? Journal of Experimental Social Psychology, 79, 328–348. https://doi.org/10.1016/j.jesp.2018.08.009\n\n\nVenables, W. N., & Ripley, B. D. (2002). Modern applied statistics with s (Fourth). Retrieved from http://www.stats.ox.ac.uk/pub/MASS4/\n\n\nWaring, E., Quinn, M., McNamara, A., Arino de la Rubia, E., Zhu, H., & Ellis, S. (2020). Skimr: Compact and flexible summaries of data. Retrieved from https://CRAN.R-project.org/package=skimr\n\n\n\n\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "aux-Tabelas_para_Publicacao.html",
      "title": "Tabelas para Publicação",
      "description": "Como montar tabelas de modelos de regressão prontas para publicação.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nEstatísticas Descritivas\nTabela de Regressão Linear/Logística\n\nAmbiente\n\n\no invés de ser obrigado a passar horas a fio formatando tabelas em Excel softwares pagos, você pode usar a biblioteca {gtsummary} (Sjoberg, Curry, Hannum, Whiting, & Zabor, 2020) para formatar automaticamente suas tabelas:\nEstatísticas Descritivas: gtsummary::tbl_summary()\nRegressões: gtsummary::tbl_regression()\nO idioma das tabelas de {gtsummary} pode ser definido com a função theme_gtsummary_language()\nEstatísticas Descritivas\nO pacote gtsummary possui um conjunto de funções para sumarizar dados e tabelas. Nós particularmente usamos a função gtsummary::tbl_summary(). Ela formata uma tabela de Estatística Descritiva de maneira bem conveniente.\n\n\ntheme_gtsummary_language(\"pt\")\n\ngtsummary::tbl_summary(\n  mtcars,\n  by = am,\n  type = all_continuous() ~ \"continuous2\",\n  statistic = list(\n    all_continuous() ~ c(\"{N_nonmiss}\",\n                         \"{median} ({p25}, {p75})\",\n                         \"{min}, {max}\"),\n    all_categorical() ~ \"{n} ({p}%)\"),\n  missing = \"no\",\n  digits = all_continuous() ~ 2) %>%\n  add_overall() %>%\n  bold_labels() %>%\n  italicize_levels() %>%\n  modify_header(list(label ~ \"**Variáveis**\",\n                     stat_1 ~ \"**Automático**, N = 18\",\n                     stat_2 ~ \"**Manual**, N = 14\")) %>%\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Automáticos vs Manuais**\") %>%\n  add_n()\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#ijwugufybe .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ijwugufybe .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ijwugufybe .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ijwugufybe .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ijwugufybe .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ijwugufybe .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ijwugufybe .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ijwugufybe .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ijwugufybe .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ijwugufybe .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ijwugufybe .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ijwugufybe .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ijwugufybe .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ijwugufybe .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ijwugufybe .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ijwugufybe .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ijwugufybe .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#ijwugufybe .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ijwugufybe .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#ijwugufybe .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ijwugufybe .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ijwugufybe .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ijwugufybe .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ijwugufybe .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ijwugufybe .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ijwugufybe .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ijwugufybe .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ijwugufybe .gt_left {\n  text-align: left;\n}\n\n#ijwugufybe .gt_center {\n  text-align: center;\n}\n\n#ijwugufybe .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ijwugufybe .gt_font_normal {\n  font-weight: normal;\n}\n\n#ijwugufybe .gt_font_bold {\n  font-weight: bold;\n}\n\n#ijwugufybe .gt_font_italic {\n  font-style: italic;\n}\n\n#ijwugufybe .gt_super {\n  font-size: 65%;\n}\n\n#ijwugufybe .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nVariáveis\n      N\n      Total, N = 32\n      \n        Automáticos vs Manuais\n      \n    Automático, N = 18\n      Manual, N = 14\n    mpg\n      32.00\n      \n      \n      \n    N\n      \n      32.00\n      19.00\n      13.00\n    Mediana (IQR)\n      \n      19.20 (15.43, 22.80)\n      17.30 (14.95, 19.20)\n      22.80 (21.00, 30.40)\n    Intervalo\n      \n      10.40, 33.90\n      10.40, 24.40\n      15.00, 33.90\n    cyl\n      32\n      \n      \n      \n    4\n      \n      11 (34%)\n      3 (16%)\n      8 (62%)\n    6\n      \n      7 (22%)\n      4 (21%)\n      3 (23%)\n    8\n      \n      14 (44%)\n      12 (63%)\n      2 (15%)\n    disp\n      32.00\n      \n      \n      \n    N\n      \n      32.00\n      19.00\n      13.00\n    Mediana (IQR)\n      \n      196.30 (120.83, 326.00)\n      275.80 (196.30, 360.00)\n      120.30 (79.00, 160.00)\n    Intervalo\n      \n      71.10, 472.00\n      120.10, 472.00\n      71.10, 351.00\n    hp\n      32.00\n      \n      \n      \n    N\n      \n      32.00\n      19.00\n      13.00\n    Mediana (IQR)\n      \n      123.00 (96.50, 180.00)\n      175.00 (116.50, 192.50)\n      109.00 (66.00, 113.00)\n    Intervalo\n      \n      52.00, 335.00\n      62.00, 245.00\n      52.00, 335.00\n    drat\n      32.00\n      \n      \n      \n    N\n      \n      32.00\n      19.00\n      13.00\n    Mediana (IQR)\n      \n      3.70 (3.08, 3.92)\n      3.15 (3.07, 3.70)\n      4.08 (3.85, 4.22)\n    Intervalo\n      \n      2.76, 4.93\n      2.76, 3.92\n      3.54, 4.93\n    wt\n      32.00\n      \n      \n      \n    N\n      \n      32.00\n      19.00\n      13.00\n    Mediana (IQR)\n      \n      3.33 (2.58, 3.61)\n      3.52 (3.44, 3.84)\n      2.32 (1.94, 2.78)\n    Intervalo\n      \n      1.51, 5.42\n      2.46, 5.42\n      1.51, 3.57\n    qsec\n      32.00\n      \n      \n      \n    N\n      \n      32.00\n      19.00\n      13.00\n    Mediana (IQR)\n      \n      17.71 (16.89, 18.90)\n      17.82 (17.18, 19.17)\n      17.02 (16.46, 18.61)\n    Intervalo\n      \n      14.50, 22.90\n      15.41, 22.90\n      14.50, 19.90\n    vs\n      32\n      14 (44%)\n      7 (37%)\n      7 (54%)\n    gear\n      32\n      \n      \n      \n    3\n      \n      15 (47%)\n      15 (79%)\n      0 (0%)\n    4\n      \n      12 (38%)\n      4 (21%)\n      8 (62%)\n    5\n      \n      5 (16%)\n      0 (0%)\n      5 (38%)\n    carb\n      32\n      \n      \n      \n    1\n      \n      7 (22%)\n      3 (16%)\n      4 (31%)\n    2\n      \n      10 (31%)\n      6 (32%)\n      4 (31%)\n    3\n      \n      3 (9.4%)\n      3 (16%)\n      0 (0%)\n    4\n      \n      10 (31%)\n      7 (37%)\n      3 (23%)\n    6\n      \n      1 (3.1%)\n      0 (0%)\n      1 (7.7%)\n    8\n      \n      1 (3.1%)\n      0 (0%)\n      1 (7.7%)\n    \n\nTabela de Regressão Linear/Logística\nA função gtsummary::tbl_regression() pode ser usada para modelos de regressão tanto linear quanto logística. Caso deseje incluir coeficientes padronizados em desvio padrões indique o argumento tidy_fun = tidy_standardize.\n\n\nlibrary(gtsummary)\nmodelo_linear <- lm(mpg ~ hp + wt, data = mtcars)\n\ntbl_regression(\n  modelo_linear,\n  tidy_fun = tidy_standardize) %>%\n  bold_labels() %>%\n  add_glance_source_note(c(r.squared, adj.r.squared)) %>%\n  modify_header(list(estimate ~ \"**Beta Padronizados**\"))\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#hlmrayyfuo .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#hlmrayyfuo .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#hlmrayyfuo .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#hlmrayyfuo .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#hlmrayyfuo .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hlmrayyfuo .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#hlmrayyfuo .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#hlmrayyfuo .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#hlmrayyfuo .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#hlmrayyfuo .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#hlmrayyfuo .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#hlmrayyfuo .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#hlmrayyfuo .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#hlmrayyfuo .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#hlmrayyfuo .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#hlmrayyfuo .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#hlmrayyfuo .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#hlmrayyfuo .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hlmrayyfuo .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#hlmrayyfuo .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hlmrayyfuo .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#hlmrayyfuo .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#hlmrayyfuo .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hlmrayyfuo .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#hlmrayyfuo .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#hlmrayyfuo .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#hlmrayyfuo .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#hlmrayyfuo .gt_left {\n  text-align: left;\n}\n\n#hlmrayyfuo .gt_center {\n  text-align: center;\n}\n\n#hlmrayyfuo .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#hlmrayyfuo .gt_font_normal {\n  font-weight: normal;\n}\n\n#hlmrayyfuo .gt_font_bold {\n  font-weight: bold;\n}\n\n#hlmrayyfuo .gt_font_italic {\n  font-style: italic;\n}\n\n#hlmrayyfuo .gt_super {\n  font-size: 65%;\n}\n\n#hlmrayyfuo .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nCaracterísticas\n      Beta Padronizados\n      95% CI1\n    hp\n      -0.36\n      -0.57, -0.15\n    wt\n      -0.63\n      -0.84, -0.42\n    R² = 0.827; Adjusted R² = 0.815\n    \n        \n          1\n          \n           \n          CI = Intervalo de confiança\n          \n      \n    \n\nNo caso de regressão logísticos os coeficientes são mostrados em formato bruto: logaritmo natural de razões de probabilidades (odds ratio – OR). Caso deseje exibir os coeficientes em razões de probabilidade (OR) para uma melhor interpretação, indique o argumento exponentiate = TRUE.\n\n\ndata(\"TitanicSurvival\", package = \"carData\")\nmodelo_logistico <- glm(survived ~ age + sex,\n                        data = TitanicSurvival, family = binomial)\n\ntbl_regression(\n  modelo_logistico,\n  exponentiate = TRUE) %>%\n  bold_labels() %>%\n  bold_p()\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#iozptfkhvv .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#iozptfkhvv .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#iozptfkhvv .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#iozptfkhvv .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#iozptfkhvv .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#iozptfkhvv .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#iozptfkhvv .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#iozptfkhvv .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#iozptfkhvv .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#iozptfkhvv .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#iozptfkhvv .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#iozptfkhvv .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#iozptfkhvv .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#iozptfkhvv .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#iozptfkhvv .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#iozptfkhvv .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#iozptfkhvv .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#iozptfkhvv .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#iozptfkhvv .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#iozptfkhvv .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#iozptfkhvv .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#iozptfkhvv .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#iozptfkhvv .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#iozptfkhvv .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#iozptfkhvv .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#iozptfkhvv .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#iozptfkhvv .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#iozptfkhvv .gt_left {\n  text-align: left;\n}\n\n#iozptfkhvv .gt_center {\n  text-align: center;\n}\n\n#iozptfkhvv .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#iozptfkhvv .gt_font_normal {\n  font-weight: normal;\n}\n\n#iozptfkhvv .gt_font_bold {\n  font-weight: bold;\n}\n\n#iozptfkhvv .gt_font_italic {\n  font-style: italic;\n}\n\n#iozptfkhvv .gt_super {\n  font-size: 65%;\n}\n\n#iozptfkhvv .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nCaracterísticas\n      OR1\n      95% CI1\n      p-value\n    age\n      1.00\n      0.99, 1.01\n      0.4\n    sex\n      \n      \n      \n    female\n      —\n      —\n      \n    male\n      0.09\n      0.06, 0.11\n      <0.001\n    \n        \n          1\n          \n           \n          OR = Razão de chances, CI = Intervalo de confiança\n          \n      \n    \n\nAlém disso conseguimos facilmente comparar diferentes modelos de regressão em uma mesma tabela com a função gtsummary::tbl_merge()\n\n\nmodelo_simples <- glm(survived ~ age + sex,\n                      data = TitanicSurvival, family = binomial)\nmodelo_quali <- glm(survived ~ age + sex + passengerClass,\n                    data = TitanicSurvival, family = binomial)\nmodelo_interacao <- glm(survived ~ age + sex * passengerClass,\n                        data = TitanicSurvival, family = binomial)\n\ntabelas_modelos <- list(modelo_simples, modelo_quali, modelo_interacao) %>%\n  purrr::map(~ tbl_regression(\n  .,\n  exponentiate = TRUE) %>%\n  bold_labels() %>%\n  bold_p())\n\n\ntbl_merge(\n  tabelas_modelos,\n  tab_spanner = c(\"**Modelo Simples**\",\n                  \"**Modelo Qualitativo**\",\n                  \"**Modelo Interação**\")\n)\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#gpqvrqbdme .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#gpqvrqbdme .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#gpqvrqbdme .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#gpqvrqbdme .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#gpqvrqbdme .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#gpqvrqbdme .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#gpqvrqbdme .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#gpqvrqbdme .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#gpqvrqbdme .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#gpqvrqbdme .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#gpqvrqbdme .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#gpqvrqbdme .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#gpqvrqbdme .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#gpqvrqbdme .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#gpqvrqbdme .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#gpqvrqbdme .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#gpqvrqbdme .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#gpqvrqbdme .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#gpqvrqbdme .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#gpqvrqbdme .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#gpqvrqbdme .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#gpqvrqbdme .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#gpqvrqbdme .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#gpqvrqbdme .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#gpqvrqbdme .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#gpqvrqbdme .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#gpqvrqbdme .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#gpqvrqbdme .gt_left {\n  text-align: left;\n}\n\n#gpqvrqbdme .gt_center {\n  text-align: center;\n}\n\n#gpqvrqbdme .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#gpqvrqbdme .gt_font_normal {\n  font-weight: normal;\n}\n\n#gpqvrqbdme .gt_font_bold {\n  font-weight: bold;\n}\n\n#gpqvrqbdme .gt_font_italic {\n  font-style: italic;\n}\n\n#gpqvrqbdme .gt_super {\n  font-size: 65%;\n}\n\n#gpqvrqbdme .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nCaracterísticas\n      \n        Modelo Simples\n      \n      \n        Modelo Qualitativo\n      \n      \n        Modelo Interação\n      \n    OR1\n      95% CI1\n      p-value\n      OR1\n      95% CI1\n      p-value\n      OR1\n      95% CI1\n      p-value\n    age\n      1.00\n      0.99, 1.01\n      0.4\n      0.97\n      0.95, 0.98\n      <0.001\n      0.96\n      0.95, 0.97\n      <0.001\n    sex\n      \n      \n      \n      \n      \n      \n      \n      \n      \n    female\n      —\n      —\n      \n      —\n      —\n      \n      —\n      —\n      \n    male\n      0.09\n      0.06, 0.11\n      <0.001\n      0.08\n      0.06, 0.11\n      <0.001\n      0.02\n      0.01, 0.05\n      <0.001\n    passengerClass\n      \n      \n      \n      \n      \n      \n      \n      \n      \n    1st\n      \n      \n      \n      —\n      —\n      \n      —\n      —\n      \n    2nd\n      \n      \n      \n      0.28\n      0.18, 0.43\n      <0.001\n      0.22\n      0.07, 0.63\n      0.007\n    3rd\n      \n      \n      \n      0.10\n      0.06, 0.16\n      <0.001\n      0.02\n      0.01, 0.04\n      <0.001\n    sex * passengerClass\n      \n      \n      \n      \n      \n      \n      \n      \n      \n    male * 2nd\n      \n      \n      \n      \n      \n      \n      0.93\n      0.28, 3.44\n      >0.9\n    male * 3rd\n      \n      \n      \n      \n      \n      \n      12.0\n      4.50, 38.7\n      <0.001\n    \n        \n          1\n          \n           \n          OR = Razão de chances, CI = Intervalo de confiança\n          \n      \n    \n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] MASS_7.3-53          likert_1.3.5         xtable_1.8-4        \n [4] naniar_0.6.0.9000    purrr_0.3.4          gtsummary_1.3.6     \n [7] gt_0.2.2             lm.beta_1.5-1        lmtest_0.9-38       \n[10] zoo_1.8-8            ggfortify_0.4.11     sjPlot_2.8.7        \n[13] broom_0.7.4          palmerpenguins_0.1.0 magrittr_2.0.1      \n[16] mnormt_2.0.2         cowplot_1.1.1        tidyr_1.1.2         \n[19] DescTools_0.99.40    skimr_2.1.2          ggpubr_0.4.0        \n[22] car_3.0-10           carData_3.0-4        patchwork_1.1.1     \n[25] dplyr_1.0.4          ggplot2_3.3.3        DiagrammeR_1.0.6.1  \n[28] readxl_1.3.1        \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1     plyr_1.8.6          repr_1.1.3         \n  [4] splines_4.0.3       usethis_2.0.1       digest_0.6.27      \n  [7] htmltools_0.5.1.1   magick_2.6.0        fansi_0.4.2        \n [10] checkmate_2.0.0     openxlsx_4.2.3      modelr_0.1.8       \n [13] colorspace_2.0-0    haven_2.3.1         xfun_0.21          \n [16] crayon_1.4.1        jsonlite_1.7.2      Exact_2.1          \n [19] lme4_1.1-26         survival_3.2-7      glue_1.4.2         \n [22] gtable_0.3.0        emmeans_1.5.4       sjstats_0.18.1     \n [25] sjmisc_2.8.6        abind_1.4-5         scales_1.1.1       \n [28] mvtnorm_1.1-1       DBI_1.1.1           rstatix_0.6.0      \n [31] ggeffects_1.0.1     Rcpp_1.0.6          performance_0.7.0  \n [34] tmvnsim_1.0-2       reticulate_1.18     foreign_0.8-80     \n [37] htmlwidgets_1.5.3   RColorBrewer_1.1-2  ellipsis_0.3.1     \n [40] pkgconfig_2.0.3     farver_2.0.3        sass_0.3.1         \n [43] utf8_1.1.4          reshape2_1.4.4      tidyselect_1.1.0   \n [46] labeling_0.4.2      rlang_0.4.10        effectsize_0.4.3   \n [49] munsell_0.5.0       cellranger_1.1.0    tools_4.0.3        \n [52] visNetwork_2.0.9    cli_2.3.0           generics_0.1.0     \n [55] sjlabelled_1.1.7    evaluate_0.14       stringr_1.4.0      \n [58] yaml_2.2.1          fs_1.5.0            knitr_1.31         \n [61] zip_2.1.1           visdat_0.5.3        rootSolve_1.8.2.1  \n [64] nlme_3.1-149        xml2_1.3.2          compiler_4.0.3     \n [67] rstudioapi_0.13     curl_4.3            e1071_1.7-4        \n [70] ggsignif_0.6.0      tibble_3.0.6        statmod_1.4.35     \n [73] broom.helpers_1.1.0 stringi_1.5.3       highr_0.8          \n [76] parameters_0.11.0   forcats_0.5.1       lattice_0.20-41    \n [79] Matrix_1.2-18       psych_2.0.12        commonmark_1.7     \n [82] nloptr_1.2.2.2      ggsci_2.9           vctrs_0.3.6        \n [85] norm_1.0-9.5        pillar_1.4.7        lifecycle_0.2.0    \n [88] estimability_1.3    data.table_1.13.6   insight_0.12.0     \n [91] lmom_2.8            R6_2.5.0            bookdown_0.21      \n [94] gridExtra_2.3       rio_0.5.16          gld_2.6.2          \n [97] distill_1.2         boot_1.3-25         assertthat_0.2.1   \n[100] rprojroot_2.0.2     withr_2.4.1         parallel_4.0.3     \n[103] mgcv_1.8-33         bayestestR_0.8.2    expm_0.999-6       \n[106] hms_1.0.0           labelled_2.7.0      grid_4.0.3         \n[109] class_7.3-17        minqa_1.2.4         rmarkdown_2.6      \n[112] downlit_0.2.1       lubridate_1.7.9.2   base64enc_0.1-3    \n\n\n\n\nSjoberg, D. D., Curry, M., Hannum, M., Whiting, K., & Zabor, E. C. (2020). Gtsummary: Presentation-ready data summary and analytic result tables. Retrieved from https://CRAN.R-project.org/package=gtsummary\n\n\n\n\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "aux-Tamanho_Amostra.html",
      "title": "Tamanho de Amostra e Tamanho de Efeito",
      "description": "Como definir o tamanho de amostra para o tamanho de efeito que deseja encontrar em sua pesquisa.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nTamanho de Efeito\nEfeitos pequenos, médios e grandes\n\nTamanho de Amostra\nCalculando Tamanho de Amostra no R\nExemplo 1 - Teste \\(t\\)\nExemplo 2 - Regressão Linear\n\nAmbiente\n\n\nEste tutorial apresenta os diferentes tipos de efeitos e seus tamanhos. Munido do tamanho do efeito, pesquisadores podem calcular o tamanho mínimo da amostra para que um teste estatístico possa detectar um efeito do tamanho desejado.\nTamanho de Efeito\nTamanho de efeito é definido como “um número que mede a força da relação entre duas variáveis em uma população estatística ou uma estimativa baseada em amostra dessa quantidade. Pode referir-se ao valor de uma estatística calculada a partir de uma amostra, ao valor de um parâmetro de uma população estatística hipotética ou à equação que operacionaliza como as estatísticas ou parâmetros levam ao valor do tamanho do efeito” (Kelley & Preacher, 2012). Exemplos de tamanho de efeito incluem a correlação entre duas variáveis, o coeficiente de uma variável em uma regressão e a diferença média entre grupos distintos.\nOs tamanhos de efeito complementam o teste de hipótese estatística e desempenham um papel importante nas análises de poder de um teste estatístico e planejamento do tamanho da amostra.\nOs tamanhos de efeito podem ser medidos em termos relativos ou absolutos. Em tamanhos de efeito relativos, dois grupos são comparados diretamente um com o outro, como em razão de probabilidades (odds ratio – OR) e riscos relativos. Para tamanhos de efeito absolutos, um valor absoluto maior sempre indica um efeito mais forte. Muitos tipos de medidas podem ser expressos como absolutos ou relativos e podem ser usados em conjunto porque transmitem informações diferentes. Se atentem ao contexto e quando usar medidas absolutas versus relativas1.\nEfeitos pequenos, médios e grandes\nA principal referência em tamanhos de efeito é Cohen (1988) que distingue tamanhos de efeito em pequeno, médio e grande; mas note que é necessário cautela: “Os termos ‘pequeno,’ ‘médio’ e ‘grande’ são relativos, não apenas uns aos outros, mas à área da ciência do qual pertencem ou, ainda mais particularmente, ao conteúdo específico e ao método de pesquisa empregado em qualquer investigação…” (Cohen, 1988).\nOs tamanho de efeito para as diferentes métricas estatística dos testes de hipótese são definidos em Cohen (1988), mas mesmo assim eles podem variar conforme área da ciência e contexto, portanto o pesquisador deve sempre justificar (preferencialmente com argumentos baseado em evidências) caso escolha usar as métricas padrões ou caso precise alterá-las.\nNeste tutorial cobriremos três principais tipos de efeito: \\(d\\) de Cohen, \\(r\\) de Pearson e \\(f^2\\) de Cohen. Esses tipos de efeitos são os usados em testes \\(t\\), ANOVA, correlação e regressão linear.\n\\(d\\) de Cohen\nO \\(d\\)2 de Cohen (Cohen, 1988) é a diferença entre a média de dois grupos padronizada por desvios padrões:\n\\[d = \\frac{\\mu_1 - \\mu_2}{\\sigma}\\]\nonde \\(\\mu_1\\) é a média de um grupo, \\(\\mu_2\\) média do outro grupo e \\(\\sigma\\) o desvio padrão com base em ambos os grupos.\n\\(d\\) de Cohen é usado em testes de diferença de média como o teste \\(t\\) e teste de Tukey. Os tamanhos de efeito para \\(d\\) de Cohen (Cohen, 1988) são:\nPequeno: \\(d = 0.2\\)\nMédio: \\(d = 0.5\\)\nGrande: \\(d = 0.8\\)\nVeja na figura 1 uma demonstração dos tamanhos de efeito de \\(d\\) de Cohen. Note que as medidas comparadas entre os grupos segue uma distribuição Normal (assim como o teste \\(t\\) de Student – paramétrico).\n\n\n\nFigure 1: \\(d\\) de Cohen\n\n\n\n\\(r\\) de Pearson\nJá cruzamos com o \\(r\\) de Pearson(Pearson, 1895) no tutorial de correlação. Os tamanhos de efeito para \\(r\\) de Pearson são (Cohen, 1988):\nPequeno: \\(r = 0.1\\)\nMédio: \\(r = 0.3\\)\nGrande: \\(r = 0.5\\)\nVeja na figura 2 uma demonstração dos tamanhos de efeito de \\(r\\) de Pearson.\n\n\n\nFigure 2: \\(r\\) de Pearson\n\n\n\n\\(f^2\\) de Cohen\nO \\(f^2\\) de Cohen é usado em contextos de testes estatísticos que usam a distribuição \\(F\\) de Fisher. Em ANOVAs e regressão linear, o \\(f^2\\) é a proporção da variabilidade na variável dependente prevista pelas variável independentes e indica o poder preditivo de um modelo estatístico. Em especial, para regressões lineares, o \\(f^2\\) pode ser usado como indicador de poder preditivo de um modelo completo \\(R^2\\) ou como indicador de poder preditivo (e poder de influência) de uma variável independente sobre uma dependente (aqui o \\(f^2\\) equivale ao coeficiente padronizado em desvios padrões).\nOs tamanhos de efeito para \\(f^2\\) de Cohen (Cohen, 1988) são:\nANOVA:\nPequeno: \\(f^2 = 0.1\\)\nMédio: \\(f^2 = 0.25\\)\nGrande: \\(f^2 = 0.4\\)\n\nRegressão Linear:\nPequeno: \\(f^2 = 0.02\\)\nMédio: \\(f^2 = 0.15\\)\nGrande: \\(f^2 = 0.35\\)\n\nTamanho de Amostra\nO tamanho de amostra é influenciado diretamente pelo erro tipo I e erro tipo II. No tutorial de \\(p\\)-valores definimos dois tipos erros:\nErro tipo I, também chamado de “falso positivo”, é a chance de rejeitarmos a hipótese nula quando ela é verdadeira. Esse erro é o alpha \\(\\alpha\\) que é usado como limiar de significância do \\(p\\)-valor.\nErro tipo II, também chamado de “falso negativo”, é a chance de não rejeitarmos a hipótese nula quando ela é falsa. Esse erro é identificado como a letra grega beta \\(\\beta\\). Além disso, o poder de um teste estatístico é mensurado como \\(1 - \\beta\\). O poder de um teste estatístico aumenta proporcionalmente ao tamanho amostral. Quanto maior a amostra, maior o poder do teste.\n\nEsses conceitos foram criados por matemáticos, então a nomenclatura erro tipo I e erro tipo II é perfeita matematicamente, pois no contexto de testes estatísticos contra uma hipótese nula só existem dois tipos de erros. Mas para o ensino da Estatística e comunicação de incertezas é péssima. Sempre que possível optamos por usar termos como “falso positivo” e “falso negativo” ao invés de erro tipo I e erro tipo II.\n\n\n\nEsses dois tipos de erros foram cunhados por Jerzy Neyman, fundador do paradigma NHST3, que defendia a ideia de que é melhor absolver um culpado (erro tipo II – falso negativo) do que culpar um inocente (erro tipo I – falso positivo):\n\n“É mais sério condenar um homem inocente ou absolver um culpado? Isso dependerá das consequências do erro. A punição é morte ou multa? Qual é o risco de criminosos libertados para a sociedade ? Quais são os pontos de vista éticos atuais sobre punição? Do ponto de vista da teoria matemática, tudo o que podemos fazer é mostrar como o risco de erros pode ser controlado e minimizado. O uso dessas ferramentas estatísticas em qualquer caso específico para determinar como o equilíbrio deve ser alcançado , deve ser deixado para o investigador.”4 (Neyman & Pearson, 1933)\n\nPortanto, caro leitor, é você! Você deve pensar cuidadosamente em como o equilíbrio dessas taxas de erro deve ser atingido. Você não deve confiar em nenhum padrão porque cada situação exige que você considere quais seriam as taxas de erro ideais.\nCom isso esclarecido, desmonstraremos como calcular o tamanho de amostra no R.\nCalculando Tamanho de Amostra no R\nPara calcular um tamanho de amostra no R usaremos a biblioteca {pwr} (Champely, 2020). As funções disponíveis são:\npwr.t.test() – Teste \\(t\\) para Amostras Independentes e para duas Amostras Pareadas\npwr.r.test – Correlação usando o \\(r\\) de Pearson\npwr.anova.test – ANOVA Unidirecional\npwr.f2.test – Regressão Linear\nA lógica do {pwr} é a seguinte. Cada uma dessas função possui argumentos para:\nTamanho de Efeito – d, r ou f2\nTamanho de Amostra – n\nProbabilidade do erro tipo I – falso positivo – \\(\\alpha\\) – sig.level padrão 0.05\nPoder Estatístico – 1 menos a probabilidade do erro tipo II – falso negativo – \\(1 - \\beta\\) – power\nComo esses quatro conceitos são interdependentes (para o cálculo de um é necessário saber o valor dos outros três), você deve especificar três dessas quatro métricas para obter o resultado da métrica desejada.\nExemplo 1 - Teste \\(t\\)\nCaso queira calcular o tamanho de amostra necessário para um teste \\(t\\) detectar um efeito médio, \\(d = 0.5\\), com taxa de falso positivo (\\(\\alpha\\)) de 5%, e poder estatístico (\\(1 - \\beta\\)) de 80%:\n\n\nlibrary(pwr)\n\npwr.t.test(d = 0.5, sig.level = 0.05, power = 0.8)\n\n\n\n     Two-sample t test power calculation \n\n              n = 63.76561\n              d = 0.5\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\nSão necessário dois grupos com 64 observações em cada grupo. Um total de amostra de 128 observações.\nExemplo 2 - Regressão Linear\nVamos para um segundo exemplo com regressão linear. Aqui o uso da função pwr.f2.test() é um pouco mais complicado porque, além do tamanho de efeito f2, sig.level, n e power, temos que especificar os graus de liberdade do numerador u e graus de liberdade do denominador v.\nOs graus de liberdade do numerador, u, é o número de coeficientes que você terá em seu modelo (menos a constante): \\(u = \\text{coeficientes} - 1\\). Os graus de liberdade do denominador, v, é o número de graus de liberdade do erro do modelo. Você pode calcular os graus de liberdade do denominador subtraindo o número de observações de amostra do número total de coeficientes exceto a constante menos 1. Então \\(v = n - u - 1\\).\nSuponha que você queira saber o tamanho de amostra necessário para uma regressão linear com cinco variáveis independentes detectar efeitos grandes, \\(f^2 = 0.35\\), com taxa de falso positivo (\\(\\alpha\\)) de 1%, e poder estatístico (\\(1 - \\beta\\)) de 95%. Aqui temos u = 5, pois são seis coeficientes (contando com a constante) menos a constante (\\(6-1=5\\)).\n\n\npwr.f2.test(f2 = 0.35, u = 5, sig.level = 0.01, power = 0.95)\n\n\n\n     Multiple regression power calculation \n\n              u = 5\n              v = 75.3845\n             f2 = 0.35\n      sig.level = 0.01\n          power = 0.95\n\nVeja que o resultado não nos informa um tamanho amostral, mas sim os graus de liberdade do denominador: v. Lembre-se que \\(v = n - u - 1\\), então \\(n = v + u + 1\\). Portanto nosso tamanho amostral é 81. Isto quer dizer que para identificar efeitos grandes, de no mínimo \\(f^2 = 0.35\\), tanto para \\(R^2\\) quanto para influências das variáveis independentes (em coeficientes padronizados por desvios padrões), com \\(\\alpha\\) em 1% e poder estatístico de 95%, é necessário no mínimo uma amostra com 81 observações.\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Catalina 10.15.7\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] pwr_1.3-0            MASS_7.3-53          likert_1.3.5        \n [4] xtable_1.8-4         naniar_0.6.0.9000    purrr_0.3.4         \n [7] gtsummary_1.3.6      gt_0.2.2             lm.beta_1.5-1       \n[10] lmtest_0.9-38        zoo_1.8-8            ggfortify_0.4.11    \n[13] sjPlot_2.8.7         broom_0.7.4          palmerpenguins_0.1.0\n[16] magrittr_2.0.1       mnormt_2.0.2         cowplot_1.1.1       \n[19] tidyr_1.1.2          DescTools_0.99.40    skimr_2.1.2         \n[22] ggpubr_0.4.0         car_3.0-10           carData_3.0-4       \n[25] patchwork_1.1.1      dplyr_1.0.4          ggplot2_3.3.3       \n[28] DiagrammeR_1.0.6.1   readxl_1.3.1        \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1     plyr_1.8.6          repr_1.1.3         \n  [4] splines_4.0.3       usethis_2.0.1       digest_0.6.27      \n  [7] htmltools_0.5.1.1   magick_2.6.0        fansi_0.4.2        \n [10] checkmate_2.0.0     openxlsx_4.2.3      modelr_0.1.8       \n [13] colorspace_2.0-0    haven_2.3.1         xfun_0.21          \n [16] crayon_1.4.1        jsonlite_1.7.2      Exact_2.1          \n [19] lme4_1.1-26         survival_3.2-7      glue_1.4.2         \n [22] gtable_0.3.0        emmeans_1.5.4       sjstats_0.18.1     \n [25] sjmisc_2.8.6        abind_1.4-5         scales_1.1.1       \n [28] mvtnorm_1.1-1       DBI_1.1.1           rstatix_0.6.0      \n [31] ggeffects_1.0.1     Rcpp_1.0.6          performance_0.7.0  \n [34] tmvnsim_1.0-2       reticulate_1.18     foreign_0.8-80     \n [37] htmlwidgets_1.5.3   RColorBrewer_1.1-2  ellipsis_0.3.1     \n [40] pkgconfig_2.0.3     farver_2.0.3        sass_0.3.1         \n [43] utf8_1.1.4          reshape2_1.4.4      tidyselect_1.1.0   \n [46] labeling_0.4.2      rlang_0.4.10        effectsize_0.4.3   \n [49] munsell_0.5.0       cellranger_1.1.0    tools_4.0.3        \n [52] visNetwork_2.0.9    cli_2.3.0           generics_0.1.0     \n [55] sjlabelled_1.1.7    evaluate_0.14       stringr_1.4.0      \n [58] yaml_2.2.1          fs_1.5.0            knitr_1.31         \n [61] zip_2.1.1           visdat_0.5.3        rootSolve_1.8.2.1  \n [64] nlme_3.1-149        xml2_1.3.2          compiler_4.0.3     \n [67] rstudioapi_0.13     curl_4.3            e1071_1.7-4        \n [70] ggsignif_0.6.0      tibble_3.0.6        statmod_1.4.35     \n [73] broom.helpers_1.1.0 stringi_1.5.3       highr_0.8          \n [76] parameters_0.11.0   forcats_0.5.1       lattice_0.20-41    \n [79] Matrix_1.2-18       psych_2.0.12        commonmark_1.7     \n [82] nloptr_1.2.2.2      ggsci_2.9           vctrs_0.3.6        \n [85] norm_1.0-9.5        pillar_1.4.7        lifecycle_0.2.0    \n [88] estimability_1.3    data.table_1.13.6   insight_0.12.0     \n [91] lmom_2.8            R6_2.5.0            bookdown_0.21      \n [94] gridExtra_2.3       rio_0.5.16          gld_2.6.2          \n [97] distill_1.2         boot_1.3-25         assertthat_0.2.1   \n[100] rprojroot_2.0.2     withr_2.4.1         parallel_4.0.3     \n[103] mgcv_1.8-33         bayestestR_0.8.2    expm_0.999-6       \n[106] hms_1.0.0           labelled_2.7.0      grid_4.0.3         \n[109] class_7.3-17        minqa_1.2.4         rmarkdown_2.6      \n[112] downlit_0.2.1       lubridate_1.7.9.2   base64enc_0.1-3    \n\n\n\n\nChampely, S. (2020). Pwr: Basic functions for power analysis. Retrieved from https://CRAN.R-project.org/package=pwr\n\n\nCohen, J. (1988). Statistical power analysis for the behavioral sciences. Lawrence Erlbaum Associates.\n\n\nKelley, K., & Preacher, K. J. (2012). On effect size. Psychological Methods, 17(2), 137.\n\n\nNeyman, J., & Pearson, E. S. (1933). On the problem of the most efficient tests of statistical hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694-706), 289–337.\n\n\nPearson, K. (1895). Notes on regression and inheritance in the case of two parents. Proceedings of the royal society of london, 58, 240–242. Royal Society of London.\n\n\nautor 1 ficou indignado quanto um estudo falou que um grupo possuía 50% mais risco de acidente cardiovascular que outro grupo ao transformar o risco absoluto dos dois grupos, mensurados em 1.005 e 1.0075, em risco relativo. Aqui a diferença de risco absoluto é 0.25%, mas quando convertido para risco relativo se torna 50%!↩︎\n\\(d\\) de diferença↩︎\nNull Hypothesis Significance Testing – NHST (tradução: teste de significância de hipótese nula)↩︎\ndo original em inglês: “Is it more serious to convict an innocent man or to acquit a guilty? That will depend upon the consequences of the error. Is the punishment death or fine? What is the danger to the community of released criminals? What are the current ethical views on punishment? From the point of view of mathematical theory, all that we can do is to show how the risk of errors may be controlled and minimized. The use of these statistical tools in any given case in determining just how the balance should be struck, must be left to the investigator.”↩︎\n",
      "last_modified": "2021-02-25T11:21:01-03:00"
    },
    {
      "path": "index.html",
      "title": "Estatística com R",
      "description": "Tutoriais de R para a disciplina de Estatística para alunos de Mestrado e Doutorado da UNINOVE.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        },
        {
          "name": "Leonardo Vils",
          "url": "https://scholar.google.com/citations?user=VO07L9EAAAAJ&hl=en"
        }
      ],
      "date": "January 11, 2021",
      "contents": "\n\nContents\nPor que R?\nAulas\nConteúdos Principais\nConteúdos Auxiliares\n\nO que esta disciplina não é\nRStudio na Núvem Gratuito\nProfessores\nComo usar esse conteúdo?\nSlides de Apresentação da Disciplina\nLicença\n\n\n\nPor que R?\nR é uma linguagem criada por estatísticos para estatísticos. Possui um vasto ecossistema de bibliotecas e é amplamente usado na ciência e em especial nas ciências aplicadas. Fizemos toda uma argumentação de porque você deve usar R aqui ou clicando no banner superior em “Por que R?”.\nAulas\nConteúdos Principais\n\nPara quem gosta de nomenclaturas chiques: Conteúdos curriculares obrigatórios na formação do futuro pesquisador. Aqui estão coisas importantes que você usará nas suas pesquisas.\nComandos Básicos de R\n\\(p\\)-Valores, Hipóteses Nula e Pressupostos\nTeste de Hipóteses e Teste \\(t\\)\nAnálise de Variância (ANOVA)\nCorrelações\nRegressão Linear\nRegressão Logística\nConteúdos Auxiliares\n\nMais nomenclaturas chiques: Conteúdos extracurriculares facultativos na formação do futuro pesquisador. Aqui estão coisas não-essenciais mas que farão sua vida de pesquisador muito mais fácil.\nQuarteto de Anscombe\nDados Faltantes\nTamanho de Amostra e Tamanho de Efeito\nLikert e Escalas Ordinais\nTabelas para Publicação\nO que esta disciplina não é\nNão será coberto conteúdos sobre leitura, manipulação e exportação de dados com R. Para isso recomendamos fortemente o livro R para Data Science (Figura 1) que pode ser encontrado gratuitamente aqui e possui uma versão impressa em português1.\n\n\n\nFigure 1: R for Data Science\n\n\n\nRStudio na Núvem Gratuito\nClique no ícone abaixo para abrir uma sessão do RStudio no Projeto Binder.\n\nProfessores\nProf. Dr. José Eduardo Storopoli    \nProf. Dr. Leonardo Vils   \nComo usar esse conteúdo?\nEste conteúdo possui licença livre para uso. Caso queira utilizar o conteúdo para um curso ou estudos, por favor colabore nesse repositório quaisquer aprimorações que foram realizadas.\nPara configurar um ambiente local:\nClone o repositório do GitHub: git clone https://github.com/storopoli/Estatistica.git\nAcesse o diretório: cd Estatistica\nInstale os pacotes necessários: Rscript .binder/install.R\nSlides de Apresentação da Disciplina2\n\n\n\nfitvids('.shareagain', {players: 'iframe'});\n\nLicença\nEste obra está licenciado com uma Licença Creative Commons Atribuição-CompartilhaIgual 4.0 Internacional.\n\n\nNão temos nada a ver com a Amazon. Caso queira comprar em qualquer outra loja fique à vontade, ou algum sebo… Jeff Bezos nem sabe que nós existimos…↩︎\nGeralmente nossos Slides são extremamente enxutos e o real conteúdo fica na nossa fala e na interatividade da apresentação. Provavelmente você não entenderá nada desses slides, mas a sua experiência conosco apresentando-os deverá ser excepcional.↩︎\n",
      "last_modified": "2021-02-25T11:31:14-03:00"
    }
  ],
  "collections": []
}
